{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一、预处理\n",
    "\n",
    "导入相关函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce GTX 1660 Ti\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# We have three versions of our implementations\n",
    "# Version1: without using socket and no DP+PixelDP\n",
    "# Version2: with using socket but no DP+PixelDP\n",
    "# Version3: without using socket but with DP+PixelDP\n",
    "\n",
    "# This program is Version1: Single program simulation\n",
    "# ============================================================================\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "from pandas import DataFrame\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "def init_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        print(torch.cuda.get_device_name(0))\n",
    "init_seeds(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1模型初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "\n",
    "class ResNet18_client_side(nn.Module):\n",
    "    def __init__(self, block, num_blocks):\n",
    "        super(ResNet18_client_side, self).__init__()\n",
    "        self.in_planes = 64\n",
    "        self.conv1 = conv3x3(3, 64)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(in_planes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion * planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion * planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet18_server_side(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10, pool_size=4):  # Add a new argument pool_size\n",
    "        super(ResNet18_server_side, self).__init__()\n",
    "        self.in_planes = 64\n",
    "        self.pool_size = pool_size  # Add this line to store pool_size\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer2(x)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        # print(\"Output shape before pooling:\", out.shape)\n",
    "        out = F.avg_pool2d(out, kernel_size=self.pool_size)  # Use self.pool_size instead of 8\n",
    "        # print(\"Output shape after pooling:\", out.shape)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        y_hat = self.linear(out)\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------SFLV1_label_random_----------\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "def init_logging(program_name):\n",
    "    logging.basicConfig(filename=f'{program_name}.log', level=logging.INFO)\n",
    "    logging.getLogger().addHandler(logging.StreamHandler())\n",
    "    \n",
    "# ===================================================================\n",
    "program = \"SFLV1_label_random_\"\n",
    "print(f\"---------{program}----------\")  # this is to identify the program in the slurm outputs files\n",
    "init_logging(program)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# ===================================================================\n",
    "\n",
    "# No. of users\n",
    "num_users = 20\n",
    "epochs = 100\n",
    "frac = 1  # participation of clients; if 1 then 100% clients participate in SFLV1\n",
    "lr = 0.0001\n",
    "poisoned_frac = 0.1\n",
    "\n",
    "# CIFAR10\\HAM10000\n",
    "dataset_choice = 'CIFAR10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ResNet18_client_side(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "ResNet18_server_side(\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "def init_models(device, dataset_choice):\n",
    "    net_glob_client = ResNet18_client_side(BasicBlock, [2, 2, 2, 2]).to(device)\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        logging.info(f\"We use {torch.cuda.device_count()} GPUs\")\n",
    "        net_glob_client = nn.DataParallel(net_glob_client)\n",
    "\n",
    "    net_glob_client.to(device)\n",
    "    logging.info(net_glob_client)\n",
    "\n",
    "    if dataset_choice == 'HAM10000':\n",
    "        num_classes = 7\n",
    "        pool_size = 8\n",
    "    elif dataset_choice == 'CIFAR10':\n",
    "        num_classes = 10\n",
    "        pool_size = 4\n",
    "    else:\n",
    "        raise ValueError('Invalid dataset choice.')\n",
    "\n",
    "    net_glob_server = ResNet18_server_side(BasicBlock, [2,2,2,2], num_classes=num_classes,pool_size=pool_size)\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        logging.info(f\"We use {torch.cuda.device_count()} GPUs\")\n",
    "        net_glob_server = nn.DataParallel(net_glob_server)\n",
    "\n",
    "    net_glob_server.to(device)\n",
    "    logging.info(net_glob_server)\n",
    "\n",
    "    return net_glob_client, net_glob_server\n",
    "\n",
    "net_glob_client, net_glob_server = init_models(device, dataset_choice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 变量初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ===================================================================================\n",
    "# For Server Side Loss and Accuracy\n",
    "loss_train_collect = []\n",
    "acc_train_collect = []\n",
    "loss_test_collect = []\n",
    "acc_test_collect = []\n",
    "batch_acc_train = []\n",
    "batch_loss_train = []\n",
    "batch_acc_test = []\n",
    "batch_loss_test = []\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "count1 = 0\n",
    "count2 = 0\n",
    "\n",
    "# ====================================================================================================\n",
    "#                                  Server Side Program\n",
    "# ====================================================================================================\n",
    "# Federated averaging: FedAvg\n",
    "# to print train - test together in each round-- these are made global\n",
    "acc_avg_all_user_train = 0\n",
    "loss_avg_all_user_train = 0\n",
    "loss_train_collect_user = []\n",
    "acc_train_collect_user = []\n",
    "loss_test_collect_user = []\n",
    "acc_test_collect_user = []\n",
    "\n",
    "# （即权重和偏置）保存到w_glob_server中。\n",
    "w_glob_server = net_glob_server.state_dict()\n",
    "w_locals_server = []\n",
    "\n",
    "# client idx collector\n",
    "idx_collect = []  # 初始化一个空列表，用于收集选择的客户端的索引。\n",
    "l_epoch_check = False  # 初始化一个布尔变量，用于指示是否进行了本地训练轮次的检查。\n",
    "fed_check = False  # 初始化一个布尔变量，用于指示是否完成了联邦学习。\n",
    "# Initialization of net_model_server and net_server (server-side model)\n",
    "net_model_server = [net_glob_server for i in range(num_users)]  # 该列表包含了每个客户端的初始模型。\n",
    "net_server = copy.deepcopy(net_model_server[0]).to(device)  # 初始化为net_model_server的第一个元素的深拷贝，并将其移到GPU上。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To print in color -------test/train of the client side\n",
    "def prRed(skk): print(\"\\033[91m {}\\033[00m\" .format(skk))\n",
    "def prGreen(skk): print(\"\\033[92m {}\\033[00m\" .format(skk))\n",
    "\n",
    "def calculate_accuracy(fx, y):\n",
    "    preds = fx.max(1, keepdim=True)[1]\n",
    "    correct = preds.eq(y.view_as(preds)).sum()\n",
    "    acc = 100.00 *correct.float()/preds.shape[0]\n",
    "    return acc\n",
    "\n",
    "def subtract_weights(w1, w2):\n",
    "    \"\"\"\n",
    "    计算 w1 和 w2 之间的差，即 w1 - w2。\n",
    "\n",
    "    Args:\n",
    "        w1 (OrderedDict): 权重字典 1\n",
    "        w2 (OrderedDict): 权重字典 2\n",
    "\n",
    "    Returns:\n",
    "        OrderedDict: w1 和 w2 之间的权重差异\n",
    "    \"\"\"\n",
    "    diff = OrderedDict()\n",
    "    for key in w1.keys():\n",
    "        diff[key] = w1[key] - w2[key]\n",
    "    return diff\n",
    "\n",
    "\n",
    "# Federated averaging: FedAvg\n",
    "def FedAvg(w):\n",
    "    w_avg = copy.deepcopy(w[0])\n",
    "    for k in w_avg.keys():\n",
    "        for i in range(1, len(w)):\n",
    "            w_avg[k] += w[i][k]\n",
    "        w_avg[k] = torch.div(w_avg[k], len(w))\n",
    "    return w_avg\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def remove_anomalies_kmeans(w_locals, w_glob, n_clusters, remove_ratio):\n",
    "    gradients_diffs = [subtract_weights(w_local, w_glob) for w_local in w_locals]\n",
    "    gradients_list = []\n",
    "\n",
    "    for diff in gradients_diffs:\n",
    "        diff_list = [v.cpu().numpy().flatten() for v in diff.values()]\n",
    "        gradients_list.append(np.concatenate(diff_list))\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaled_gradients = scaler.fit_transform(gradients_list)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(scaled_gradients)\n",
    "    cluster_labels = kmeans.labels_\n",
    "\n",
    "    cluster_sizes = np.bincount(cluster_labels)\n",
    "    smallest_cluster = np.argmin(cluster_sizes)\n",
    "\n",
    "    remove_count = int(remove_ratio * len(w_locals))\n",
    "    smallest_cluster_indices = np.argsort(np.linalg.norm(kmeans.transform(gradients_list), axis=1))[:remove_count]\n",
    "\n",
    "    w_locals = [w for idx, w in enumerate(w_locals) if idx not in smallest_cluster_indices]\n",
    "\n",
    "    return w_locals,smallest_cluster_indices\n",
    "\n",
    "def krum_aggregation(weight_dicts, num_to_select):\n",
    "    # ...（weights_to_array、array_to_weights和pairwise_distances函数保持不变）\n",
    "    def weights_to_array(weight_dict):\n",
    "        \"\"\"\n",
    "        将权重字典转换为 numpy 数组。\n",
    "        :param weight_dict: 权重字典，其中每个值都是一个 torch.Tensor 张量。\n",
    "        :return: 一个 numpy 数组，其中包含了所有权重张量的扁平化数组。\n",
    "        \"\"\"\n",
    "        # 初始化 weight_list 列表，用于存储 weight_dict 中每个权重张量的扁平化数组。\n",
    "        weight_list = []\n",
    "        for key in weight_dict:\n",
    "            # 将权重张量转换为 numpy 数组，并使用 flatten 函数将其扁平化\n",
    "            weight_list.append(weight_dict[key].cpu().numpy().flatten())\n",
    "        # 将 weight_list 中的数组连接成一个 numpy 数组，并返回该数组\n",
    "        return np.concatenate(weight_list)\n",
    "\n",
    "    def array_to_weights(array, weight_dict_template):\n",
    "        \"\"\"\n",
    "        从 numpy 数组中提取权重张量，并将它们保存到一个新的权重字典中。\n",
    "        :param array: 包含所有权重张量的扁平化 numpy 数组。\n",
    "        :param weight_dict_template: 一个权重字典模板，其中包含了所有权重张量的形状。\n",
    "        :return: 一个新的权重字典，其中包含了从数组中提取的权重张量。\n",
    "        \"\"\"\n",
    "        # 初始化一个新的有序字典 new_weight_dict，用于存储从 numpy 数组中提取的权重张量\n",
    "        new_weight_dict = OrderedDict()\n",
    "        # 初始化一个索引变量 idx，用于跟踪从数组中提取权重的位置\n",
    "        idx = 0\n",
    "        # 遍历权重字典模板中的每个键 key\n",
    "        for key in weight_dict_template:\n",
    "            # 获取权重张量的大小 size\n",
    "            size = weight_dict_template[key].numel()\n",
    "            # 从 numpy 数组中提取一个与权重张量相同大小的一维切片，并使用 reshape 函数重新塑形\n",
    "            # 将 numpy 数组转换为 torch.Tensor 张量，并将其存储到新的有序字典 new_weight_dict 中\n",
    "            new_weight_dict[key] = torch.from_numpy(array[idx:idx + size].reshape(weight_dict_template[key].shape))\n",
    "            # 更新索引变量 idx 的值，跳过已经提取的权重张量\n",
    "            idx += size\n",
    "        # 返回新的有序字典 new_weight_dict\n",
    "        return new_weight_dict\n",
    "\n",
    "    def pairwise_distances(weight_updates):\n",
    "        # 获取客户端数量\n",
    "        n_clients = len(weight_updates)\n",
    "        # 初始化一个距离矩阵，矩阵大小为 n_clients * n_clients\n",
    "        distances = np.zeros((n_clients, n_clients))\n",
    "\n",
    "        # 遍历所有的客户端对\n",
    "        for i in range(n_clients):\n",
    "            for j in range(i + 1, n_clients):\n",
    "                # 计算 i 和 j 客户端之间的欧氏距离\n",
    "                dist = np.linalg.norm(weight_updates[i] - weight_updates[j])\n",
    "                # 在距离矩阵中记录距离\n",
    "                distances[i, j] = dist\n",
    "                distances[j, i] = dist\n",
    "\n",
    "        # 返回距离矩阵\n",
    "        return distances\n",
    "\n",
    "    weight_arrays = [weights_to_array(weight_dict) for weight_dict in weight_dicts]\n",
    "    n_clients = len(weight_arrays)\n",
    "    distances = pairwise_distances(weight_arrays)\n",
    "\n",
    "    krum_scores = []\n",
    "    for i in range(n_clients):\n",
    "        sorted_distances = np.sort(distances[i])\n",
    "        # 计算当前客户端的Krum分数，即距离最大的n_clients - num_to_select - 1个客户端之间的距离总和。\n",
    "        krum_score = np.sum(sorted_distances[-(n_clients - num_to_select - 1):])\n",
    "        krum_scores.append(krum_score)\n",
    "\n",
    "    # 使用np.argpartition函数找到具有最低Krum分数的num_to_select个客户端的索引。\n",
    "    best_clients_indices = np.argpartition(krum_scores, num_to_select)[:num_to_select]\n",
    "\n",
    "    # 从权重数组中选择最佳客户端的权重。\n",
    "    selected_weight_arrays = [weight_arrays[i] for i in best_clients_indices]\n",
    "    # 计算选定客户端的权重数组的平均值，得到聚合后的权重数组。\n",
    "    aggregated_weight_array = np.mean(selected_weight_arrays, axis=0)\n",
    "\n",
    "    # 使用array_to_weights函数将聚合后的权重数组转换回权重字典。\n",
    "    aggregated_weights = array_to_weights(aggregated_weight_array, weight_dicts[0])\n",
    "\n",
    "    # 返回聚合后的权重字典和最好的客户端索引列表。\n",
    "    return aggregated_weights, best_clients_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3定义服务端"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_server(fx_client, y, l_epoch_count, l_epoch, idx, len_batch):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        fx_client: 一个函数，用于在客户端更新模型参数，它接受以下参数：net_model_client（客户端模型），optimizer_client（客户端优化器），train_loader（客户端训练数据），l_epoch（客户端训练轮数）。\n",
    "        y:目标变量的标签值。\n",
    "        l_epoch_count:训练的总轮数\n",
    "        l_epoch:当前训练的轮数\n",
    "        idx:用于选择在全局模型中使用哪些本地模型进行更新的客户端的索引。\n",
    "        len_batch:训练数据的批次大小。\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    # 这些是全局变量，因为它们在函数内被更新，并且在函数之外被调用。\n",
    "    \"\"\"\n",
    "    net_model_server: 全局模型。\n",
    "    criterion: 损失函数，用于计算模型的误差。\n",
    "    optimizer_server: 优化器，用于更新全局模型的参数。\n",
    "    device: 设备（CPU或GPU）用于计算。\n",
    "    batch_acc_train: 当前批次的准确度。\n",
    "    batch_loss_train: 当前批次的损失。\n",
    "    l_epoch_check: 在训练期间用于检查损失和准确度的训练周期数。\n",
    "    fed_check: 用于检查训练周期是否已完成的标志。\n",
    "    loss_train_collect: 用于收集所有客户端训练损失的列表。\n",
    "    acc_train_collect: 用于收集所有客户端训练准确度的列表。\n",
    "    count1: 计数器，用于跟踪当前已经训练的客户端数量。\n",
    "    acc_avg_all_user_train: 所有客户端训练准确度的平均值。\n",
    "    loss_avg_all_user_train: 所有客户端训练损失的平均值。\n",
    "    idx_collect: 用于跟踪已经训练的客户端的索引列表。\n",
    "    w_locals_server: 所有客户端本地模型参数的列表。\n",
    "    w_glob_server: 全局模型参数的列表。\n",
    "    net_server: 全局模型。\n",
    "    \"\"\"\n",
    "    global net_model_server, criterion, optimizer_server, device, batch_acc_train, batch_loss_train, l_epoch_check, fed_check\n",
    "    global loss_train_collect, acc_train_collect, count1, acc_avg_all_user_train, loss_avg_all_user_train, idx_collect, w_locals_server, w_glob_server, net_server\n",
    "    global loss_train_collect_user, acc_train_collect_user, lr\n",
    "\n",
    "    # net_server是全局模型，返回制定索引的本地模型\n",
    "    net_server = copy.deepcopy(net_model_server[idx]).to(\n",
    "        device)  # copy.deepcopy() 函数用于创建一个当前本地模型的副本，以便我们可以在全局模型的更新过程中使用它，而不会对原始本地模型进行更改。\n",
    "    # 方法将模型设置为训练模式，这意味着在计算时会使用训练期间的正则化技术，如dropout或batch normalization。\n",
    "    net_server.train()\n",
    "    # 是一个PyTorch中的Adam优化器的实现，它接受模型参数和学习率作为参数，用于更新模型参数以最小化损失函数。在这里，我们使用全局模型的参数和一个预定义的学习率 lr 创建了一个Adam优化器对象\n",
    "    optimizer_server = torch.optim.Adam(net_server.parameters(), lr=lr)\n",
    "\n",
    "    # 1.train and update\n",
    "    # 用于清空之前的梯度信息，这样我们可以在每个训练迭代中计算新的梯度并更新模型参数。\n",
    "    optimizer_server.zero_grad()\n",
    "\n",
    "    fx_client = fx_client.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    # ---------forward prop-------------\n",
    "    fx_server = net_server(fx_client)  # 作为输入传递到全局模型 net_server 中，然后返回模型的预测输出 fx_server\n",
    "\n",
    "    # calculate loss\n",
    "    loss = criterion(fx_server, y)\n",
    "    # calculate accuracy\n",
    "    acc = calculate_accuracy(fx_server, y)\n",
    "\n",
    "    # --------backward prop--------------\n",
    "    loss.backward()\n",
    "    # 由于我们需要在全局模型更新之前将 fx_client 更新到最新的版本，因此我们使用 clone().detach() 函数来创建一个新的 dfx_client 张量，它具有相同的值但不会被计算图所记录。\n",
    "    dfx_client = fx_client.grad.clone().detach()\n",
    "    optimizer_server.step()\n",
    "\n",
    "    batch_loss_train.append(loss.item())\n",
    "    batch_acc_train.append(acc.item())\n",
    "\n",
    "    # Update the server-side model for the current batch\n",
    "    net_model_server[idx] = copy.deepcopy(net_server)\n",
    "\n",
    "    # count1: to track the completion of the local batch associated with one client\n",
    "    count1 += 1\n",
    "    if count1 == len_batch:\n",
    "        acc_avg_train = sum(batch_acc_train) / len(batch_acc_train)  # 计算当前batch的准确率\n",
    "        loss_avg_train = sum(batch_loss_train) / len(batch_loss_train)  # 计算当前batch的损失\n",
    "\n",
    "        batch_acc_train = []  # 将当前batch准确率清零\n",
    "        batch_loss_train = []\n",
    "        count1 = 0\n",
    "\n",
    "        prRed('Client{} Train => Local Epoch: {} \\tAcc: {:.3f} \\tLoss: {:.4f}'.format(idx, l_epoch_count, acc_avg_train,\n",
    "                                                                                      loss_avg_train))\n",
    "\n",
    "        # copy the last trained model in the batch\n",
    "        # 的状态字典复制到一个新的字典中，以便我们可以将其发送到参与者，从而启动下一轮的联邦学习。注意，w_server 中包含的参数是最新一轮训练的参数，因此每个参与者将从这些参数开始训练它们的本地模型。\n",
    "        w_server = net_server.state_dict()\n",
    "\n",
    "        # If one local epoch is completed, after this a new client will come\n",
    "        if l_epoch_count == l_epoch - 1:\n",
    "            # l_epoch_count 是本地epoch的计数器，l_epoch 是本地epoch的总数。当计数器 l_epoch_count 等于总数 l_epoch 减 1 时，说明本地epoch已经完成。\n",
    "            # # 标记已经完成本地epoch\n",
    "            l_epoch_check = True  # to evaluate_server function - to check local epoch has completed or not\n",
    "            # We store the state of the net_glob_server()\n",
    "            # w_server 是全局模型中最新的训练参数，w_locals_server 是用于存储每个参与者的最后一轮训练参数的列表。因此，当本地epoch完成时，将 w_server 添加到 w_locals_server 中，以便之后将其发送到联邦平均服务器。\n",
    "            w_locals_server.append(copy.deepcopy(w_server))\n",
    "\n",
    "            # we store the last accuracy in the last batch of the epoch and it is not the average of all local epochs\n",
    "            # this is because we work on the last trained model and its accuracy (not earlier cases)\n",
    "\n",
    "            # print(\"accuracy = \", acc_avg_train)\n",
    "            acc_avg_train_all = acc_avg_train  # 记录最后一个batch的准确率和损失，作为本地epoch的结果\n",
    "            loss_avg_train_all = loss_avg_train  #\n",
    "\n",
    "            # accumulate accuracy and loss for each new user\n",
    "            loss_train_collect_user.append(loss_avg_train_all)  # 将本地epoch的损失添加到损失列表中\n",
    "            acc_train_collect_user.append(acc_avg_train_all)  # # 将本地epoch的准确率添加到准确率列表中\n",
    "\n",
    "            # collect the id of each new user\n",
    "            if idx not in idx_collect:\n",
    "                idx_collect.append(idx)\n",
    "                # print(idx_collect)\n",
    "#                 print(\"已经训练的客户端:\" + str(idx_collect))\n",
    "\n",
    "        # This is for federation process--------------------\n",
    "        if len(idx_collect) == num_users * frac:\n",
    "            # 如果客户端编号列表的长度等于客户端总数，说明所有客户端的训练结果都已经到达服务器了。\n",
    "            # 这里不对，是选择的客户端总数\n",
    "            fed_check = True  # to evaluate_server function  - to check fed check has hitted\n",
    "\n",
    "            # 异常检测\n",
    "            # 使用异常检测移除异常客户端\n",
    "            # anomaly_threshold = 2  # 自定义阈值\n",
    "            # w_locals_server = remove_anomalies(w_locals_server, w_glob_server.state_dict(), anomaly_threshold)\n",
    "\n",
    "            # ================== 使用不同的聚合算法 =================\n",
    "            w_locals_server,smallest_cluster_indices = remove_anomalies_kmeans(w_locals_server, w_glob_server, n_clusters=4\n",
    "            , remove_ratio=poisoned_frac)\n",
    "\n",
    "            # ================== 使用不同的聚合算法 =================\n",
    "            w_glob_server = FedAvg(w_locals_server)  # 使用联邦平均算法更新全局模型，将所有客户端的本地模型参数传入该函数中。\n",
    "            # num_to_select = int(num_users * (1 - poisoned_frac - 0.1))  # 选择的客户端数量\n",
    "            # w_glob_server, selected_clients_indices = krum_aggregation(w_locals_server, num_to_select)\n",
    "\n",
    "            # server-side global model update and distribute that model to all clients ------------------------------\n",
    "            net_glob_server.load_state_dict(w_glob_server)  # 将更新后的全局模型参数加载到服务器端的模型中。\n",
    "            net_model_server = [net_glob_server for i in\n",
    "                                range(num_users)]  # 创建一个长度为客户端数量的列表，每个元素都是更新后的全局模型。这个列表用于向每个客户端分发全局模型参数。\n",
    "\n",
    "\n",
    "\n",
    "            acc_avg_all_user_train = sum(acc_train_collect_user) / len(acc_train_collect_user)  # 计算所有客户端训练结果的平均准确率和损失\n",
    "            loss_avg_all_user_train = sum(loss_train_collect_user) / len(loss_train_collect_user)\n",
    "\n",
    "            # 更新性能指标列表\n",
    "            loss_train_collect.append(loss_avg_all_user_train)\n",
    "            acc_train_collect.append(acc_avg_all_user_train)\n",
    "\n",
    "            acc_train_collect_user = []\n",
    "            loss_train_collect_user = []\n",
    "\n",
    "            w_locals_server = []  # # 清空本地模型参数列表\n",
    "            idx_collect = []  # 清空客户端编号列表\n",
    "\n",
    "    # send gradients to the client\n",
    "    return dfx_client\n",
    "\n",
    "\n",
    "def evaluate_server(fx_client, y, idx, len_batch, ell, selected_clients):\n",
    "    global net_model_server, criterion, batch_acc_test, batch_loss_test, check_fed, net_server, net_glob_server\n",
    "    global loss_test_collect, acc_test_collect, count2, num_users, acc_avg_train_all, loss_avg_train_all, w_glob_server, l_epoch_check, fed_check\n",
    "    global loss_test_collect_user, acc_test_collect_user, acc_avg_all_user_train, loss_avg_all_user_train\n",
    "\n",
    "    net = copy.deepcopy(net_model_server[idx]).to(device)\n",
    "    net.eval()\n",
    "    return_local_results = False\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # with torch.no_grad()是一个上下文管理器，它可以暂时关闭所有的requires_grad标志，从而不计算梯度1。这样可以节省内存，提高推理速度，也可以避免不必要的梯度累积2。通常在验证或部署模型时使用这个方法3。\n",
    "        fx_client = fx_client.to(device)\n",
    "        y = y.to(device)\n",
    "        # ---------forward prop-------------\n",
    "        fx_server = net(fx_client)\n",
    "\n",
    "        # calculate loss\n",
    "        loss = criterion(fx_server, y)\n",
    "        # calculate accuracy\n",
    "        acc = calculate_accuracy(fx_server, y)\n",
    "\n",
    "        batch_loss_test.append(loss.item())\n",
    "        batch_acc_test.append(acc.item())\n",
    "\n",
    "        count2 += 1\n",
    "        if count2 == len_batch:\n",
    "            acc_avg_test = sum(batch_acc_test) / len(batch_acc_test)\n",
    "            loss_avg_test = sum(batch_loss_test) / len(batch_loss_test)\n",
    "\n",
    "            batch_acc_test = []\n",
    "            batch_loss_test = []\n",
    "            count2 = 0\n",
    "\n",
    "            prGreen('Client{} Test =>                   \\tAcc: {:.3f} \\tLoss: {:.4f}'.format(idx, acc_avg_test,\n",
    "                                                                                             loss_avg_test))\n",
    "\n",
    "            # if a local epoch is completed\n",
    "            if l_epoch_check:\n",
    "                l_epoch_check = False\n",
    "                return_local_results = True\n",
    "\n",
    "                # Store the last accuracy and loss\n",
    "                acc_avg_test_all = acc_avg_test\n",
    "                loss_avg_test_all = loss_avg_test\n",
    "\n",
    "                loss_test_collect_user.append(loss_avg_test_all)\n",
    "                acc_test_collect_user.append(acc_avg_test_all)\n",
    "\n",
    "            # if federation is happened----------\n",
    "            if fed_check:\n",
    "                fed_check = False\n",
    "                print(\"------------------------------------------------\")\n",
    "                print(\"------ Federation process at Server-Side ------- \")\n",
    "                print(\"------------------------------------------------\")\n",
    "\n",
    "                # 计算Krum选定客户端的平均准确率和损失\n",
    "                if selected_clients is None or len(selected_clients) == 0:\n",
    "                    acc_avg_all_user = sum(acc_test_collect_user) / len(acc_test_collect_user)\n",
    "                    loss_avg_all_user = sum(loss_test_collect_user) / len(loss_test_collect_user)\n",
    "                else:\n",
    "                    print(\"选择的客户端index:\", selected_clients)\n",
    "                    acc_test_collect_user = [acc_test_collect_user[i] for i in selected_clients]\n",
    "                    loss_test_collect_user = [loss_test_collect_user[i] for i in selected_clients]\n",
    "\n",
    "                    acc_avg_all_user = sum(acc_test_collect_user) / len(acc_test_collect_user)\n",
    "                    loss_avg_all_user = sum(loss_test_collect_user) / len(loss_test_collect_user)\n",
    "\n",
    "                loss_test_collect.append(loss_avg_all_user)\n",
    "                acc_test_collect.append(acc_avg_all_user)\n",
    "                acc_test_collect_user = []\n",
    "                loss_test_collect_user = []\n",
    "\n",
    "                print(\"====================== SERVER V1==========================\")\n",
    "                print(' Train: Round {:3d}, Avg Accuracy {:.3f} | Avg Loss {:.3f}'.format(ell, acc_avg_all_user_train,\n",
    "                                                                                          loss_avg_all_user_train))\n",
    "                print(' Test: Round {:3d}, Avg Accuracy {:.3f} | Avg Loss {:.3f}'.format(ell, acc_avg_all_user,\n",
    "                                                                                         loss_avg_all_user))\n",
    "                print(\"==========================================================\")\n",
    "\n",
    "    if return_local_results:\n",
    "        return acc_avg_test_all, loss_avg_test_all\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "\n",
    "class Client(object):\n",
    "    def __init__(self, net_client_model, idx, lr, device, dataset_train=None, dataset_test=None, idxs=None,\n",
    "                 idxs_test=None, is_attacker=None, batch_size=128):\n",
    "        \"\"\"\n",
    "        :param idxs: idxs是一个表示该客户端用于训练的数据集的索引列表。在联邦学习中，原始数据集通常由多个客户端持有，每个客户端只能访问自己所持有的部分数据集。因此，为了让每个客户端只使用自己所持有的数据进行训练，需要将原始数据集划分成多个部分，每个部分由一个客户端持有，并通过idxs将该客户端用于训练的数据集的索引列表传递给Client类的构造函数。\n",
    "        :param idxs_test:\n",
    "        \"\"\"\n",
    "        # net_client_model:一个与客户端实例相关的神经网络模型。\n",
    "        self.batch_size = batch_size\n",
    "        self.is_attacker = is_attacker\n",
    "        self.idx = idx  # 一个整数，表示客户端的索引\n",
    "        self.device = device  # 一个字符串，表示执行客户端计算的设备。\n",
    "        self.lr = lr\n",
    "        self.local_ep = 1\n",
    "        # self.selected_clients = []\n",
    "        # DatasetSplit(dataset_train, idxs)表示使用DatasetSplit类将原始的数据集dataset_train按照索引idxs进行划分，以获得当前客户端可用于训练的数据集。\n",
    "        self.ldr_train = DataLoader(DatasetSplit(dataset_train, idxs), batch_size=self.batch_size,\n",
    "                                    shuffle=True)\n",
    "        self.ldr_test = DataLoader(DatasetSplit(dataset_test, idxs_test), batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "    def train(self, net):\n",
    "        net.train()\n",
    "        optimizer_client = torch.optim.Adam(net.parameters(), lr=self.lr)\n",
    "\n",
    "        for iter in range(self.local_ep):\n",
    "            if self.is_attacker:\n",
    "                dataset_split = self.ldr_train.dataset\n",
    "                num_malicious_samples = len(dataset_split.idxs)\n",
    "                dataset_split.add_malicious_samples(num_malicious_samples,dataset_type=dataset_choice)\n",
    "\n",
    "                # Refresh the DataLoader after adding malicious samples\n",
    "                self.ldr_train = DataLoader(dataset_split, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "            # 外层循环是客户端的本地训练轮数self.local_ep\n",
    "            len_batch = len(self.ldr_train)  # 计算该客户端的训练集数据分成的批次数。\n",
    "            for batch_idx, (images, labels) in enumerate(self.ldr_train):\n",
    "                # 内层循环是数据加载器self.ldr_train中每个批次的训练。在每个批次中，将图像和标签加载到设备上，然后将优化器的梯度清零。\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                optimizer_client.zero_grad()\n",
    "                # ---------forward prop-------------\n",
    "                fx = net(images)\n",
    "                # 生成一个可求导的副本client_fx\n",
    "                client_fx = fx.clone().detach().requires_grad_(True)\n",
    "\n",
    "                # Sending activations to server and receiving gradients from server\n",
    "                dfx = train_server(client_fx, labels, iter, self.local_ep, self.idx, len_batch)\n",
    "\n",
    "                # --------backward prop -------------\n",
    "                fx.backward(dfx)\n",
    "                optimizer_client.step()\n",
    "\n",
    "            # prRed('Client{} Train => Epoch: {}'.format(self.idx, ell))\n",
    "\n",
    "        return net.state_dict()\n",
    "\n",
    "    def evaluate(self, net=None, ell=None, selected_clients=None):\n",
    "        net.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            len_batch = len(self.ldr_test)\n",
    "            for batch_idx, (images, labels) in enumerate(self.ldr_test):\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                # ---------forward prop-------------\n",
    "                fx = net(images)\n",
    "\n",
    "                # Sending activations to server\n",
    "                acc_avg_test_all, loss_avg_test_all = evaluate_server(fx, labels, self.idx, len_batch, ell,\n",
    "                                                                      selected_clients)\n",
    "\n",
    "            # prRed('Client{} Test => Epoch: {}'.format(self.idx, ell))\n",
    "            if loss_avg_test_all is not None and acc_avg_test_all is not None:\n",
    "                self.loss_avg_test_all = loss_avg_test_all\n",
    "                self.acc_avg_test_all = acc_avg_test_all\n",
    "\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image, ImageFilter\n",
    "from PIL import ImageEnhance\n",
    "\n",
    "class DatasetSplit(Dataset):\n",
    "    def __init__(self, dataset, idxs):\n",
    "        self.dataset = dataset\n",
    "        self.idxs = list(idxs)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idxs)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        image, label = self.dataset[self.idxs[item]]\n",
    "        return image, label\n",
    "\n",
    "    def add_malicious_samples(self, num_malicious_samples, dataset_type='CIFAR10'):\n",
    "        for i in range(num_malicious_samples):\n",
    "            # Randomly select an image to modify\n",
    "            dataset_idx = random.choice(self.idxs)\n",
    "\n",
    "            # Access the image data depending on the dataset structure\n",
    "            img = self.dataset.data[dataset_idx]\n",
    "            img = Image.fromarray(img)\n",
    "\n",
    "            # Apply a random modification to the image (e.g., flip, rotate, or change color)\n",
    "            modified_img = img.transpose(Image.FLIP_LEFT_RIGHT)  # Flip the image horizontally\n",
    "            modified_img = modified_img.rotate(random.randint(0, 360))  # Rotate the image randomly\n",
    "\n",
    "            brightness = ImageEnhance.Brightness(modified_img)\n",
    "            modified_img = brightness.enhance(random.uniform(0.5, 1.5))\n",
    "\n",
    "            contrast = ImageEnhance.Contrast(modified_img)\n",
    "            modified_img = contrast.enhance(random.uniform(0.5, 1.5))\n",
    "\n",
    "            saturation = ImageEnhance.Color(modified_img)\n",
    "            modified_img = saturation.enhance(random.uniform(0.5, 1.5))\n",
    "\n",
    "            # Add additional distortions\n",
    "            modified_img = modified_img.filter(\n",
    "                ImageFilter.GaussianBlur(radius=random.uniform(0, 2)))  # Apply Gaussian blur\n",
    "\n",
    "            # Add noise to the image\n",
    "            noise = np.random.normal(0, 25, modified_img.size)\n",
    "            noise = noise.reshape(modified_img.size[::-1]).T.astype(np.uint8)\n",
    "            modified_img = Image.fromarray(np.array(modified_img) + noise)\n",
    "\n",
    "            # Clip the pixel values to be within the valid range (0-255)\n",
    "            modified_img = np.clip(modified_img, 0, 255)\n",
    "\n",
    "            # Convert the modified PIL Image back to a numpy array\n",
    "            modified_img = np.array(modified_img)\n",
    "\n",
    "            self.dataset.data[dataset_idx] = modified_img\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ==============================================================\n",
    "# Custom dataset prepration in Pytorch format\n",
    "class SkinData(Dataset):\n",
    "    def __init__(self, df, data, targets, transform=None):\n",
    "        self.df = df\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, target = self.data[index], self.targets[index]\n",
    "        img = Image.fromarray(img)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "\n",
    "        return img, target\n",
    "\n",
    "\n",
    "def dataset_iid(dataset, num_users):\n",
    "    \"\"\"\n",
    "    该函数接受一个数据集dataset和一个整数num_users作为输入。\n",
    "    它的作用是将数据集分割成num_users份，以便每个客户端都有一份相同分布的数据集。\n",
    "    :param dataset:\n",
    "    :param num_users:\n",
    "    :return:函数返回一个字典dict_users，其中包含num_users个键，每个键对应一个客户端，值为该客户端所分配的数据集索引的集合。\n",
    "    dict_users:{idx:int : []:list}\n",
    "    \"\"\"\n",
    "    # 该函数首先计算每个客户端应该拥有的数据量num_items\n",
    "    num_items = int(len(dataset)/num_users)\n",
    "    dict_users, all_idxs = {}, [i for i in range(len(dataset))]\n",
    "    for i in range(num_users):\n",
    "        # 接着，函数使用np.random.choice函数从all_idxs中选择num_items个索引，将这些索引添加到字典dict_users的第i个键中，表示第i个客户端的数据集。在选择后，从all_idxs中移除已经分配给第i个客户端的索引。\n",
    "        dict_users[i] = set(np.random.choice(all_idxs, num_items, replace = False))\n",
    "        all_idxs = list(set(all_idxs) - dict_users[i])\n",
    "    return dict_users\n",
    "\n",
    "def load_data(dataset_choice, num_users):\n",
    "    \"\"\"\n",
    "\n",
    "    :param dataset_choice: 选择的数据集\n",
    "    :param num_users: 用户的数量\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if dataset_choice == 'HAM10000':\n",
    "        df = pd.read_csv('data/HAM10000_metadata.csv')\n",
    "        print(df.head())\n",
    "\n",
    "        lesion_type = {\n",
    "            'nv': 'Melanocytic nevi',\n",
    "            'mel': 'Melanoma',\n",
    "            'bkl': 'Benign keratosis-like lesions ',\n",
    "            'bcc': 'Basal cell carcinoma',\n",
    "            'akiec': 'Actinic keratoses',\n",
    "            'vasc': 'Vascular lesions',\n",
    "            'df': 'Dermatofibroma'\n",
    "        }\n",
    "\n",
    "        # merging both folders of HAM1000 dataset -- part1 and part2 -- into a single directory\n",
    "        imageid_path = {os.path.splitext(os.path.basename(x))[0]: x\n",
    "                        for x in glob(os.path.join(\"data\", '*', '*.jpg'))}\n",
    "\n",
    "        # print(\"path---------------------------------------\", imageid_path.get)\n",
    "        # 将图像id映射为图像文件的路径，并将其存储在数据集中的path列中。\n",
    "        df['path'] = df['image_id'].map(imageid_path.get)\n",
    "        # 将诊断编码映射为对应的分类名称，并将其存储在数据集中的cell_type列中。\n",
    "        df['cell_type'] = df['dx'].map(lesion_type.get)\n",
    "        # 将分类名称转换为数字编码，并将其存储在数据集中的target列中。这里使用了.\n",
    "        # 可以将字符串类型的分类变量转换为数字编码，其中不同的分类名称对应不同的数字编码。\n",
    "        df['target'] = pd.Categorical(df['cell_type']).codes\n",
    "        print(df['cell_type'].value_counts())\n",
    "        print(df['target'].value_counts())\n",
    "\n",
    "        # =============================================================================\n",
    "        # Train-test split\n",
    "        train, test = train_test_split(df, test_size=0.2)\n",
    "\n",
    "        train = train.reset_index()\n",
    "\n",
    "        test = test.reset_index()\n",
    "\n",
    "        # Load image data and targets\n",
    "        image_data = []\n",
    "        for path in train['path']:\n",
    "            image = Image.open(path).resize((64, 64))\n",
    "            image_data.append(np.array(image))\n",
    "        train_data = np.array(image_data)\n",
    "        train_targets = train['target'].astype(np.int64).to_numpy()  # Change dtype to int64\n",
    "\n",
    "        image_data = []\n",
    "        for path in test['path']:\n",
    "            image = Image.open(path).resize((64, 64))\n",
    "            image_data.append(np.array(image))\n",
    "        test_data = np.array(image_data)\n",
    "        test_targets = test['target'].astype(np.int64).to_numpy()  # Change dtype to int64\n",
    "\n",
    "\n",
    "\n",
    "        # =============================================================================\n",
    "        #                         Data preprocessing\n",
    "        # =============================================================================\n",
    "        # Data preprocessing: Transformation\n",
    "        mean = [0.485, 0.456, 0.406]\n",
    "        std = [0.229, 0.224, 0.225]\n",
    "\n",
    "        train_transforms = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
    "                                               transforms.RandomVerticalFlip(),\n",
    "                                               transforms.Pad(3),\n",
    "                                               transforms.RandomRotation(10),\n",
    "                                               transforms.CenterCrop(64),\n",
    "                                               transforms.ToTensor(),\n",
    "                                               transforms.Normalize(mean=mean, std=std)\n",
    "                                               ])\n",
    "\n",
    "        test_transforms = transforms.Compose([\n",
    "            transforms.Pad(3),\n",
    "            transforms.CenterCrop(64),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=mean, std=std)\n",
    "        ])\n",
    "\n",
    "        # With augmentation\n",
    "        dataset_train = SkinData(train, train_data, train_targets, transform=train_transforms)\n",
    "        dataset_test = SkinData(train, test_data, test_targets, transform=test_transforms)\n",
    "\n",
    "        # ----------------------------------------------------------------\n",
    "        dict_users = dataset_iid(dataset_train, num_users)\n",
    "        dict_users_test = dataset_iid(dataset_test, num_users)\n",
    "    elif dataset_choice == 'CIFAR10':\n",
    "        # =============================================================================\n",
    "        #                         Data loading\n",
    "        # =============================================================================\n",
    "        # Load CIFAR-10 dataset\n",
    "        trainset = datasets.CIFAR10(root='./data', train=True, download=True)\n",
    "        testset = datasets.CIFAR10(root='./data', train=False, download=True)\n",
    "\n",
    "        train_df = pd.DataFrame(trainset.targets, columns=['target'])\n",
    "        test_df = pd.DataFrame(testset.targets, columns=['target'])\n",
    "\n",
    "        # Set the class names\n",
    "        class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "        train_df['cell_type'] = train_df['target'].apply(lambda x: class_names[x])\n",
    "        test_df['cell_type'] = test_df['target'].apply(lambda x: class_names[x])\n",
    "\n",
    "        print(train_df['cell_type'].value_counts())\n",
    "        print(train_df['target'].value_counts())\n",
    "\n",
    "        # =============================================================================\n",
    "        # Train-test split\n",
    "        train = train_df.reset_index()\n",
    "        test = test_df.reset_index()\n",
    "\n",
    "        # =============================================================================\n",
    "        #                         Data preprocessing\n",
    "        # =============================================================================\n",
    "        # Data preprocessing: Transformation\n",
    "        mean = [0.485, 0.456, 0.406]\n",
    "        std = [0.229, 0.224, 0.225]\n",
    "\n",
    "        train_transforms = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
    "                                               transforms.RandomVerticalFlip(),\n",
    "                                               transforms.Pad(3),\n",
    "                                               transforms.RandomRotation(10),\n",
    "                                               transforms.CenterCrop(32),\n",
    "                                               transforms.ToTensor(),\n",
    "                                               transforms.Normalize(mean=mean, std=std)\n",
    "                                               ])\n",
    "\n",
    "        test_transforms = transforms.Compose([\n",
    "            transforms.Pad(3),\n",
    "            transforms.CenterCrop(32),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=mean, std=std)\n",
    "        ])\n",
    "\n",
    "        # With augmentation\n",
    "        dataset_train = datasets.CIFAR10(root='./data', train=True, transform=train_transforms, download=True)\n",
    "        dataset_test = datasets.CIFAR10(root='./data', train=False, transform=test_transforms, download=True)\n",
    "\n",
    "        # ----------------------------------------------------------------\n",
    "        dict_users = dataset_iid(dataset_train, num_users)\n",
    "        dict_users_test = dataset_iid(dataset_test, num_users)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid dataset_choice: Choose either 'HAM10000' or 'CIFAR10'\")\n",
    "\n",
    "    return dataset_train,dataset_test,dict_users,dict_users_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "frog          5000\n",
      "truck         5000\n",
      "deer          5000\n",
      "automobile    5000\n",
      "bird          5000\n",
      "horse         5000\n",
      "ship          5000\n",
      "cat           5000\n",
      "dog           5000\n",
      "airplane      5000\n",
      "Name: cell_type, dtype: int64\n",
      "6    5000\n",
      "9    5000\n",
      "4    5000\n",
      "1    5000\n",
      "2    5000\n",
      "7    5000\n",
      "8    5000\n",
      "3    5000\n",
      "5    5000\n",
      "0    5000\n",
      "Name: target, dtype: int64\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataset_train, dataset_test, dict_users, dict_users_test = load_data(dataset_choice, num_users)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.3数据投毒——标签翻转"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def replace_label1_with_label2_on_df(df,label1,label2,poisoned_dict_users):\n",
    "    \"\"\"\n",
    "    标签反转\n",
    "    :param df:dataframe\n",
    "    :param label1: 等待翻转的标签\n",
    "    :param label2: 需要翻转的标签\n",
    "    :param poisoned_dict_users:包含索引列表的字典,中毒的用户\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    for idx_list in poisoned_dict_users.values():\n",
    "        for idx in idx_list:\n",
    "            if df.loc[idx,'target'] == label1:\n",
    "                df.loc[idx,'target'] = label2\n",
    "    # df.loc[df['target'] == label1, 'target'] = label2\n",
    "    return df\n",
    "\n",
    "def random_select_poisoning_users(dict_users, n):\n",
    "    \"\"\"\n",
    "    随机选择n个key-value对\n",
    "    :param dict_users: 字典，key为索引，value为包含索引值的列表\n",
    "    :param n: 选择的key-value对的数量\n",
    "    :return: 随机选择的key-value对组成的字典\n",
    "    \"\"\"\n",
    "    selected = {}\n",
    "    keys = random.sample(list(dict_users.keys()), n)\n",
    "    for k in keys:\n",
    "        selected[k] = dict_users[k]\n",
    "    return selected\n",
    "\n",
    "# def poison_data(dataset_train, dict_users, poisoned_users_num, original_label, target_label):\n",
    "#     poisoned_dict_users = random_select_poisoning_users(dict_users, poisoned_users_num)\n",
    "#     replace_label1_with_label2_on_df(dataset_train.df, original_label, target_label, poisoned_dict_users)\n",
    "#     return poisoned_dict_users\n",
    "\n",
    "def print_poisoning_results(poisoned_dict_users, dataset_train):\n",
    "    for poisoned_user_key in poisoned_dict_users:\n",
    "        print(\"被投毒的用户:\", poisoned_user_key)\n",
    "\n",
    "    print(\"标签反转后的target统计:\")\n",
    "    print(dataset_train.df['target'].value_counts())\n",
    "\n",
    "def cifar10_to_dataframe(dataset):\n",
    "    data = [dataset[i] for i in range(len(dataset))]\n",
    "    images, labels = zip(*data)\n",
    "    df = pd.DataFrame({\"image\": images, \"target\": labels})\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def poison_data(dataset_train, dataset_choice, dict_users, poisoned_users_num, label_mappings):\n",
    "    if dataset_choice == 'CIFAR10':\n",
    "        df_train = cifar10_to_dataframe(dataset_train)\n",
    "    elif dataset_choice == 'HAM10000':\n",
    "        df_train = dataset_train.df\n",
    "    else:\n",
    "        raise ValueError(\"Invalid dataset choice.\")\n",
    "\n",
    "    poisoned_dict_users = random_select_poisoning_users(dict_users, poisoned_users_num)\n",
    "\n",
    "    for original_label, target_label in label_mappings:\n",
    "        replace_label1_with_label2_on_df(df_train, original_label, target_label, poisoned_dict_users)\n",
    "\n",
    "    # 修改 dataset_train 的标签\n",
    "    if dataset_choice == 'CIFAR10':\n",
    "        for idx, row in df_train.iterrows():\n",
    "            dataset_train.targets[idx] = row['target']\n",
    "\n",
    "    return poisoned_dict_users\n",
    "\n",
    "def poison_data_random(dataset_train, dataset_choice, dict_users, poisoned_users_num):\n",
    "    if dataset_choice == 'CIFAR10':\n",
    "        df_train = cifar10_to_dataframe(dataset_train)\n",
    "    elif dataset_choice == 'HAM10000':\n",
    "        df_train = dataset_train.df\n",
    "    else:\n",
    "        raise ValueError(\"Invalid dataset choice.\")\n",
    "\n",
    "    poisoned_dict_users = random_select_poisoning_users(dict_users, poisoned_users_num)\n",
    "\n",
    "    for idx_list in poisoned_dict_users.values():\n",
    "        for idx in idx_list:\n",
    "            labels = list(set(df_train['target'].unique()) - {df_train.loc[idx, 'target']})\n",
    "            df_train.loc[idx, 'target'] = random.choice(labels)\n",
    "\n",
    "    # 修改 dataset_train 的标签\n",
    "    if dataset_choice == 'CIFAR10':\n",
    "        for idx, row in df_train.iterrows():\n",
    "            dataset_train.targets[idx] = row['target']\n",
    "\n",
    "    return poisoned_dict_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "被投毒的用户: 0\n",
      "被投毒的用户: 19\n",
      "标签反转后的target统计:\n",
      "0    6550\n",
      "1    6001\n",
      "3    5487\n",
      "5    4979\n",
      "4    4522\n",
      "6    4509\n",
      "7    4505\n",
      "2    4489\n",
      "8    4486\n",
      "9    4472\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "#                         Poisoning\n",
    "# =============================================================================\n",
    "\n",
    "def generate_label_mappings(dataset_choice):\n",
    "    if dataset_choice == 'CIFAR10':\n",
    "        num_classes = 10\n",
    "    elif dataset_choice == 'HAM10000':\n",
    "        num_classes = 7\n",
    "    else:\n",
    "        raise ValueError(\"Invalid dataset choice.\")\n",
    "\n",
    "    label_mappings = []\n",
    "    for i in range(num_classes):\n",
    "        target_label = random.choice([j for j in range(num_classes) if j != i])\n",
    "        label_mappings.append((i, target_label))\n",
    "\n",
    "    return label_mappings\n",
    "\n",
    "# 定义攻击模式和目标标签\n",
    "# attack_pattern = np.full((32, 32, 3), 255, dtype=np.uint8)\n",
    "# target_label = 5\n",
    "\n",
    "poisoned_users_num = int(poisoned_frac * num_users)\n",
    "# label_mappings = [(4, 2), (1, 7), (3, 1), (2, 6), (6, 5)]\n",
    "label_mappings = generate_label_mappings(dataset_choice)\n",
    "poisoned_dict_users = poison_data(dataset_train, dataset_choice, dict_users, poisoned_users_num, label_mappings)\n",
    "# # poisoned_dict_users = poison_data_model(dataset_train, dataset_choice, dict_users, poisoned_users_num, attack_pattern, target_label)\n",
    "for poisoned_user_key in poisoned_dict_users:\n",
    "    print(\"被投毒的用户:\", poisoned_user_key)\n",
    "\n",
    "# 如果使用的是 HAM10000 数据集，您可以直接使用 dataset_train.df 查看标签分布\n",
    "if dataset_choice == 'HAM10000':\n",
    "    print(\"标签反转后的target统计:\")\n",
    "    print(dataset_train.df['target'].value_counts())\n",
    "elif dataset_choice == 'CIFAR10':\n",
    "    cifar10_df = cifar10_to_dataframe(dataset_train)\n",
    "    print(\"标签反转后的target统计:\")\n",
    "    print(cifar10_df['target'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.模型train和test\n",
    "## 3.1 初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ------------ Training And Testing  -----------------\n",
    "net_glob_client.train()\n",
    "# copy weights\n",
    "w_glob_client = net_glob_client.state_dict()\n",
    "# Federation takes place after certain local epochs in train() client-side\n",
    "# this epoch is global epoch, also known as rounds\n",
    "\n",
    "total_time = 0.0  # 初始化总时间为0\n",
    "best_clients_indices = None\n",
    "krum_acc_test_collect = []\n",
    "krum_loss_test_collect = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 24.616 \tLoss: 2.0384\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 7.779 \tLoss: 2.9855\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 24.079 \tLoss: 2.0534\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 7.738 \tLoss: 3.0779\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 23.081 \tLoss: 2.0679\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 11.335 \tLoss: 2.9693\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 22.833 \tLoss: 2.0726\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 10.419 \tLoss: 2.8585\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 22.987 \tLoss: 2.0482\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 8.897 \tLoss: 2.9100\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 22.119 \tLoss: 2.0718\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 8.425 \tLoss: 3.3848\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 22.403 \tLoss: 2.0721\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 7.334 \tLoss: 2.8268\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 24.350 \tLoss: 2.0530\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 11.887 \tLoss: 2.9331\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 21.997 \tLoss: 2.0649\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 9.617 \tLoss: 2.8306\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 24.104 \tLoss: 2.0741\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 10.203 \tLoss: 3.0623\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 44.069 \tLoss: 1.4389\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 9.287 \tLoss: 2.8679\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 21.411 \tLoss: 2.0966\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 8.661 \tLoss: 2.7893\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 23.819 \tLoss: 2.0567\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 11.025 \tLoss: 2.9550\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 23.146 \tLoss: 2.0811\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 10.048 \tLoss: 2.8758\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 23.529 \tLoss: 2.0560\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 9.577 \tLoss: 3.2656\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 23.235 \tLoss: 2.0689\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 9.341 \tLoss: 2.8852\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 44.874 \tLoss: 1.4598\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 10.594 \tLoss: 2.9685\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 23.688 \tLoss: 2.0495\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 10.480 \tLoss: 2.9987\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 23.189 \tLoss: 2.0829\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 10.695 \tLoss: 3.1565\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 24.131 \tLoss: 2.0636\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client9 Test =>                   \tAcc: 10.695 \tLoss: 2.8730\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "====================== SERVER V1==========================\n",
      " Train: Round   0, Avg Accuracy 25.383 | Avg Loss 2.004\n",
      " Test: Round   0, Avg Accuracy 9.702 | Avg Loss 2.974\n",
      "==========================================================\n",
      "idxs_users [11  4 14 18  8  1 12  6 16 17  0  7 10  5  3 13 19  2 15  9]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 14, 18, 8, 1, 12, 6, 16, 17, 0, 7, 10, 5, 3, 13, 19, 2, 15]\n",
      "fedserver选择的客户端index: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n",
      "acc: 7.738415956497192\n",
      "acc: 11.334859848022461\n",
      "acc: 10.418911695480347\n",
      "acc: 8.896821022033691\n",
      "acc: 8.425377130508423\n",
      "acc: 7.334321022033691\n",
      "acc: 11.887122869491577\n",
      "acc: 9.617456912994385\n",
      "acc: 10.203394412994385\n",
      "acc: 9.287446022033691\n",
      "acc: 8.661099195480347\n",
      "acc: 11.025053977966309\n",
      "acc: 10.048491477966309\n",
      "acc: 9.577047348022461\n",
      "acc: 9.341325402259827\n",
      "acc: 10.594019412994385\n",
      "acc: 10.479525804519653\n",
      "acc: 10.695043087005615\n",
      "====================== Fed Server==========================\n",
      " Train: Round   0, Avg Accuracy 25.383 | Avg Loss 2.004\n",
      " Test: Round   0, Avg Accuracy 9.754 | Avg Loss 2.979\n",
      "==========================================================\n",
      "Epoch 0 finished in 00:02:30\n",
      "Epoch 0 finished. Total time: 150.37 seconds\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 31.758 \tLoss: 1.8261\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 15.073 \tLoss: 2.7023\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 30.662 \tLoss: 1.8557\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 13.194 \tLoss: 2.5594\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 32.135 \tLoss: 1.8242\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 10.419 \tLoss: 3.1400\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 30.267 \tLoss: 1.8237\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 11.887 \tLoss: 2.8281\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 30.237 \tLoss: 1.8241\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 17.827 \tLoss: 2.5791\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 31.551 \tLoss: 1.8319\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 11.786 \tLoss: 3.1260\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 31.765 \tLoss: 1.8344\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 14.601 \tLoss: 2.8090\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 30.218 \tLoss: 1.8424\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 15.308 \tLoss: 2.6567\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 31.813 \tLoss: 1.8184\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 12.412 \tLoss: 2.7826\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 32.091 \tLoss: 1.8342\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 15.423 \tLoss: 2.5105\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 32.174 \tLoss: 1.8161\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 15.167 \tLoss: 2.8535\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 31.847 \tLoss: 1.8155\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 9.382 \tLoss: 3.2327\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 30.671 \tLoss: 1.8167\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 12.998 \tLoss: 3.0776\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 47.447 \tLoss: 1.4516\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 5.590 \tLoss: 3.3621\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 31.760 \tLoss: 1.8215\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 13.504 \tLoss: 2.6548\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 30.119 \tLoss: 1.8243\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 14.992 \tLoss: 3.0100\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 49.079 \tLoss: 1.4506\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 11.355 \tLoss: 3.1230\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 30.395 \tLoss: 1.8450\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 11.510 \tLoss: 3.0112\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 31.540 \tLoss: 1.8074\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 12.682 \tLoss: 3.0002\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 31.749 \tLoss: 1.8367\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client14 Test =>                   \tAcc: 14.231 \tLoss: 2.8747\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round   1, Avg Accuracy 32.964 | Avg Loss 1.790\n",
      " Test: Round   1, Avg Accuracy 12.780 | Avg Loss 2.906\n",
      "==========================================================\n",
      "idxs_users [10  5  4  8 15 16  6  7  3 18 12  1  2 19 13 11  0  9 17 14]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 5, 4, 8, 15, 16, 6, 7, 3, 18, 12, 1, 2, 13, 11, 9, 17, 14]\n",
      "fedserver选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 17, 18, 19]\n",
      "acc: 15.072737216949463\n",
      "acc: 13.193696022033691\n",
      "acc: 10.418911695480347\n",
      "acc: 11.887122869491577\n",
      "acc: 17.827316761016846\n",
      "acc: 11.786099195480347\n",
      "acc: 14.601293087005615\n",
      "acc: 15.308458805084229\n",
      "acc: 12.412446022033691\n",
      "acc: 15.422952651977539\n",
      "acc: 15.167025804519653\n",
      "acc: 9.381734848022461\n",
      "acc: 12.998383522033691\n",
      "acc: 13.503502130508423\n",
      "acc: 14.991918087005615\n",
      "acc: 11.509967684745789\n",
      "acc: 12.681842684745789\n",
      "acc: 14.230872869491577\n",
      "====================== Fed Server==========================\n",
      " Train: Round   1, Avg Accuracy 32.964 | Avg Loss 1.790\n",
      " Test: Round   1, Avg Accuracy 13.466 | Avg Loss 2.856\n",
      "==========================================================\n",
      "Epoch 1 finished in 00:02:02\n",
      "Epoch 1 finished. Total time: 272.37 seconds\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 36.682 \tLoss: 1.7133\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 29.809 \tLoss: 1.8727\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 34.881 \tLoss: 1.7467\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 33.055 \tLoss: 1.8265\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 35.641 \tLoss: 1.7094\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 25.276 \tLoss: 2.0766\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 35.069 \tLoss: 1.7226\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 31.432 \tLoss: 1.8403\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 33.557 \tLoss: 1.7299\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 27.984 \tLoss: 1.9518\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 35.407 \tLoss: 1.7535\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 33.210 \tLoss: 1.7910\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 33.920 \tLoss: 1.7418\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 33.971 \tLoss: 1.9232\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 49.906 \tLoss: 1.4162\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 3.401 \tLoss: 4.6213\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 34.000 \tLoss: 1.7308\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 26.973 \tLoss: 1.8852\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 36.406 \tLoss: 1.7001\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 26.192 \tLoss: 2.0722\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 34.642 \tLoss: 1.7200\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 28.300 \tLoss: 2.0163\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 35.857 \tLoss: 1.7057\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 32.644 \tLoss: 1.8834\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 35.728 \tLoss: 1.7179\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 31.102 \tLoss: 1.7466\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 34.940 \tLoss: 1.7139\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 25.997 \tLoss: 2.3391\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 48.722 \tLoss: 1.4238\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 9.072 \tLoss: 4.0123\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 36.643 \tLoss: 1.7194\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 30.664 \tLoss: 1.8522\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 36.126 \tLoss: 1.7102\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 23.202 \tLoss: 2.4852\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 34.676 \tLoss: 1.7129\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 30.139 \tLoss: 1.9286\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 35.898 \tLoss: 1.7160\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 34.166 \tLoss: 1.7933\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 33.550 \tLoss: 1.7299\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client1 Test =>                   \tAcc: 34.348 \tLoss: 1.8076\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round   2, Avg Accuracy 36.613 | Avg Loss 1.692\n",
      " Test: Round   2, Avg Accuracy 27.874 | Avg Loss 2.161\n",
      "==========================================================\n",
      "idxs_users [ 4  7 13  2 14  5 15  0 12 17  9 10 16  8 19 11  6 18  3  1]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 7, 13, 2, 14, 5, 15, 12, 17, 9, 10, 16, 8, 11, 6, 18, 3, 1]\n",
      "fedserver选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19]\n",
      "acc: 29.808728218078613\n",
      "acc: 33.05495643615723\n",
      "acc: 25.276131629943848\n",
      "acc: 31.431842803955078\n",
      "acc: 27.983566761016846\n",
      "acc: 33.20985984802246\n",
      "acc: 33.97090530395508\n",
      "acc: 26.973329544067383\n",
      "acc: 26.192079544067383\n",
      "acc: 28.300107955932617\n",
      "acc: 32.644126892089844\n",
      "acc: 31.101831436157227\n",
      "acc: 25.996767044067383\n",
      "acc: 30.6640625\n",
      "acc: 23.201777935028076\n",
      "acc: 30.138739109039307\n",
      "acc: 34.16621780395508\n",
      "acc: 34.348060607910156\n",
      "====================== Fed Server==========================\n",
      " Train: Round   2, Avg Accuracy 36.613 | Avg Loss 1.692\n",
      " Test: Round   2, Avg Accuracy 29.915 | Avg Loss 1.950\n",
      "==========================================================\n",
      "Epoch 2 finished in 00:02:01\n",
      "Epoch 2 finished. Total time: 394.28 seconds\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 36.926 \tLoss: 1.6658\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 34.786 \tLoss: 1.7578\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 37.978 \tLoss: 1.6624\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 37.406 \tLoss: 1.7516\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 37.553 \tLoss: 1.6570\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 37.567 \tLoss: 1.6590\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 36.324 \tLoss: 1.6744\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 33.910 \tLoss: 1.8619\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 38.288 \tLoss: 1.6407\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 36.988 \tLoss: 1.6976\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 37.771 \tLoss: 1.6692\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 37.163 \tLoss: 1.6404\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 37.447 \tLoss: 1.6578\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 34.947 \tLoss: 1.7735\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 37.601 \tLoss: 1.6664\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 31.903 \tLoss: 1.8288\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 38.026 \tLoss: 1.6643\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 30.725 \tLoss: 1.9469\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 36.374 \tLoss: 1.6771\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 26.172 \tLoss: 2.0886\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 38.019 \tLoss: 1.6530\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 37.507 \tLoss: 1.7383\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 39.134 \tLoss: 1.6409\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 30.374 \tLoss: 1.8157\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 39.350 \tLoss: 1.6305\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 31.843 \tLoss: 1.7894\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 37.165 \tLoss: 1.6660\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 27.526 \tLoss: 2.3464\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 39.113 \tLoss: 1.6499\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 34.025 \tLoss: 2.1042\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 37.482 \tLoss: 1.6631\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 35.621 \tLoss: 1.6937\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 38.674 \tLoss: 1.6591\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 38.490 \tLoss: 1.5777\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 51.535 \tLoss: 1.3815\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 10.264 \tLoss: 5.5061\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 50.928 \tLoss: 1.3938\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 4.337 \tLoss: 4.2463\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 39.065 \tLoss: 1.6618\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client18 Test =>                   \tAcc: 40.760 \tLoss: 1.5763\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round   3, Avg Accuracy 39.238 | Avg Loss 1.632\n",
      " Test: Round   3, Avg Accuracy 31.466 | Avg Loss 2.137\n",
      "==========================================================\n",
      "idxs_users [12 16  9 14 10  8 11  2 15  5  3 13 17  1  6  7  4 19  0 18]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 16, 9, 14, 10, 8, 11, 2, 15, 5, 3, 13, 17, 1, 6, 7, 4, 18]\n",
      "fedserver选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 19]\n",
      "acc: 34.78582954406738\n",
      "acc: 37.40571117401123\n",
      "acc: 37.567349433898926\n",
      "acc: 33.91029071807861\n",
      "acc: 36.98814678192139\n",
      "acc: 37.163254737854004\n",
      "acc: 34.94746780395508\n",
      "acc: 31.903286933898926\n",
      "acc: 30.724676609039307\n",
      "acc: 26.171875\n",
      "acc: 37.50673484802246\n",
      "acc: 30.37446117401123\n",
      "acc: 31.84267234802246\n",
      "acc: 27.525592803955078\n",
      "acc: 34.024784564971924\n",
      "acc: 35.62095928192139\n",
      "acc: 38.49003219604492\n",
      "acc: 40.759697914123535\n",
      "====================== Fed Server==========================\n",
      " Train: Round   3, Avg Accuracy 39.238 | Avg Loss 1.632\n",
      " Test: Round   3, Avg Accuracy 34.317 | Avg Loss 1.814\n",
      "==========================================================\n",
      "Epoch 3 finished in 00:02:01\n",
      "Epoch 3 finished. Total time: 515.83 seconds\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 52.394 \tLoss: 1.3918\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 3.186 \tLoss: 4.0836\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 39.989 \tLoss: 1.6252\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 38.935 \tLoss: 1.6814\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 39.386 \tLoss: 1.6108\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 34.213 \tLoss: 1.9272\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 39.334 \tLoss: 1.6228\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 38.530 \tLoss: 1.7614\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 40.758 \tLoss: 1.5998\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 27.404 \tLoss: 2.0407\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 40.191 \tLoss: 1.6309\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 29.984 \tLoss: 1.9195\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 41.581 \tLoss: 1.6067\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 38.881 \tLoss: 1.6438\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 39.706 \tLoss: 1.5928\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 40.046 \tLoss: 1.5394\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 40.970 \tLoss: 1.5921\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 28.495 \tLoss: 2.1825\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 42.323 \tLoss: 1.5802\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 38.800 \tLoss: 1.7648\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 41.386 \tLoss: 1.5880\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 37.002 \tLoss: 1.6914\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 40.924 \tLoss: 1.5872\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 38.389 \tLoss: 1.8640\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 40.570 \tLoss: 1.5708\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 30.725 \tLoss: 1.9283\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 41.052 \tLoss: 1.5931\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 39.150 \tLoss: 1.6337\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 51.641 \tLoss: 1.3771\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 9.988 \tLoss: 4.8473\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 40.393 \tLoss: 1.6110\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 29.613 \tLoss: 2.0018\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 40.535 \tLoss: 1.6097\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 37.042 \tLoss: 1.6881\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 39.589 \tLoss: 1.6109\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 32.018 \tLoss: 1.7965\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 40.731 \tLoss: 1.6091\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 31.822 \tLoss: 2.0957\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 39.511 \tLoss: 1.6185\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client2 Test =>                   \tAcc: 40.578 \tLoss: 1.5437\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round   4, Avg Accuracy 41.648 | Avg Loss 1.581\n",
      " Test: Round   4, Avg Accuracy 32.276 | Avg Loss 2.097\n",
      "==========================================================\n",
      "idxs_users [ 0  7 18  1 16  5  6 15  9 17 10  3 13  4 19 11 12 14  8  2]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 18, 16, 5, 6, 15, 9, 17, 10, 3, 13, 4, 19, 11, 12, 14, 8, 2]\n",
      "fedserver选择的客户端index: [1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "acc: 38.934536933898926\n",
      "acc: 34.213361740112305\n",
      "acc: 27.404364109039307\n",
      "acc: 29.98383617401123\n",
      "acc: 38.88065719604492\n",
      "acc: 40.04579734802246\n",
      "acc: 28.495420455932617\n",
      "acc: 38.799838066101074\n",
      "acc: 37.00161647796631\n",
      "acc: 38.38900852203369\n",
      "acc: 30.724676609039307\n",
      "acc: 39.15005397796631\n",
      "acc: 9.987877130508423\n",
      "acc: 29.613415718078613\n",
      "acc: 37.042025566101074\n",
      "acc: 32.01778030395508\n",
      "acc: 31.822467803955078\n",
      "acc: 40.57785511016846\n",
      "====================== Fed Server==========================\n",
      " Train: Round   4, Avg Accuracy 41.648 | Avg Loss 1.581\n",
      " Test: Round   4, Avg Accuracy 33.505 | Avg Loss 1.988\n",
      "==========================================================\n",
      "Epoch 4 finished in 00:02:01\n",
      "Epoch 4 finished. Total time: 637.18 seconds\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 49.915 \tLoss: 1.4521\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 9.247 \tLoss: 4.6627\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 41.395 \tLoss: 1.5681\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 42.612 \tLoss: 1.5411\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 43.056 \tLoss: 1.5551\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 42.928 \tLoss: 1.7207\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 43.523 \tLoss: 1.5500\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 36.651 \tLoss: 1.8054\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 41.937 \tLoss: 1.5426\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 40.187 \tLoss: 1.5758\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 43.304 \tLoss: 1.5428\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 34.557 \tLoss: 1.7197\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 42.215 \tLoss: 1.5715\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 42.120 \tLoss: 1.6162\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 41.517 \tLoss: 1.5511\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 31.156 \tLoss: 2.1453\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 42.406 \tLoss: 1.5629\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 39.547 \tLoss: 1.6686\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 41.369 \tLoss: 1.5711\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 39.446 \tLoss: 1.6432\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 43.442 \tLoss: 1.5378\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 37.258 \tLoss: 1.6470\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 42.080 \tLoss: 1.5719\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 43.487 \tLoss: 1.5927\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 43.739 \tLoss: 1.5404\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 39.891 \tLoss: 1.6359\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 40.673 \tLoss: 1.5511\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 28.772 \tLoss: 2.2128\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 43.481 \tLoss: 1.5347\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 32.584 \tLoss: 1.7480\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 42.638 \tLoss: 1.5483\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 42.046 \tLoss: 1.7240\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 41.615 \tLoss: 1.5683\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 40.463 \tLoss: 1.6155\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 41.645 \tLoss: 1.5480\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 40.638 \tLoss: 1.6834\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 41.703 \tLoss: 1.5475\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 45.562 \tLoss: 1.4856\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 50.738 \tLoss: 1.4303\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client0 Test =>                   \tAcc: 42.666 \tLoss: 1.4769\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round   5, Avg Accuracy 43.119 | Avg Loss 1.542\n",
      " Test: Round   5, Avg Accuracy 39.218 | Avg Loss 1.692\n",
      "==========================================================\n",
      "idxs_users [19  5  6 18 13 11  7  9 14  1 10  3  4  2 17 16 15 12  8  0]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 6, 18, 13, 11, 7, 9, 14, 1, 10, 3, 4, 2, 17, 15, 12, 8, 0]\n",
      "fedserver选择的客户端index: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19]\n",
      "acc: 42.611799240112305\n",
      "acc: 42.928340911865234\n",
      "acc: 36.651400566101074\n",
      "acc: 40.18723011016846\n",
      "acc: 34.55684280395508\n",
      "acc: 42.120150566101074\n",
      "acc: 31.15571117401123\n",
      "acc: 39.54741382598877\n",
      "acc: 39.44639015197754\n",
      "acc: 37.25754261016846\n",
      "acc: 43.487338066101074\n",
      "acc: 39.89089393615723\n",
      "acc: 28.771551609039307\n",
      "acc: 32.58351278305054\n",
      "acc: 40.463361740112305\n",
      "acc: 40.63846969604492\n",
      "acc: 45.561692237854004\n",
      "acc: 42.66567897796631\n",
      "====================== Fed Server==========================\n",
      " Train: Round   5, Avg Accuracy 43.119 | Avg Loss 1.542\n",
      " Test: Round   5, Avg Accuracy 38.918 | Avg Loss 1.696\n",
      "==========================================================\n",
      "Epoch 5 finished in 00:02:02\n",
      "Epoch 5 finished. Total time: 759.35 seconds\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 42.585 \tLoss: 1.5316\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 37.803 \tLoss: 1.7789\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 42.128 \tLoss: 1.5339\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 36.470 \tLoss: 1.6466\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 43.745 \tLoss: 1.5296\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 41.420 \tLoss: 1.6340\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 44.012 \tLoss: 1.4992\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 40.073 \tLoss: 1.5567\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 43.824 \tLoss: 1.5119\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 37.742 \tLoss: 1.9273\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 44.081 \tLoss: 1.5086\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 44.895 \tLoss: 1.6083\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 42.392 \tLoss: 1.5306\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 44.376 \tLoss: 1.6033\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 42.523 \tLoss: 1.5380\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 38.072 \tLoss: 1.6665\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 43.290 \tLoss: 1.5225\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 37.742 \tLoss: 1.7718\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 44.501 \tLoss: 1.5037\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 34.483 \tLoss: 1.8436\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 45.335 \tLoss: 1.5164\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 45.447 \tLoss: 1.5151\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 43.681 \tLoss: 1.5269\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 43.763 \tLoss: 1.5810\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 42.879 \tLoss: 1.5467\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 40.517 \tLoss: 1.5657\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 44.667 \tLoss: 1.5151\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 48.498 \tLoss: 1.4394\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 43.015 \tLoss: 1.5133\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 39.366 \tLoss: 1.7424\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 44.931 \tLoss: 1.5214\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 43.474 \tLoss: 1.6132\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 53.968 \tLoss: 1.2987\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 10.904 \tLoss: 4.1410\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 44.019 \tLoss: 1.5202\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 37.803 \tLoss: 1.6530\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 52.282 \tLoss: 1.3187\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 2.579 \tLoss: 4.8667\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 45.283 \tLoss: 1.4954\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client17 Test =>                   \tAcc: 48.202 \tLoss: 1.3586\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round   6, Avg Accuracy 44.657 | Avg Loss 1.499\n",
      " Test: Round   6, Avg Accuracy 37.353 | Avg Loss 1.951\n",
      "==========================================================\n",
      "idxs_users [12 11  7 13  9  8  1  2  3 18 10  5 15  4 16  6  0 14 19 17]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 11, 7, 13, 9, 8, 1, 2, 3, 18, 10, 5, 15, 4, 16, 6, 14, 17]\n",
      "fedserver选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 19]\n",
      "acc: 37.80307102203369\n",
      "acc: 36.469558238983154\n",
      "acc: 41.41971969604492\n",
      "acc: 40.072736740112305\n",
      "acc: 37.74245643615723\n",
      "acc: 44.894935607910156\n",
      "acc: 44.376346588134766\n",
      "acc: 38.07246780395508\n",
      "acc: 37.74245643615723\n",
      "acc: 34.48275852203369\n",
      "acc: 45.447197914123535\n",
      "acc: 43.76346969604492\n",
      "acc: 40.51724147796631\n",
      "acc: 48.498114585876465\n",
      "acc: 39.36557102203369\n",
      "acc: 43.47386837005615\n",
      "acc: 37.80307102203369\n",
      "acc: 48.201778411865234\n",
      "====================== Fed Server==========================\n",
      " Train: Round   6, Avg Accuracy 44.657 | Avg Loss 1.499\n",
      " Test: Round   6, Avg Accuracy 41.119 | Avg Loss 1.639\n",
      "==========================================================\n",
      "Epoch 6 finished in 00:02:01\n",
      "Epoch 6 finished. Total time: 881.33 seconds\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 45.248 \tLoss: 1.4825\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 40.564 \tLoss: 1.6212\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 44.993 \tLoss: 1.4974\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 29.182 \tLoss: 2.2607\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 44.244 \tLoss: 1.4775\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 40.638 \tLoss: 1.7108\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 46.602 \tLoss: 1.4626\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 37.938 \tLoss: 1.6796\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 44.676 \tLoss: 1.4785\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 41.325 \tLoss: 1.7094\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 46.011 \tLoss: 1.4754\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 33.250 \tLoss: 2.0996\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 46.068 \tLoss: 1.4458\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 43.299 \tLoss: 1.5203\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 45.620 \tLoss: 1.4724\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 45.602 \tLoss: 1.5523\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 46.294 \tLoss: 1.4838\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 41.534 \tLoss: 1.6085\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 52.346 \tLoss: 1.3539\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 3.206 \tLoss: 6.1860\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 46.953 \tLoss: 1.4591\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 46.444 \tLoss: 1.4864\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 44.890 \tLoss: 1.4959\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 39.130 \tLoss: 1.7785\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 45.788 \tLoss: 1.4699\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 42.807 \tLoss: 1.5833\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 45.687 \tLoss: 1.4902\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 33.567 \tLoss: 1.8268\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 44.223 \tLoss: 1.4845\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 40.537 \tLoss: 1.5542\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 43.911 \tLoss: 1.4972\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 41.049 \tLoss: 1.6072\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 52.282 \tLoss: 1.3717\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 8.149 \tLoss: 4.8955\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 45.205 \tLoss: 1.4719\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 43.400 \tLoss: 1.6510\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 46.898 \tLoss: 1.4702\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 36.382 \tLoss: 1.6812\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 44.908 \tLoss: 1.5082\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client2 Test =>                   \tAcc: 46.949 \tLoss: 1.4418\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round   7, Avg Accuracy 46.142 | Avg Loss 1.467\n",
      " Test: Round   7, Avg Accuracy 38.357 | Avg Loss 1.938\n",
      "==========================================================\n",
      "idxs_users [ 8 11 12 18 14  4 13  6  3 19 10 15 16  7  1  5  0 17  9  2]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 11, 12, 18, 14, 4, 13, 6, 3, 10, 15, 16, 7, 1, 5, 17, 9, 2]\n",
      "fedserver选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 17, 18, 19]\n",
      "acc: 40.564385414123535\n",
      "acc: 29.182381629943848\n",
      "acc: 40.63846969604492\n",
      "acc: 37.93776893615723\n",
      "acc: 41.32543087005615\n",
      "acc: 33.25026893615723\n",
      "acc: 43.298760414123535\n",
      "acc: 45.60210132598877\n",
      "acc: 41.534213066101074\n",
      "acc: 46.443965911865234\n",
      "acc: 39.129849433898926\n",
      "acc: 42.807111740112305\n",
      "acc: 33.566810607910156\n",
      "acc: 40.53744602203369\n",
      "acc: 41.049299240112305\n",
      "acc: 43.399784088134766\n",
      "acc: 36.382004737854004\n",
      "acc: 46.94908428192139\n",
      "====================== Fed Server==========================\n",
      " Train: Round   7, Avg Accuracy 46.142 | Avg Loss 1.467\n",
      " Test: Round   7, Avg Accuracy 40.200 | Avg Loss 1.687\n",
      "==========================================================\n",
      "Epoch 7 finished in 00:02:02\n",
      "Epoch 7 finished. Total time: 1003.60 seconds\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 47.904 \tLoss: 1.4125\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 49.104 \tLoss: 1.4196\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 46.859 \tLoss: 1.4645\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 41.016 \tLoss: 1.6784\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 46.039 \tLoss: 1.4585\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 43.292 \tLoss: 1.5240\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 50.591 \tLoss: 1.4391\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 6.957 \tLoss: 4.3821\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 48.281 \tLoss: 1.4186\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 34.402 \tLoss: 1.7842\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 52.341 \tLoss: 1.4044\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 4.654 \tLoss: 4.6349\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 44.768 \tLoss: 1.4829\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 44.942 \tLoss: 1.5410\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 46.303 \tLoss: 1.4512\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 48.572 \tLoss: 1.4582\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 47.440 \tLoss: 1.4356\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 45.427 \tLoss: 1.4402\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 45.696 \tLoss: 1.4605\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 41.575 \tLoss: 1.5385\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 47.084 \tLoss: 1.4306\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 37.763 \tLoss: 1.7957\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 46.085 \tLoss: 1.4581\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 42.221 \tLoss: 1.5560\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 46.824 \tLoss: 1.4268\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 44.275 \tLoss: 1.6864\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 48.261 \tLoss: 1.4282\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 44.269 \tLoss: 1.4471\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 46.889 \tLoss: 1.4422\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 30.846 \tLoss: 2.1115\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 48.031 \tLoss: 1.4223\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 40.558 \tLoss: 1.7749\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 46.558 \tLoss: 1.4445\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 41.164 \tLoss: 1.6061\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 48.001 \tLoss: 1.4329\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 43.494 \tLoss: 1.5251\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 45.131 \tLoss: 1.4551\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 41.534 \tLoss: 1.5368\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 46.011 \tLoss: 1.4697\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client14 Test =>                   \tAcc: 52.438 \tLoss: 1.3228\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round   8, Avg Accuracy 47.255 | Avg Loss 1.442\n",
      " Test: Round   8, Avg Accuracy 38.654 | Avg Loss 1.923\n",
      "==========================================================\n",
      "idxs_users [16  3  5 19 18  0  7  8 17 12  9  1  6 13 11 10  2  4 15 14]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16, 3, 5, 18, 0, 7, 8, 17, 12, 9, 1, 6, 11, 10, 2, 4, 15, 14]\n",
      "fedserver选择的客户端index: [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19]\n",
      "acc: 49.10425662994385\n",
      "acc: 41.015625\n",
      "acc: 43.292025566101074\n",
      "acc: 34.401939392089844\n",
      "acc: 4.653825402259827\n",
      "acc: 44.94207954406738\n",
      "acc: 48.572197914123535\n",
      "acc: 45.42699337005615\n",
      "acc: 41.574623107910156\n",
      "acc: 37.762661933898926\n",
      "acc: 42.221174240112305\n",
      "acc: 44.275322914123535\n",
      "acc: 30.845905303955078\n",
      "acc: 40.557650566101074\n",
      "acc: 41.16379261016846\n",
      "acc: 43.494072914123535\n",
      "acc: 41.534213066101074\n",
      "acc: 52.43803882598877\n",
      "====================== Fed Server==========================\n",
      " Train: Round   8, Avg Accuracy 47.255 | Avg Loss 1.442\n",
      " Test: Round   8, Avg Accuracy 40.404 | Avg Loss 1.774\n",
      "==========================================================\n",
      "Epoch 8 finished in 00:02:00\n",
      "Epoch 8 finished. Total time: 1124.58 seconds\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 47.190 \tLoss: 1.4224\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 42.949 \tLoss: 1.6573\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 47.139 \tLoss: 1.4234\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 43.373 \tLoss: 1.5231\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 48.591 \tLoss: 1.4032\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 42.942 \tLoss: 1.5098\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 50.972 \tLoss: 1.4714\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 8.250 \tLoss: 4.1908\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 47.904 \tLoss: 1.4249\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 45.622 \tLoss: 1.5690\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 47.006 \tLoss: 1.4176\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 44.329 \tLoss: 1.5196\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 47.017 \tLoss: 1.4387\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 43.885 \tLoss: 1.5057\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 48.185 \tLoss: 1.4056\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 43.770 \tLoss: 1.5664\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 51.261 \tLoss: 1.4378\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 4.984 \tLoss: 4.1104\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 47.833 \tLoss: 1.4234\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 34.072 \tLoss: 2.0176\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 48.323 \tLoss: 1.4188\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 43.649 \tLoss: 1.5970\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 47.059 \tLoss: 1.4350\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 47.953 \tLoss: 1.5275\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 47.778 \tLoss: 1.4296\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 38.625 \tLoss: 2.0043\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 49.253 \tLoss: 1.4019\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 41.905 \tLoss: 1.4733\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 49.515 \tLoss: 1.4001\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 36.591 \tLoss: 1.8171\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 46.461 \tLoss: 1.4411\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 41.379 \tLoss: 1.6358\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 48.555 \tLoss: 1.4021\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 45.730 \tLoss: 1.6862\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 48.139 \tLoss: 1.4087\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 44.525 \tLoss: 1.4654\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 48.837 \tLoss: 1.4234\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 45.528 \tLoss: 1.4747\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 45.970 \tLoss: 1.4320\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client5 Test =>                   \tAcc: 53.852 \tLoss: 1.3098\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round   9, Avg Accuracy 48.149 | Avg Loss 1.423\n",
      " Test: Round   9, Avg Accuracy 41.320 | Avg Loss 1.750\n",
      "==========================================================\n",
      "idxs_users [10  9 13 19 12 15 14 16  0 11  3  2  7  4 18  8  6 17  1  5]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 9, 13, 19, 12, 14, 16, 11, 3, 2, 7, 4, 18, 8, 6, 17, 1, 5]\n",
      "fedserver选择的客户端index: [0, 1, 2, 3, 4, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "acc: 42.94854545593262\n",
      "acc: 43.37284469604492\n",
      "acc: 42.941810607910156\n",
      "acc: 8.250269412994385\n",
      "acc: 45.62230587005615\n",
      "acc: 43.884697914123535\n",
      "acc: 43.77020454406738\n",
      "acc: 34.07192897796631\n",
      "acc: 43.64897632598877\n",
      "acc: 47.95258617401123\n",
      "acc: 38.62473011016846\n",
      "acc: 41.90463352203369\n",
      "acc: 36.590786933898926\n",
      "acc: 41.379310607910156\n",
      "acc: 45.730064392089844\n",
      "acc: 44.52451515197754\n",
      "acc: 45.52801704406738\n",
      "acc: 53.852370262145996\n",
      "====================== Fed Server==========================\n",
      " Train: Round   9, Avg Accuracy 48.149 | Avg Loss 1.423\n",
      " Test: Round   9, Avg Accuracy 41.367 | Avg Loss 1.752\n",
      "==========================================================\n",
      "Epoch 9 finished in 00:02:00\n",
      "Epoch 9 finished. Total time: 1245.31 seconds\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 48.235 \tLoss: 1.3999\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 41.810 \tLoss: 1.5366\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 48.665 \tLoss: 1.4089\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 42.161 \tLoss: 1.6686\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 49.010 \tLoss: 1.3879\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 42.356 \tLoss: 1.5890\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 49.141 \tLoss: 1.3815\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 44.511 \tLoss: 1.5812\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 48.968 \tLoss: 1.3803\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 40.187 \tLoss: 1.6093\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 48.442 \tLoss: 1.4204\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 49.023 \tLoss: 1.4522\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 49.315 \tLoss: 1.3819\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 44.780 \tLoss: 1.6381\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 47.470 \tLoss: 1.4129\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 46.114 \tLoss: 1.4614\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 51.248 \tLoss: 1.3645\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 48.161 \tLoss: 1.3978\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 50.005 \tLoss: 1.3805\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 42.949 \tLoss: 1.4824\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 49.253 \tLoss: 1.3873\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 43.023 \tLoss: 1.5139\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 48.477 \tLoss: 1.4158\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 48.963 \tLoss: 1.3699\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 48.295 \tLoss: 1.3991\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 42.538 \tLoss: 1.6138\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 48.826 \tLoss: 1.3813\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 43.279 \tLoss: 1.7548\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 52.528 \tLoss: 1.4336\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 10.224 \tLoss: 4.6468\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 50.078 \tLoss: 1.3620\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 42.416 \tLoss: 1.5676\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 48.442 \tLoss: 1.4083\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 44.895 \tLoss: 1.4954\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 50.542 \tLoss: 1.3561\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 47.380 \tLoss: 1.4373\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 53.362 \tLoss: 1.4144\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 2.990 \tLoss: 4.9642\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 48.038 \tLoss: 1.4048\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client7 Test =>                   \tAcc: 53.341 \tLoss: 1.3084\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 3, 4, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  10, Avg Accuracy 49.417 | Avg Loss 1.394\n",
      " Test: Round  10, Avg Accuracy 40.218 | Avg Loss 1.902\n",
      "==========================================================\n",
      "idxs_users [12 11  2 17  9  3  6  5  4 10  8 14  1 18 19 16 15 13  0  7]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 11, 2, 17, 9, 3, 6, 5, 4, 10, 8, 14, 1, 18, 19, 15, 13, 7]\n",
      "fedserver选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 19]\n",
      "acc: 41.81034469604492\n",
      "acc: 42.160560607910156\n",
      "acc: 42.355873107910156\n",
      "acc: 44.51104545593262\n",
      "acc: 40.18723011016846\n",
      "acc: 49.0234375\n",
      "acc: 44.780442237854004\n",
      "acc: 46.11395454406738\n",
      "acc: 48.16136837005615\n",
      "acc: 42.94854545593262\n",
      "acc: 43.022629737854004\n",
      "acc: 48.962822914123535\n",
      "acc: 42.537715911865234\n",
      "acc: 43.27855587005615\n",
      "acc: 10.223599195480347\n",
      "acc: 44.894935607910156\n",
      "acc: 47.38011837005615\n",
      "acc: 53.34051704406738\n",
      "====================== Fed Server==========================\n",
      " Train: Round  10, Avg Accuracy 49.417 | Avg Loss 1.394\n",
      " Test: Round  10, Avg Accuracy 43.094 | Avg Loss 1.698\n",
      "==========================================================\n",
      "Epoch 10 finished in 00:02:00\n",
      "Epoch 10 finished. Total time: 1366.19 seconds\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 50.092 \tLoss: 1.3789\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 41.972 \tLoss: 1.5848\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 49.228 \tLoss: 1.3746\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 43.905 \tLoss: 1.5545\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 49.527 \tLoss: 1.3633\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 45.892 \tLoss: 1.4227\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 49.331 \tLoss: 1.3776\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 41.595 \tLoss: 1.7405\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 50.928 \tLoss: 1.3529\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 47.690 \tLoss: 1.3684\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 48.555 \tLoss: 1.3903\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 43.959 \tLoss: 1.5419\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 50.662 \tLoss: 1.4846\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 5.610 \tLoss: 4.5725\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 50.347 \tLoss: 1.3330\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 44.141 \tLoss: 1.5486\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 49.115 \tLoss: 1.3650\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 47.771 \tLoss: 1.4348\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 48.426 \tLoss: 1.3542\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 49.475 \tLoss: 1.4353\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 51.392 \tLoss: 1.3583\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 44.296 \tLoss: 1.5422\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 48.925 \tLoss: 1.3674\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 40.147 \tLoss: 1.6592\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 49.600 \tLoss: 1.3542\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 42.248 \tLoss: 1.6663\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 50.616 \tLoss: 1.3413\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 47.495 \tLoss: 1.4081\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 48.959 \tLoss: 1.3766\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 39.130 \tLoss: 1.9300\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 50.758 \tLoss: 1.3636\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 39.056 \tLoss: 1.8001\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 50.630 \tLoss: 1.3707\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 48.161 \tLoss: 1.4155\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 49.076 \tLoss: 1.3900\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 43.528 \tLoss: 1.5064\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 53.058 \tLoss: 1.4524\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 5.354 \tLoss: 4.7627\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 49.148 \tLoss: 1.3578\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client16 Test =>                   \tAcc: 54.863 \tLoss: 1.2177\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  11, Avg Accuracy 49.919 | Avg Loss 1.375\n",
      " Test: Round  11, Avg Accuracy 42.882 | Avg Loss 1.697\n",
      "==========================================================\n",
      "idxs_users [ 7  5 15 12 10 14 19 13  3  1  6  2  9  4 18  8 17 11  0 16]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 5, 15, 12, 10, 14, 13, 1, 6, 2, 9, 4, 18, 8, 17, 11, 0, 16]\n",
      "fedserver选择的客户端index: [0, 1, 2, 3, 4, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "acc: 41.97198295593262\n",
      "acc: 43.904903411865234\n",
      "acc: 45.89170265197754\n",
      "acc: 41.59482765197754\n",
      "acc: 47.689924240112305\n",
      "acc: 43.95878219604492\n",
      "acc: 44.140625\n",
      "acc: 49.474677085876465\n",
      "acc: 44.295528411865234\n",
      "acc: 40.14682102203369\n",
      "acc: 42.248114585876465\n",
      "acc: 47.494611740112305\n",
      "acc: 39.129849433898926\n",
      "acc: 39.05576515197754\n",
      "acc: 48.16136837005615\n",
      "acc: 43.527748107910156\n",
      "acc: 5.354256451129913\n",
      "acc: 54.86260795593262\n",
      "====================== Fed Server==========================\n",
      " Train: Round  11, Avg Accuracy 49.919 | Avg Loss 1.375\n",
      " Test: Round  11, Avg Accuracy 42.384 | Avg Loss 1.728\n",
      "==========================================================\n",
      "Epoch 11 finished in 00:02:00\n",
      "Epoch 11 finished. Total time: 1487.13 seconds\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 49.926 \tLoss: 1.3553\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 43.258 \tLoss: 1.5066\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 52.001 \tLoss: 1.3192\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 42.241 \tLoss: 1.7118\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 48.720 \tLoss: 1.3632\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 48.256 \tLoss: 1.5676\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 49.839 \tLoss: 1.3560\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 50.418 \tLoss: 1.4518\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 50.659 \tLoss: 1.3588\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 44.585 \tLoss: 1.6590\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 52.022 \tLoss: 1.3392\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 43.272 \tLoss: 1.5786\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 53.065 \tLoss: 1.4591\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 8.661 \tLoss: 4.4136\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 50.216 \tLoss: 1.3350\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 45.191 \tLoss: 1.5174\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 51.103 \tLoss: 1.3087\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 49.320 \tLoss: 1.3547\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 51.939 \tLoss: 1.3215\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 52.815 \tLoss: 1.3128\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 51.250 \tLoss: 1.3267\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 41.797 \tLoss: 1.7431\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 50.807 \tLoss: 1.3632\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 42.147 \tLoss: 1.6552\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 52.217 \tLoss: 1.3157\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 51.859 \tLoss: 1.3873\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 52.624 \tLoss: 1.3206\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 48.673 \tLoss: 1.4628\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 53.111 \tLoss: 1.3016\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 47.636 \tLoss: 1.4029\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 49.952 \tLoss: 1.3626\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 41.999 \tLoss: 1.6336\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 50.287 \tLoss: 1.3513\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 42.006 \tLoss: 1.6456\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 51.114 \tLoss: 1.3572\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 47.515 \tLoss: 1.3945\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 51.999 \tLoss: 1.4648\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 11.436 \tLoss: 4.8026\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 51.523 \tLoss: 1.3327\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client6 Test =>                   \tAcc: 54.634 \tLoss: 1.3010\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 3, 4, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  12, Avg Accuracy 51.219 | Avg Loss 1.351\n",
      " Test: Round  12, Avg Accuracy 44.430 | Avg Loss 1.707\n",
      "==========================================================\n",
      "idxs_users [ 5  2  3  7 11 15  0  9 13  4 18 14 16 10 17  1 12  8 19  6]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 2, 3, 7, 11, 15, 0, 9, 4, 18, 14, 16, 10, 17, 1, 12, 8, 6]\n",
      "fedserver选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19]\n",
      "acc: 43.25835132598877\n",
      "acc: 42.241379737854004\n",
      "acc: 48.25565719604492\n",
      "acc: 50.417564392089844\n",
      "acc: 44.585129737854004\n",
      "acc: 43.27182102203369\n",
      "acc: 8.661099195480347\n",
      "acc: 45.19127178192139\n",
      "acc: 52.81519412994385\n",
      "acc: 41.796875\n",
      "acc: 42.147090911865234\n",
      "acc: 51.85883617401123\n",
      "acc: 48.673221588134766\n",
      "acc: 47.63604545593262\n",
      "acc: 41.99892234802246\n",
      "acc: 42.00565719604492\n",
      "acc: 47.514817237854004\n",
      "acc: 54.633620262145996\n",
      "====================== Fed Server==========================\n",
      " Train: Round  12, Avg Accuracy 51.219 | Avg Loss 1.351\n",
      " Test: Round  12, Avg Accuracy 44.276 | Avg Loss 1.686\n",
      "==========================================================\n",
      "Epoch 12 finished in 00:02:01\n",
      "Epoch 12 finished. Total time: 1608.30 seconds\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 53.249 \tLoss: 1.2899\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 43.770 \tLoss: 1.6153\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 50.434 \tLoss: 1.3310\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 46.033 \tLoss: 1.4889\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 54.129 \tLoss: 1.4431\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 4.027 \tLoss: 4.9673\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 53.024 \tLoss: 1.3029\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 49.165 \tLoss: 1.4635\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 50.616 \tLoss: 1.3535\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 42.592 \tLoss: 1.5516\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 53.235 \tLoss: 1.4731\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 8.661 \tLoss: 4.6135\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 52.780 \tLoss: 1.3039\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 51.542 \tLoss: 1.2682\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 51.670 \tLoss: 1.3324\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 42.686 \tLoss: 1.5553\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 52.456 \tLoss: 1.2915\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 47.555 \tLoss: 1.4877\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 50.005 \tLoss: 1.3210\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 46.761 \tLoss: 1.3907\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 52.360 \tLoss: 1.3116\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 46.127 \tLoss: 1.4861\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 52.985 \tLoss: 1.3102\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 44.289 \tLoss: 1.5930\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 51.861 \tLoss: 1.3153\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 42.120 \tLoss: 1.7253\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 51.075 \tLoss: 1.3295\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 46.835 \tLoss: 1.5045\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 53.803 \tLoss: 1.2847\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 47.548 \tLoss: 1.4355\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 52.574 \tLoss: 1.2946\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 53.947 \tLoss: 1.3054\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 52.403 \tLoss: 1.3153\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 46.558 \tLoss: 1.4641\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 52.737 \tLoss: 1.3222\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 49.239 \tLoss: 1.3624\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 53.008 \tLoss: 1.3049\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 42.848 \tLoss: 1.6115\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 52.700 \tLoss: 1.3145\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client3 Test =>                   \tAcc: 56.937 \tLoss: 1.2207\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  13, Avg Accuracy 52.355 | Avg Loss 1.327\n",
      " Test: Round  13, Avg Accuracy 42.713 | Avg Loss 1.834\n",
      "==========================================================\n",
      "idxs_users [17  5  0  8 14 19 10  7 16 15 12 18  9  2 13  4 11  1  6  3]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 8, 14, 19, 10, 7, 16, 15, 12, 18, 9, 2, 13, 4, 11, 1, 6, 3]\n",
      "fedserver选择的客户端index: [1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "acc: 46.033135414123535\n",
      "acc: 49.164870262145996\n",
      "acc: 42.59159469604492\n",
      "acc: 8.661099195480347\n",
      "acc: 51.54229545593262\n",
      "acc: 42.68588352203369\n",
      "acc: 47.55522632598877\n",
      "acc: 46.76050662994385\n",
      "acc: 46.127424240112305\n",
      "acc: 44.28879261016846\n",
      "acc: 42.120150566101074\n",
      "acc: 46.834590911865234\n",
      "acc: 47.54849147796631\n",
      "acc: 53.946659088134766\n",
      "acc: 46.55845928192139\n",
      "acc: 49.23895454406738\n",
      "acc: 42.84752178192139\n",
      "acc: 56.93696117401123\n",
      "====================== Fed Server==========================\n",
      " Train: Round  13, Avg Accuracy 52.355 | Avg Loss 1.327\n",
      " Test: Round  13, Avg Accuracy 45.080 | Avg Loss 1.640\n",
      "==========================================================\n",
      "Epoch 13 finished in 00:02:01\n",
      "Epoch 13 finished. Total time: 1729.58 seconds\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 53.072 \tLoss: 1.2878\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 50.269 \tLoss: 1.3725\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 52.293 \tLoss: 1.5057\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 11.827 \tLoss: 4.2727\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 52.468 \tLoss: 1.4839\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 9.537 \tLoss: 4.2009\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 53.006 \tLoss: 1.3082\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 50.141 \tLoss: 1.4627\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 54.308 \tLoss: 1.2641\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 45.777 \tLoss: 1.5447\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 52.865 \tLoss: 1.2933\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 47.340 \tLoss: 1.4605\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 52.553 \tLoss: 1.2997\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 45.898 \tLoss: 1.5606\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 53.042 \tLoss: 1.2938\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 48.613 \tLoss: 1.4153\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 54.517 \tLoss: 1.2685\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 55.300 \tLoss: 1.2148\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 53.176 \tLoss: 1.2957\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 51.825 \tLoss: 1.3198\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 53.458 \tLoss: 1.3056\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 50.350 \tLoss: 1.3125\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 53.194 \tLoss: 1.2911\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 49.589 \tLoss: 1.3305\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 54.207 \tLoss: 1.2809\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 44.720 \tLoss: 1.5563\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 54.334 \tLoss: 1.2757\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 51.111 \tLoss: 1.4183\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 52.920 \tLoss: 1.2711\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 49.609 \tLoss: 1.4270\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 53.311 \tLoss: 1.2814\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 48.161 \tLoss: 1.5043\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 53.054 \tLoss: 1.2987\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 45.602 \tLoss: 1.4586\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 52.560 \tLoss: 1.3189\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 52.303 \tLoss: 1.2811\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 53.136 \tLoss: 1.2905\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 46.814 \tLoss: 1.5147\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 52.980 \tLoss: 1.2801\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client6 Test =>                   \tAcc: 54.108 \tLoss: 1.2724\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  14, Avg Accuracy 53.223 | Avg Loss 1.310\n",
      " Test: Round  14, Avg Accuracy 47.172 | Avg Loss 1.574\n",
      "==========================================================\n",
      "idxs_users [10 19  0  5 13 11 12 18  4  8 15 17  3  7 16  9  1 14  2  6]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 5, 13, 11, 12, 18, 4, 8, 15, 17, 3, 7, 16, 9, 1, 14, 2, 6]\n",
      "fedserver选择的客户端index: [0, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "acc: 50.26939678192139\n",
      "acc: 50.141432762145996\n",
      "acc: 45.77720928192139\n",
      "acc: 47.33970928192139\n",
      "acc: 45.8984375\n",
      "acc: 48.61260795593262\n",
      "acc: 55.300376892089844\n",
      "acc: 51.825161933898926\n",
      "acc: 50.350215911865234\n",
      "acc: 49.58917045593262\n",
      "acc: 44.71982765197754\n",
      "acc: 51.111260414123535\n",
      "acc: 49.609375\n",
      "acc: 48.16136837005615\n",
      "acc: 45.60210132598877\n",
      "acc: 52.303340911865234\n",
      "acc: 46.814385414123535\n",
      "acc: 54.10829734802246\n",
      "====================== Fed Server==========================\n",
      " Train: Round  14, Avg Accuracy 53.223 | Avg Loss 1.310\n",
      " Test: Round  14, Avg Accuracy 49.307 | Avg Loss 1.413\n",
      "==========================================================\n",
      "Epoch 14 finished in 00:02:01\n",
      "Epoch 14 finished. Total time: 1851.04 seconds\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 52.640 \tLoss: 1.2821\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 50.680 \tLoss: 1.4711\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 53.159 \tLoss: 1.2656\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 53.280 \tLoss: 1.2348\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 53.697 \tLoss: 1.4993\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 10.028 \tLoss: 3.9606\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 53.966 \tLoss: 1.2679\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 47.084 \tLoss: 1.4644\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 54.635 \tLoss: 1.2679\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 48.889 \tLoss: 1.4127\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 54.366 \tLoss: 1.2599\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 46.909 \tLoss: 1.5268\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 53.281 \tLoss: 1.2567\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 47.926 \tLoss: 1.5176\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 54.260 \tLoss: 1.2632\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 49.084 \tLoss: 1.5605\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 53.199 \tLoss: 1.2832\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 48.336 \tLoss: 1.4100\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 53.424 \tLoss: 1.2866\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 53.260 \tLoss: 1.3324\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 52.916 \tLoss: 1.2768\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 49.670 \tLoss: 1.3823\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 52.523 \tLoss: 1.2790\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 44.881 \tLoss: 1.5464\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 53.555 \tLoss: 1.2883\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 48.262 \tLoss: 1.4064\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 52.183 \tLoss: 1.3114\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 46.700 \tLoss: 1.5050\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 53.325 \tLoss: 1.2599\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 55.004 \tLoss: 1.3214\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 55.329 \tLoss: 1.2376\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 48.222 \tLoss: 1.3911\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 53.810 \tLoss: 1.2666\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 51.724 \tLoss: 1.4334\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 49.621 \tLoss: 1.5436\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 6.802 \tLoss: 4.5698\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 54.336 \tLoss: 1.2702\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 46.774 \tLoss: 1.4261\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 54.398 \tLoss: 1.2760\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client6 Test =>                   \tAcc: 57.671 \tLoss: 1.2347\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  15, Avg Accuracy 53.431 | Avg Loss 1.297\n",
      " Test: Round  15, Avg Accuracy 47.104 | Avg Loss 1.606\n",
      "==========================================================\n",
      "idxs_users [ 2  8  0 16  1 17  9 18 11  3 15 12  5 14  4 13 10 19  7  6]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 8, 16, 1, 9, 18, 11, 3, 15, 12, 5, 14, 4, 13, 10, 19, 7, 6]\n",
      "fedserver选择的客户端index: [0, 1, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "acc: 50.68022632598877\n",
      "acc: 53.279903411865234\n",
      "acc: 47.08378219604492\n",
      "acc: 48.888739585876465\n",
      "acc: 47.92564678192139\n",
      "acc: 49.084052085876465\n",
      "acc: 48.33647632598877\n",
      "acc: 53.259697914123535\n",
      "acc: 49.669989585876465\n",
      "acc: 44.881465911865234\n",
      "acc: 48.26239204406738\n",
      "acc: 46.69989204406738\n",
      "acc: 55.00404071807861\n",
      "acc: 48.22198295593262\n",
      "acc: 51.724138259887695\n",
      "acc: 6.802262902259827\n",
      "acc: 46.77397632598877\n",
      "acc: 57.67106628417969\n",
      "====================== Fed Server==========================\n",
      " Train: Round  15, Avg Accuracy 53.431 | Avg Loss 1.297\n",
      " Test: Round  15, Avg Accuracy 47.458 | Avg Loss 1.590\n",
      "==========================================================\n",
      "Epoch 15 finished in 00:02:01\n",
      "Epoch 15 finished. Total time: 1972.09 seconds\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 54.432 \tLoss: 1.2434\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 51.684 \tLoss: 1.2921\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 55.607 \tLoss: 1.2173\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 56.917 \tLoss: 1.2500\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 55.699 \tLoss: 1.2340\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 42.571 \tLoss: 1.7225\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 54.127 \tLoss: 1.2682\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 47.421 \tLoss: 1.5181\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 50.836 \tLoss: 1.5359\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 10.459 \tLoss: 4.4677\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 55.191 \tLoss: 1.2544\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 44.720 \tLoss: 1.4794\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 51.643 \tLoss: 1.5325\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 9.287 \tLoss: 4.6645\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 55.264 \tLoss: 1.2328\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 44.801 \tLoss: 1.5335\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 53.984 \tLoss: 1.2550\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 46.734 \tLoss: 1.4322\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 54.180 \tLoss: 1.2731\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 46.612 \tLoss: 1.5140\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 55.333 \tLoss: 1.2382\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 51.293 \tLoss: 1.3711\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 53.346 \tLoss: 1.2738\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 49.044 \tLoss: 1.3786\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 54.586 \tLoss: 1.2369\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 41.534 \tLoss: 1.6869\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 53.555 \tLoss: 1.2761\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 42.039 \tLoss: 1.6354\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 52.422 \tLoss: 1.2632\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 46.929 \tLoss: 1.6054\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 55.142 \tLoss: 1.2500\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 51.347 \tLoss: 1.3963\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 56.101 \tLoss: 1.2464\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 41.130 \tLoss: 1.6447\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 55.733 \tLoss: 1.2284\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 48.963 \tLoss: 1.5164\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 54.182 \tLoss: 1.2711\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 52.034 \tLoss: 1.3366\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 54.423 \tLoss: 1.2457\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client12 Test =>                   \tAcc: 56.668 \tLoss: 1.2304\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  16, Avg Accuracy 54.289 | Avg Loss 1.279\n",
      " Test: Round  16, Avg Accuracy 44.161 | Avg Loss 1.804\n",
      "==========================================================\n",
      "idxs_users [10  4  9  2 19  1  0 13 15  3  6  5  7 11  8 17 18 16 14 12]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 4, 9, 2, 1, 0, 13, 15, 3, 6, 7, 11, 8, 17, 18, 16, 14, 12]\n",
      "fedserver选择的客户端index: [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "acc: 51.68372821807861\n",
      "acc: 56.91675662994385\n",
      "acc: 42.57139015197754\n",
      "acc: 47.420528411865234\n",
      "acc: 44.71982765197754\n",
      "acc: 9.287446022033691\n",
      "acc: 44.80064678192139\n",
      "acc: 46.733567237854004\n",
      "acc: 46.612338066101074\n",
      "acc: 51.29310321807861\n",
      "acc: 41.534213066101074\n",
      "acc: 42.03933143615723\n",
      "acc: 46.928879737854004\n",
      "acc: 51.34698295593262\n",
      "acc: 41.13011837005615\n",
      "acc: 48.962822914123535\n",
      "acc: 52.03394412994385\n",
      "acc: 56.667564392089844\n",
      "====================== Fed Server==========================\n",
      " Train: Round  16, Avg Accuracy 54.289 | Avg Loss 1.279\n",
      " Test: Round  16, Avg Accuracy 45.705 | Avg Loss 1.657\n",
      "==========================================================\n",
      "Epoch 16 finished in 00:02:01\n",
      "Epoch 16 finished. Total time: 2093.21 seconds\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 56.482 \tLoss: 1.2270\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 51.994 \tLoss: 1.3908\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 55.568 \tLoss: 1.2252\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 44.471 \tLoss: 1.5269\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 53.716 \tLoss: 1.2488\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 52.324 \tLoss: 1.3341\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 55.722 \tLoss: 1.2169\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 45.952 \tLoss: 1.5385\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 53.665 \tLoss: 1.4848\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 4.048 \tLoss: 4.0472\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 56.167 \tLoss: 1.2249\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 51.488 \tLoss: 1.4255\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 57.955 \tLoss: 1.1969\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 50.801 \tLoss: 1.3707\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 54.848 \tLoss: 1.2507\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 46.619 \tLoss: 1.4920\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 56.514 \tLoss: 1.2181\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 47.717 \tLoss: 1.6095\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 55.060 \tLoss: 1.2448\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 56.095 \tLoss: 1.2150\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 57.229 \tLoss: 1.2053\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 45.723 \tLoss: 1.5442\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 54.517 \tLoss: 1.2393\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 55.024 \tLoss: 1.2287\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 54.393 \tLoss: 1.2501\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 40.383 \tLoss: 1.9657\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 56.608 \tLoss: 1.2162\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 52.324 \tLoss: 1.3434\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 55.306 \tLoss: 1.2326\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 44.080 \tLoss: 1.9285\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 51.873 \tLoss: 1.5168\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 8.836 \tLoss: 4.6971\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 54.722 \tLoss: 1.2468\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 50.828 \tLoss: 1.3778\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 53.619 \tLoss: 1.2470\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 53.320 \tLoss: 1.3377\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 55.528 \tLoss: 1.2270\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 47.030 \tLoss: 1.4045\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 57.146 \tLoss: 1.2096\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client13 Test =>                   \tAcc: 59.106 \tLoss: 1.1597\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  17, Avg Accuracy 55.332 | Avg Loss 1.256\n",
      " Test: Round  17, Avg Accuracy 47.172 | Avg Loss 1.648\n",
      "==========================================================\n",
      "idxs_users [ 2  1 15 18  0  6  4 12 16 14  7 10 11  8  9 19  3  5 17 13]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 1, 15, 18, 6, 4, 12, 16, 14, 7, 10, 11, 8, 9, 3, 5, 17, 13]\n",
      "fedserver选择的客户端index: [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19]\n",
      "acc: 51.993534088134766\n",
      "acc: 44.470635414123535\n",
      "acc: 52.32354545593262\n",
      "acc: 45.952317237854004\n",
      "acc: 51.48841571807861\n",
      "acc: 50.80145454406738\n",
      "acc: 46.619072914123535\n",
      "acc: 47.716864585876465\n",
      "acc: 56.095096588134766\n",
      "acc: 45.72332954406738\n",
      "acc: 55.024245262145996\n",
      "acc: 40.38254261016846\n",
      "acc: 52.32354545593262\n",
      "acc: 44.080010414123535\n",
      "acc: 50.82839393615723\n",
      "acc: 53.3203125\n",
      "acc: 47.029903411865234\n",
      "acc: 59.10560321807861\n",
      "====================== Fed Server==========================\n",
      " Train: Round  17, Avg Accuracy 55.332 | Avg Loss 1.256\n",
      " Test: Round  17, Avg Accuracy 49.738 | Avg Loss 1.455\n",
      "==========================================================\n",
      "Epoch 17 finished in 00:02:01\n",
      "Epoch 17 finished. Total time: 2214.37 seconds\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 56.569 \tLoss: 1.2092\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 43.332 \tLoss: 1.6839\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 52.656 \tLoss: 1.5252\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 6.176 \tLoss: 4.3410\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 55.411 \tLoss: 1.2149\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 52.633 \tLoss: 1.3937\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 55.393 \tLoss: 1.2098\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 51.037 \tLoss: 1.3522\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 57.004 \tLoss: 1.2074\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 48.384 \tLoss: 1.6705\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 57.245 \tLoss: 1.1863\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 46.969 \tLoss: 1.4669\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 55.710 \tLoss: 1.2110\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 50.532 \tLoss: 1.3412\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 55.623 \tLoss: 1.2282\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 49.353 \tLoss: 1.5140\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 55.938 \tLoss: 1.2357\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 50.155 \tLoss: 1.3927\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 56.450 \tLoss: 1.2169\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 50.882 \tLoss: 1.3676\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 55.283 \tLoss: 1.2216\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 50.862 \tLoss: 1.4234\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 55.901 \tLoss: 1.2001\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 48.909 \tLoss: 1.4305\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 56.992 \tLoss: 1.2174\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 45.508 \tLoss: 1.4968\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 57.624 \tLoss: 1.1963\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 42.107 \tLoss: 1.6939\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 53.660 \tLoss: 1.5008\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 6.391 \tLoss: 3.7236\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 55.839 \tLoss: 1.1994\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 52.054 \tLoss: 1.3938\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 54.903 \tLoss: 1.2167\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 49.071 \tLoss: 1.3478\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 56.631 \tLoss: 1.2102\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 51.253 \tLoss: 1.4697\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 55.733 \tLoss: 1.2304\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 43.629 \tLoss: 1.5939\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 53.686 \tLoss: 1.2377\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client5 Test =>                   \tAcc: 57.489 \tLoss: 1.1439\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  18, Avg Accuracy 55.713 | Avg Loss 1.244\n",
      " Test: Round  18, Avg Accuracy 44.238 | Avg Loss 1.732\n",
      "==========================================================\n",
      "idxs_users [11 19  1  2 12  9 10  7  3  4  8 13 18 17  0 16 15  6 14  5]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 1, 2, 9, 10, 7, 3, 4, 8, 13, 18, 17, 0, 16, 15, 6, 14, 5]\n",
      "fedserver选择的客户端index: [0, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "acc: 43.332435607910156\n",
      "acc: 52.63335132598877\n",
      "acc: 51.037177085876465\n",
      "acc: 46.96928882598877\n",
      "acc: 50.532057762145996\n",
      "acc: 49.353447914123535\n",
      "acc: 50.154903411865234\n",
      "acc: 50.88227367401123\n",
      "acc: 50.86206912994385\n",
      "acc: 48.90894412994385\n",
      "acc: 45.5078125\n",
      "acc: 42.10668087005615\n",
      "acc: 6.391433238983154\n",
      "acc: 52.05414867401123\n",
      "acc: 49.07058143615723\n",
      "acc: 51.25269412994385\n",
      "acc: 43.62877178192139\n",
      "acc: 57.489224433898926\n",
      "====================== Fed Server==========================\n",
      " Train: Round  18, Avg Accuracy 55.713 | Avg Loss 1.244\n",
      " Test: Round  18, Avg Accuracy 46.787 | Avg Loss 1.568\n",
      "==========================================================\n",
      "Epoch 18 finished in 00:02:01\n",
      "Epoch 18 finished. Total time: 2335.72 seconds\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 56.043 \tLoss: 1.1869\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 53.697 \tLoss: 1.3412\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 56.643 \tLoss: 1.1695\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 49.939 \tLoss: 1.3264\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 56.730 \tLoss: 1.1995\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 52.189 \tLoss: 1.2782\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 52.806 \tLoss: 1.5749\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 7.328 \tLoss: 4.7604\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 56.857 \tLoss: 1.1919\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 52.445 \tLoss: 1.3058\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 55.182 \tLoss: 1.2135\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 44.605 \tLoss: 1.5952\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 54.281 \tLoss: 1.5202\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 5.610 \tLoss: 3.9842\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 56.613 \tLoss: 1.1824\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 47.441 \tLoss: 1.4179\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 57.169 \tLoss: 1.1827\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 53.852 \tLoss: 1.2640\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 57.686 \tLoss: 1.1681\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 44.875 \tLoss: 1.5939\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 56.369 \tLoss: 1.1937\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 52.425 \tLoss: 1.3452\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 56.765 \tLoss: 1.1931\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 57.173 \tLoss: 1.2061\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 57.194 \tLoss: 1.1768\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 52.701 \tLoss: 1.3245\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 56.581 \tLoss: 1.1976\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 38.685 \tLoss: 1.6828\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 56.119 \tLoss: 1.1950\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 48.734 \tLoss: 1.4746\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 55.797 \tLoss: 1.2184\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 40.012 \tLoss: 1.8229\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 55.372 \tLoss: 1.2021\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 53.792 \tLoss: 1.2522\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 57.130 \tLoss: 1.1809\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 59.092 \tLoss: 1.1562\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 57.603 \tLoss: 1.2024\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 54.357 \tLoss: 1.3276\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 55.473 \tLoss: 1.2178\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client5 Test =>                   \tAcc: 58.230 \tLoss: 1.1359\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  19, Avg Accuracy 56.221 | Avg Loss 1.228\n",
      " Test: Round  19, Avg Accuracy 45.822 | Avg Loss 1.720\n",
      "==========================================================\n",
      "idxs_users [ 6 13 10 19  7 14  0  9 16 18 12  8  1 11 15  2 17  4  3  5]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 13, 10, 7, 14, 0, 9, 16, 18, 12, 8, 11, 15, 2, 17, 4, 3, 5]\n",
      "fedserver选择的客户端index: [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19]\n",
      "acc: 53.69746780395508\n",
      "acc: 49.939385414123535\n",
      "acc: 52.188846588134766\n",
      "acc: 52.44477367401123\n",
      "acc: 44.60533428192139\n",
      "acc: 5.610183238983154\n",
      "acc: 47.44073295593262\n",
      "acc: 53.852370262145996\n",
      "acc: 44.87473011016846\n",
      "acc: 52.42456912994385\n",
      "acc: 57.172682762145996\n",
      "acc: 38.68534469604492\n",
      "acc: 48.73383617401123\n",
      "acc: 40.012123107910156\n",
      "acc: 53.79175662994385\n",
      "acc: 59.09213352203369\n",
      "acc: 54.357489585876465\n",
      "acc: 58.230064392089844\n",
      "====================== Fed Server==========================\n",
      " Train: Round  19, Avg Accuracy 56.221 | Avg Loss 1.228\n",
      " Test: Round  19, Avg Accuracy 48.175 | Avg Loss 1.528\n",
      "==========================================================\n",
      "Epoch 19 finished in 00:02:01\n",
      "Epoch 19 finished. Total time: 2457.46 seconds\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 57.484 \tLoss: 1.1874\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 53.596 \tLoss: 1.2741\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 53.274 \tLoss: 1.5169\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 5.179 \tLoss: 4.9021\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 53.293 \tLoss: 1.5133\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 4.984 \tLoss: 3.6194\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 57.966 \tLoss: 1.1620\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 56.432 \tLoss: 1.2443\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 58.527 \tLoss: 1.1749\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 51.778 \tLoss: 1.3535\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 58.424 \tLoss: 1.1514\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 50.492 \tLoss: 1.4798\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 58.509 \tLoss: 1.1686\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 52.384 \tLoss: 1.4219\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 57.962 \tLoss: 1.1674\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 48.458 \tLoss: 1.5931\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 56.163 \tLoss: 1.1937\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 45.797 \tLoss: 1.5901\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 57.902 \tLoss: 1.1516\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 51.091 \tLoss: 1.4354\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 57.964 \tLoss: 1.1806\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 49.340 \tLoss: 1.3733\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 57.599 \tLoss: 1.1779\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 45.784 \tLoss: 1.5236\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 57.608 \tLoss: 1.1736\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 50.101 \tLoss: 1.5162\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 58.238 \tLoss: 1.1559\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 50.977 \tLoss: 1.4219\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 57.808 \tLoss: 1.1569\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 48.559 \tLoss: 1.4077\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 56.765 \tLoss: 1.2011\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 52.384 \tLoss: 1.3831\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 56.275 \tLoss: 1.1903\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 52.876 \tLoss: 1.3754\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 55.294 \tLoss: 1.1925\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 50.330 \tLoss: 1.3918\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 57.962 \tLoss: 1.1750\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 55.220 \tLoss: 1.2386\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 58.267 \tLoss: 1.1781\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client7 Test =>                   \tAcc: 57.658 \tLoss: 1.1500\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  20, Avg Accuracy 57.164 | Avg Loss 1.208\n",
      " Test: Round  20, Avg Accuracy 45.938 | Avg Loss 1.719\n",
      "==========================================================\n",
      "idxs_users [ 1 19  0 15 17 18 10 12  2  9  8 11  6  4 13  3  5 14 16  7]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 15, 17, 18, 10, 12, 2, 9, 8, 11, 6, 4, 13, 3, 5, 14, 16, 7]\n",
      "fedserver选择的客户端index: [0, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "acc: 53.59644412994385\n",
      "acc: 56.43184280395508\n",
      "acc: 51.77801704406738\n",
      "acc: 50.49164867401123\n",
      "acc: 52.384159088134766\n",
      "acc: 48.45770454406738\n",
      "acc: 45.79741382598877\n",
      "acc: 51.09105587005615\n",
      "acc: 49.33997821807861\n",
      "acc: 45.78394412994385\n",
      "acc: 50.10102367401123\n",
      "acc: 50.9765625\n",
      "acc: 48.55872821807861\n",
      "acc: 52.384159088134766\n",
      "acc: 52.875807762145996\n",
      "acc: 50.330010414123535\n",
      "acc: 55.219557762145996\n",
      "acc: 57.657596588134766\n",
      "====================== Fed Server==========================\n",
      " Train: Round  20, Avg Accuracy 57.164 | Avg Loss 1.208\n",
      " Test: Round  20, Avg Accuracy 51.292 | Avg Loss 1.399\n",
      "==========================================================\n",
      "Epoch 20 finished in 00:02:01\n",
      "Epoch 20 finished. Total time: 2579.33 seconds\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 57.312 \tLoss: 1.1662\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 50.020 \tLoss: 1.4875\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 53.670 \tLoss: 1.5714\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 10.399 \tLoss: 4.4192\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 58.660 \tLoss: 1.1609\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 49.609 \tLoss: 1.3648\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 57.190 \tLoss: 1.1910\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 47.926 \tLoss: 1.5199\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 57.560 \tLoss: 1.1724\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 53.071 \tLoss: 1.2477\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 59.665 \tLoss: 1.1614\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 46.558 \tLoss: 1.6123\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 58.088 \tLoss: 1.1590\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 46.828 \tLoss: 1.7278\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 58.426 \tLoss: 1.1568\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 46.713 \tLoss: 1.5601\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 57.436 \tLoss: 1.1674\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 55.624 \tLoss: 1.1836\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 59.040 \tLoss: 1.1405\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 58.385 \tLoss: 1.2095\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 56.245 \tLoss: 1.1553\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 46.525 \tLoss: 1.7230\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 58.757 \tLoss: 1.1490\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 47.986 \tLoss: 1.4014\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 56.845 \tLoss: 1.1767\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 52.074 \tLoss: 1.3175\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 58.874 \tLoss: 1.1514\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 50.141 \tLoss: 1.3514\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 58.444 \tLoss: 1.1610\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 52.290 \tLoss: 1.3170\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 58.619 \tLoss: 1.1392\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 54.021 \tLoss: 1.2638\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 57.799 \tLoss: 1.1620\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 51.192 \tLoss: 1.4028\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 56.622 \tLoss: 1.1565\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 52.148 \tLoss: 1.4258\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 58.015 \tLoss: 1.1485\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 46.249 \tLoss: 1.8584\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 52.790 \tLoss: 1.5536\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client0 Test =>                   \tAcc: 60.574 \tLoss: 1.0642\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  21, Avg Accuracy 57.503 | Avg Loss 1.200\n",
      " Test: Round  21, Avg Accuracy 51.018 | Avg Loss 1.426\n",
      "==========================================================\n",
      "idxs_users [ 2 19 16  3 14 11  9 12  1  4 15  8  5 17  7 13 10 18  6  0]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 16, 14, 11, 9, 12, 1, 4, 15, 8, 5, 17, 7, 13, 10, 18, 6, 0]\n",
      "fedserver选择的客户端index: [0, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "acc: 50.02020454406738\n",
      "acc: 49.609375\n",
      "acc: 53.071120262145996\n",
      "acc: 46.55845928192139\n",
      "acc: 46.82785511016846\n",
      "acc: 46.713361740112305\n",
      "acc: 55.623653411865234\n",
      "acc: 58.38496780395508\n",
      "acc: 46.524784088134766\n",
      "acc: 47.986260414123535\n",
      "acc: 52.07435321807861\n",
      "acc: 50.141432762145996\n",
      "acc: 52.289870262145996\n",
      "acc: 54.02074337005615\n",
      "acc: 51.19207954406738\n",
      "acc: 52.1484375\n",
      "acc: 46.248653411865234\n",
      "acc: 60.573814392089844\n",
      "====================== Fed Server==========================\n",
      " Train: Round  21, Avg Accuracy 57.503 | Avg Loss 1.200\n",
      " Test: Round  21, Avg Accuracy 51.112 | Avg Loss 1.418\n",
      "==========================================================\n",
      "Epoch 21 finished in 00:02:01\n",
      "Epoch 21 finished. Total time: 2700.54 seconds\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 59.812 \tLoss: 1.1220\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 51.131 \tLoss: 1.2954\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 59.028 \tLoss: 1.1285\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 55.354 \tLoss: 1.2486\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 59.903 \tLoss: 1.1314\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 53.381 \tLoss: 1.3594\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 59.051 \tLoss: 1.1681\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 52.600 \tLoss: 1.3624\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 58.449 \tLoss: 1.1373\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 50.936 \tLoss: 1.4954\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 57.197 \tLoss: 1.1552\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 51.064 \tLoss: 1.4213\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 59.559 \tLoss: 1.1570\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 52.808 \tLoss: 1.3139\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 53.810 \tLoss: 1.5372\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 9.732 \tLoss: 4.7703\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 56.838 \tLoss: 1.1700\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 48.532 \tLoss: 1.3953\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 58.212 \tLoss: 1.1583\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 51.953 \tLoss: 1.3079\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 58.415 \tLoss: 1.1240\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 50.902 \tLoss: 1.4280\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 59.249 \tLoss: 1.1346\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 51.724 \tLoss: 1.3477\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 58.074 \tLoss: 1.1714\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 49.138 \tLoss: 1.5212\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 59.028 \tLoss: 1.1255\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 51.367 \tLoss: 1.3760\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 58.380 \tLoss: 1.1496\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 50.687 \tLoss: 1.3119\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 53.890 \tLoss: 1.5444\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 5.826 \tLoss: 3.9967\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 59.747 \tLoss: 1.1233\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 53.132 \tLoss: 1.3614\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 58.665 \tLoss: 1.1456\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 51.502 \tLoss: 1.2798\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 59.196 \tLoss: 1.1275\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 47.912 \tLoss: 1.4821\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 61.317 \tLoss: 1.1115\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client4 Test =>                   \tAcc: 65.228 \tLoss: 0.9648\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  22, Avg Accuracy 58.391 | Avg Loss 1.181\n",
      " Test: Round  22, Avg Accuracy 47.053 | Avg Loss 1.690\n",
      "==========================================================\n",
      "idxs_users [10  9 17  3  6  2 14 19  5 15 18  7 12 13 11  0 16  8  1  4]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 9, 17, 3, 6, 2, 14, 5, 15, 18, 7, 12, 13, 11, 16, 8, 1, 4]\n",
      "fedserver选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19]\n",
      "acc: 51.131465911865234\n",
      "acc: 55.35425662994385\n",
      "acc: 53.380927085876465\n",
      "acc: 52.599677085876465\n",
      "acc: 50.936153411865234\n",
      "acc: 51.06411647796631\n",
      "acc: 52.80845928192139\n",
      "acc: 48.53178882598877\n",
      "acc: 51.953125\n",
      "acc: 50.90247821807861\n",
      "acc: 51.724138259887695\n",
      "acc: 49.13793087005615\n",
      "acc: 51.3671875\n",
      "acc: 50.68696117401123\n",
      "acc: 53.13173484802246\n",
      "acc: 51.501885414123535\n",
      "acc: 47.912177085876465\n",
      "acc: 65.22764015197754\n",
      "====================== Fed Server==========================\n",
      " Train: Round  22, Avg Accuracy 58.391 | Avg Loss 1.181\n",
      " Test: Round  22, Avg Accuracy 52.186 | Avg Loss 1.348\n",
      "==========================================================\n",
      "Epoch 22 finished in 00:02:00\n",
      "Epoch 22 finished. Total time: 2821.44 seconds\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 58.693 \tLoss: 1.1350\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 53.031 \tLoss: 1.3836\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 60.365 \tLoss: 1.0973\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 55.462 \tLoss: 1.2179\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 61.140 \tLoss: 1.0983\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 54.263 \tLoss: 1.2228\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 57.989 \tLoss: 1.1208\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 54.438 \tLoss: 1.4047\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 59.798 \tLoss: 1.1214\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 50.586 \tLoss: 1.4786\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 59.460 \tLoss: 1.1300\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 53.246 \tLoss: 1.3178\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 58.130 \tLoss: 1.1404\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 55.671 \tLoss: 1.2496\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 52.165 \tLoss: 1.5604\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 16.905 \tLoss: 4.8122\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 59.352 \tLoss: 1.1252\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 48.512 \tLoss: 1.5132\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 58.941 \tLoss: 1.1514\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 56.964 \tLoss: 1.1332\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 54.602 \tLoss: 1.5168\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 11.571 \tLoss: 4.4936\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 60.115 \tLoss: 1.1408\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 56.782 \tLoss: 1.2015\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 60.515 \tLoss: 1.1086\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 55.119 \tLoss: 1.2643\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 59.738 \tLoss: 1.1143\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 57.072 \tLoss: 1.1936\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 59.483 \tLoss: 1.1101\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 54.061 \tLoss: 1.2712\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 58.571 \tLoss: 1.1190\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 59.287 \tLoss: 1.1193\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 58.941 \tLoss: 1.1215\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 51.994 \tLoss: 1.2991\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 60.129 \tLoss: 1.1201\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 51.192 \tLoss: 1.3731\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 59.246 \tLoss: 1.1287\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 61.065 \tLoss: 1.1224\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 60.168 \tLoss: 1.1193\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client7 Test =>                   \tAcc: 61.591 \tLoss: 1.1002\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  23, Avg Accuracy 58.877 | Avg Loss 1.164\n",
      " Test: Round  23, Avg Accuracy 52.368 | Avg Loss 1.458\n",
      "==========================================================\n",
      "idxs_users [15  9  4  6 11  1  5 19  2  3  0 14 16 17 13 10 18 12  8  7]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15, 9, 4, 6, 11, 1, 5, 19, 2, 3, 14, 16, 13, 10, 18, 12, 8, 7]\n",
      "fedserver选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 14, 15, 16, 17, 18, 19]\n",
      "acc: 53.03071117401123\n",
      "acc: 55.46201515197754\n",
      "acc: 54.263200759887695\n",
      "acc: 54.438307762145996\n",
      "acc: 50.5859375\n",
      "acc: 53.24622821807861\n",
      "acc: 55.67079734802246\n",
      "acc: 16.90463352203369\n",
      "acc: 48.51158428192139\n",
      "acc: 56.963900566101074\n",
      "acc: 56.782057762145996\n",
      "acc: 55.118534088134766\n",
      "acc: 54.061153411865234\n",
      "acc: 59.28744602203369\n",
      "acc: 51.993534088134766\n",
      "acc: 51.19207954406738\n",
      "acc: 61.065463066101074\n",
      "acc: 61.590786933898926\n",
      "====================== Fed Server==========================\n",
      " Train: Round  23, Avg Accuracy 58.877 | Avg Loss 1.164\n",
      " Test: Round  23, Avg Accuracy 52.787 | Avg Loss 1.471\n",
      "==========================================================\n",
      "Epoch 23 finished in 00:02:00\n",
      "Epoch 23 finished. Total time: 2942.26 seconds\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 60.315 \tLoss: 1.1284\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 52.384 \tLoss: 1.3316\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 60.967 \tLoss: 1.0916\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 53.711 \tLoss: 1.3755\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 58.727 \tLoss: 1.1592\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 53.239 \tLoss: 1.2676\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 59.499 \tLoss: 1.1183\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 53.388 \tLoss: 1.3428\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 52.254 \tLoss: 1.5856\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 6.802 \tLoss: 4.4581\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 59.405 \tLoss: 1.1335\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 49.980 \tLoss: 1.4453\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 60.717 \tLoss: 1.0930\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 51.583 \tLoss: 1.4516\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 60.471 \tLoss: 1.0868\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 58.291 \tLoss: 1.2513\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 60.722 \tLoss: 1.0940\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 54.512 \tLoss: 1.2381\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 59.782 \tLoss: 1.1180\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 51.488 \tLoss: 1.3890\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 60.572 \tLoss: 1.0858\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 53.617 \tLoss: 1.3597\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 59.851 \tLoss: 1.1204\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 48.357 \tLoss: 1.4630\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 53.061 \tLoss: 1.5819\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 8.345 \tLoss: 3.9265\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 59.874 \tLoss: 1.1014\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 49.838 \tLoss: 1.3348\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 59.874 \tLoss: 1.1058\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 56.277 \tLoss: 1.2633\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 60.705 \tLoss: 1.0935\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 56.371 \tLoss: 1.3046\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 59.288 \tLoss: 1.1257\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 57.577 \tLoss: 1.2185\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 60.995 \tLoss: 1.1059\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 52.249 \tLoss: 1.3668\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 58.702 \tLoss: 1.1192\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 58.776 \tLoss: 1.1461\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 60.264 \tLoss: 1.0970\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client1 Test =>                   \tAcc: 61.928 \tLoss: 1.0394\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 14, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  24, Avg Accuracy 59.302 | Avg Loss 1.157\n",
      " Test: Round  24, Avg Accuracy 49.181 | Avg Loss 1.627\n",
      "==========================================================\n",
      "idxs_users [ 3 17  5 11  0  2  6  9 16 12 18 15 19 10 13  4 14  7  8  1]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 17, 5, 11, 2, 6, 9, 16, 12, 18, 15, 10, 13, 4, 14, 7, 8, 1]\n",
      "fedserver选择的客户端index: [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19]\n",
      "acc: 52.384159088134766\n",
      "acc: 53.7109375\n",
      "acc: 53.23949337005615\n",
      "acc: 53.387661933898926\n",
      "acc: 49.97979545593262\n",
      "acc: 51.58270454406738\n",
      "acc: 58.29067897796631\n",
      "acc: 54.51239204406738\n",
      "acc: 51.48841571807861\n",
      "acc: 53.61664867401123\n",
      "acc: 48.35668087005615\n",
      "acc: 49.838361740112305\n",
      "acc: 56.276939392089844\n",
      "acc: 56.37122821807861\n",
      "acc: 57.576778411865234\n",
      "acc: 52.24946117401123\n",
      "acc: 58.77559280395508\n",
      "acc: 61.92753219604492\n",
      "====================== Fed Server==========================\n",
      " Train: Round  24, Avg Accuracy 59.302 | Avg Loss 1.157\n",
      " Test: Round  24, Avg Accuracy 54.087 | Avg Loss 1.311\n",
      "==========================================================\n",
      "Epoch 24 finished in 00:02:01\n",
      "Epoch 24 finished. Total time: 3063.38 seconds\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 59.864 \tLoss: 1.0821\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 54.027 \tLoss: 1.3067\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 61.165 \tLoss: 1.0769\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 57.213 \tLoss: 1.1738\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 61.487 \tLoss: 1.0827\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 56.061 \tLoss: 1.2386\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 61.698 \tLoss: 1.0755\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 57.018 \tLoss: 1.2336\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 60.545 \tLoss: 1.1029\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 54.001 \tLoss: 1.2684\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 60.338 \tLoss: 1.1089\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 49.670 \tLoss: 1.5613\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 61.018 \tLoss: 1.0946\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 53.246 \tLoss: 1.4059\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 61.475 \tLoss: 1.0696\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 59.604 \tLoss: 1.1789\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 61.319 \tLoss: 1.1027\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 54.472 \tLoss: 1.4103\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 59.386 \tLoss: 1.1232\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 56.567 \tLoss: 1.1745\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 60.735 \tLoss: 1.1077\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 52.445 \tLoss: 1.3937\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 60.924 \tLoss: 1.0877\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 50.256 \tLoss: 1.4645\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 61.291 \tLoss: 1.0888\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 55.139 \tLoss: 1.2698\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 60.997 \tLoss: 1.0841\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 56.257 \tLoss: 1.1872\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 52.328 \tLoss: 1.5783\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 8.580 \tLoss: 4.4441\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 61.608 \tLoss: 1.0930\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 52.829 \tLoss: 1.3338\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 60.411 \tLoss: 1.0991\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 55.550 \tLoss: 1.2705\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 60.147 \tLoss: 1.1064\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 52.344 \tLoss: 1.4732\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 54.329 \tLoss: 1.5469\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 6.021 \tLoss: 3.8101\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 61.815 \tLoss: 1.0662\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client10 Test =>                   \tAcc: 64.325 \tLoss: 0.9599\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  25, Avg Accuracy 60.144 | Avg Loss 1.139\n",
      " Test: Round  25, Avg Accuracy 49.805 | Avg Loss 1.612\n",
      "==========================================================\n",
      "idxs_users [18 13 16  9 15  2  1  4  6  3  5 17 11 14 19 12  8  7  0 10]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13, 16, 9, 15, 2, 1, 4, 6, 3, 5, 17, 11, 14, 12, 8, 7, 0, 10]\n",
      "fedserver选择的客户端index: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19]\n",
      "acc: 57.21309280395508\n",
      "acc: 56.06142234802246\n",
      "acc: 57.01778030395508\n",
      "acc: 54.00053882598877\n",
      "acc: 49.669989585876465\n",
      "acc: 53.24622821807861\n",
      "acc: 59.603986740112305\n",
      "acc: 54.47198295593262\n",
      "acc: 56.56654071807861\n",
      "acc: 52.44477367401123\n",
      "acc: 50.255927085876465\n",
      "acc: 55.138739585876465\n",
      "acc: 56.25673484802246\n",
      "acc: 52.82866382598877\n",
      "acc: 55.54956912994385\n",
      "acc: 52.34375\n",
      "acc: 6.021012902259827\n",
      "acc: 64.32516193389893\n",
      "====================== Fed Server==========================\n",
      " Train: Round  25, Avg Accuracy 60.144 | Avg Loss 1.139\n",
      " Test: Round  25, Avg Accuracy 52.390 | Avg Loss 1.434\n",
      "==========================================================\n",
      "Epoch 25 finished in 00:02:01\n",
      "Epoch 25 finished. Total time: 3184.40 seconds\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 59.947 \tLoss: 1.0864\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 54.674 \tLoss: 1.2307\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 61.592 \tLoss: 1.0783\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 55.058 \tLoss: 1.3202\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 61.542 \tLoss: 1.0795\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 56.021 \tLoss: 1.1938\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 60.315 \tLoss: 1.0819\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 55.240 \tLoss: 1.3203\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 62.038 \tLoss: 1.0737\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 51.347 \tLoss: 1.3830\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 50.561 \tLoss: 1.6268\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 5.516 \tLoss: 3.9104\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 60.535 \tLoss: 1.0878\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 57.893 \tLoss: 1.2821\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 61.712 \tLoss: 1.0885\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 53.011 \tLoss: 1.2548\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 62.059 \tLoss: 1.0658\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 54.674 \tLoss: 1.2889\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 61.599 \tLoss: 1.0627\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 54.620 \tLoss: 1.4885\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 62.298 \tLoss: 1.0615\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 56.412 \tLoss: 1.2795\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 59.908 \tLoss: 1.1039\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 56.216 \tLoss: 1.2392\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 53.284 \tLoss: 1.5762\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 9.146 \tLoss: 3.9963\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 60.708 \tLoss: 1.0977\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 62.096 \tLoss: 1.0954\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 62.176 \tLoss: 1.0889\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 52.755 \tLoss: 1.3618\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 61.576 \tLoss: 1.0634\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 58.580 \tLoss: 1.1647\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 60.641 \tLoss: 1.0860\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 54.688 \tLoss: 1.2058\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 62.884 \tLoss: 1.0458\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 54.102 \tLoss: 1.3428\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 62.785 \tLoss: 1.0728\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 50.431 \tLoss: 1.5223\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 62.815 \tLoss: 1.0646\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client17 Test =>                   \tAcc: 65.268 \tLoss: 0.9603\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  26, Avg Accuracy 60.549 | Avg Loss 1.130\n",
      " Test: Round  26, Avg Accuracy 50.573 | Avg Loss 1.569\n",
      "==========================================================\n",
      "idxs_users [15 18  3  6 11 19  2  8 12  9  4  5  0 14  1 13 10 16  7 17]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15, 18, 3, 6, 11, 2, 8, 12, 9, 4, 5, 14, 1, 13, 10, 16, 7, 17]\n",
      "fedserver选择的客户端index: [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19]\n",
      "acc: 54.67403030395508\n",
      "acc: 55.05792045593262\n",
      "acc: 56.021013259887695\n",
      "acc: 55.239763259887695\n",
      "acc: 51.34698295593262\n",
      "acc: 57.89331912994385\n",
      "acc: 53.01050662994385\n",
      "acc: 54.67403030395508\n",
      "acc: 54.620150566101074\n",
      "acc: 56.411638259887695\n",
      "acc: 56.216325759887695\n",
      "acc: 62.09590530395508\n",
      "acc: 52.75457954406738\n",
      "acc: 58.58028030395508\n",
      "acc: 54.6875\n",
      "acc: 54.1015625\n",
      "acc: 50.431034088134766\n",
      "acc: 65.2680492401123\n",
      "====================== Fed Server==========================\n",
      " Train: Round  26, Avg Accuracy 60.549 | Avg Loss 1.130\n",
      " Test: Round  26, Avg Accuracy 55.727 | Avg Loss 1.274\n",
      "==========================================================\n",
      "Epoch 26 finished in 00:02:01\n",
      "Epoch 26 finished. Total time: 3305.47 seconds\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 60.460 \tLoss: 1.0766\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 55.314 \tLoss: 1.2304\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 62.236 \tLoss: 1.0611\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 57.779 \tLoss: 1.2597\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 52.328 \tLoss: 1.6086\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 11.496 \tLoss: 5.0325\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 60.368 \tLoss: 1.1050\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 53.172 \tLoss: 1.3546\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 61.275 \tLoss: 1.0949\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 59.698 \tLoss: 1.1352\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 61.319 \tLoss: 1.0561\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 58.776 \tLoss: 1.0861\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 54.580 \tLoss: 1.5606\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 4.553 \tLoss: 3.9469\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 60.832 \tLoss: 1.0695\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 57.550 \tLoss: 1.2198\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 61.815 \tLoss: 1.0620\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 53.926 \tLoss: 1.3554\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 61.271 \tLoss: 1.0549\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 62.534 \tLoss: 1.0678\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 62.263 \tLoss: 1.0570\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 55.765 \tLoss: 1.2578\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 61.105 \tLoss: 1.0674\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 57.994 \tLoss: 1.2876\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 61.080 \tLoss: 1.0821\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 51.953 \tLoss: 1.3508\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 62.250 \tLoss: 1.0580\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 52.627 \tLoss: 1.3467\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 61.271 \tLoss: 1.0692\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 51.657 \tLoss: 1.3914\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 61.023 \tLoss: 1.0831\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 50.572 \tLoss: 1.5690\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 61.291 \tLoss: 1.0735\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 58.863 \tLoss: 1.2087\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 61.319 \tLoss: 1.0751\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 49.710 \tLoss: 1.4489\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 61.429 \tLoss: 1.0587\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 54.398 \tLoss: 1.2529\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 62.585 \tLoss: 1.0380\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client9 Test =>                   \tAcc: 64.170 \tLoss: 1.0180\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  27, Avg Accuracy 60.605 | Avg Loss 1.121\n",
      " Test: Round  27, Avg Accuracy 50.654 | Avg Loss 1.632\n",
      "==========================================================\n",
      "idxs_users [12  6 19  5  3 10  0 13 17  4 18 11  1  7  8  2 14 15 16  9]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 6, 5, 3, 10, 13, 17, 4, 18, 11, 1, 7, 8, 2, 14, 15, 16, 9]\n",
      "fedserver选择的客户端index: [0, 1, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "acc: 55.313846588134766\n",
      "acc: 57.778825759887695\n",
      "acc: 53.17214393615723\n",
      "acc: 59.698275566101074\n",
      "acc: 58.77559280395508\n",
      "acc: 57.549838066101074\n",
      "acc: 53.92645454406738\n",
      "acc: 62.533674240112305\n",
      "acc: 55.76508617401123\n",
      "acc: 57.99434280395508\n",
      "acc: 51.953125\n",
      "acc: 52.62661647796631\n",
      "acc: 51.65678882598877\n",
      "acc: 50.57246780395508\n",
      "acc: 58.86314582824707\n",
      "acc: 49.71039867401123\n",
      "acc: 54.39789867401123\n",
      "acc: 64.17025852203369\n",
      "====================== Fed Server==========================\n",
      " Train: Round  27, Avg Accuracy 60.605 | Avg Loss 1.121\n",
      " Test: Round  27, Avg Accuracy 55.914 | Avg Loss 1.269\n",
      "==========================================================\n",
      "Epoch 27 finished in 00:02:01\n",
      "Epoch 27 finished. Total time: 3426.97 seconds\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 63.382 \tLoss: 1.0470\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 57.408 \tLoss: 1.2084\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 62.102 \tLoss: 1.0846\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 53.381 \tLoss: 1.3718\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 54.301 \tLoss: 1.5660\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 5.960 \tLoss: 4.7382\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 63.325 \tLoss: 1.0298\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 55.449 \tLoss: 1.2875\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 61.712 \tLoss: 1.0347\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 52.344 \tLoss: 1.3665\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 62.741 \tLoss: 1.0395\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 54.748 \tLoss: 1.3121\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 61.544 \tLoss: 1.0784\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 58.068 \tLoss: 1.2243\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 60.896 \tLoss: 1.0670\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 60.129 \tLoss: 1.1199\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 61.482 \tLoss: 1.0664\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 60.048 \tLoss: 1.2199\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 62.668 \tLoss: 1.0345\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 57.408 \tLoss: 1.1942\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 60.823 \tLoss: 1.0691\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 57.624 \tLoss: 1.2183\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 63.045 \tLoss: 1.0270\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 54.317 \tLoss: 1.2708\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 61.746 \tLoss: 1.0497\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 57.503 \tLoss: 1.2276\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 52.992 \tLoss: 1.6101\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 15.517 \tLoss: 4.3693\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 62.433 \tLoss: 1.0545\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 55.684 \tLoss: 1.2977\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 62.155 \tLoss: 1.0497\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 53.502 \tLoss: 1.3194\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 62.776 \tLoss: 1.0346\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 55.496 \tLoss: 1.1912\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 61.827 \tLoss: 1.0652\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 53.152 \tLoss: 1.3664\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 63.543 \tLoss: 1.0309\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 59.126 \tLoss: 1.1627\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 62.199 \tLoss: 1.0563\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client16 Test =>                   \tAcc: 65.793 \tLoss: 0.9448\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  28, Avg Accuracy 61.385 | Avg Loss 1.105\n",
      " Test: Round  28, Avg Accuracy 54.368 | Avg Loss 1.414\n",
      "==========================================================\n",
      "idxs_users [ 4  5  0  7 13 10 11 14  6  9 15 18 12 19  2  1  8  3 17 16]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 5, 0, 7, 13, 10, 11, 14, 6, 9, 15, 18, 12, 1, 8, 3, 17, 16]\n",
      "fedserver选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19]\n",
      "acc: 57.40840530395508\n",
      "acc: 53.380927085876465\n",
      "acc: 5.9603986740112305\n",
      "acc: 55.44854545593262\n",
      "acc: 52.34375\n",
      "acc: 54.748114585876465\n",
      "acc: 58.068427085876465\n",
      "acc: 60.129310607910156\n",
      "acc: 60.04849147796631\n",
      "acc: 57.40840530395508\n",
      "acc: 57.62392234802246\n",
      "acc: 54.31707954406738\n",
      "acc: 57.50269412994385\n",
      "acc: 53.50215530395508\n",
      "acc: 55.495689392089844\n",
      "acc: 53.151939392089844\n",
      "acc: 59.125807762145996\n",
      "acc: 65.79337310791016\n",
      "====================== Fed Server==========================\n",
      " Train: Round  28, Avg Accuracy 61.385 | Avg Loss 1.105\n",
      " Test: Round  28, Avg Accuracy 53.970 | Avg Loss 1.430\n",
      "==========================================================\n",
      "Epoch 28 finished in 00:02:01\n",
      "Epoch 28 finished. Total time: 3548.06 seconds\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 62.562 \tLoss: 1.0279\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 58.466 \tLoss: 1.1600\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 63.265 \tLoss: 1.0282\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 52.856 \tLoss: 1.3514\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 63.426 \tLoss: 1.0276\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 57.644 \tLoss: 1.1997\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 63.532 \tLoss: 1.0293\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 53.502 \tLoss: 1.3477\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 62.888 \tLoss: 1.0419\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 55.900 \tLoss: 1.2820\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 62.659 \tLoss: 1.0238\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 57.112 \tLoss: 1.1991\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 63.323 \tLoss: 1.0398\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 63.847 \tLoss: 1.0314\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 63.010 \tLoss: 1.0265\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 58.210 \tLoss: 1.2343\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 63.231 \tLoss: 1.0600\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 51.717 \tLoss: 1.3993\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 61.351 \tLoss: 1.0378\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 58.702 \tLoss: 1.1875\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 62.017 \tLoss: 1.0618\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 58.951 \tLoss: 1.1508\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 61.448 \tLoss: 1.0709\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 56.075 \tLoss: 1.2284\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 62.615 \tLoss: 1.0455\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 56.486 \tLoss: 1.2377\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 62.390 \tLoss: 1.0564\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 59.005 \tLoss: 1.2060\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 61.861 \tLoss: 1.0481\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 52.034 \tLoss: 1.4966\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 62.659 \tLoss: 1.0438\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 55.785 \tLoss: 1.4182\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 62.732 \tLoss: 1.0520\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 52.849 \tLoss: 1.2962\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 62.369 \tLoss: 1.0659\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 53.502 \tLoss: 1.3566\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 53.045 \tLoss: 1.6461\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 10.264 \tLoss: 4.2169\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 53.745 \tLoss: 1.6174\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client0 Test =>                   \tAcc: 64.036 \tLoss: 0.9660\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  29, Avg Accuracy 61.706 | Avg Loss 1.103\n",
      " Test: Round  29, Avg Accuracy 54.217 | Avg Loss 1.404\n",
      "==========================================================\n",
      "idxs_users [ 4 14 17 18  6 13 10  9  2  1  8  5  7  3 15 16 12 11 19  0]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 17, 18, 6, 13, 10, 9, 2, 1, 8, 5, 7, 3, 15, 16, 12, 11, 0]\n",
      "fedserver选择的客户端index: [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19]\n",
      "acc: 58.465786933898926\n",
      "acc: 57.644126892089844\n",
      "acc: 53.50215530395508\n",
      "acc: 55.899784088134766\n",
      "acc: 57.11206912994385\n",
      "acc: 63.84698295593262\n",
      "acc: 58.20985984802246\n",
      "acc: 51.717403411865234\n",
      "acc: 58.70150852203369\n",
      "acc: 58.950700759887695\n",
      "acc: 56.07489204406738\n",
      "acc: 56.485721588134766\n",
      "acc: 59.00457954406738\n",
      "acc: 52.03394412994385\n",
      "acc: 55.78529071807861\n",
      "acc: 52.84886837005615\n",
      "acc: 53.50215530395508\n",
      "acc: 64.03556060791016\n",
      "====================== Fed Server==========================\n",
      " Train: Round  29, Avg Accuracy 61.706 | Avg Loss 1.103\n",
      " Test: Round  29, Avg Accuracy 56.879 | Avg Loss 1.244\n",
      "==========================================================\n",
      "Epoch 29 finished in 00:02:01\n",
      "Epoch 29 finished. Total time: 3669.07 seconds\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 61.838 \tLoss: 1.0445\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 52.546 \tLoss: 1.5229\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 62.776 \tLoss: 1.0532\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 55.166 \tLoss: 1.3199\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 64.069 \tLoss: 1.0128\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 55.260 \tLoss: 1.2918\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 61.643 \tLoss: 1.0477\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 60.890 \tLoss: 1.0746\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 63.605 \tLoss: 1.0289\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 58.776 \tLoss: 1.1198\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 62.482 \tLoss: 1.0184\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 59.793 \tLoss: 1.2088\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 52.884 \tLoss: 1.6130\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 8.210 \tLoss: 4.4807\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 63.366 \tLoss: 1.0264\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 61.005 \tLoss: 1.0875\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 64.745 \tLoss: 0.9984\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 55.624 \tLoss: 1.3888\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 63.410 \tLoss: 1.0225\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 47.751 \tLoss: 1.5942\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 54.504 \tLoss: 1.6002\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 4.068 \tLoss: 4.3912\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 63.417 \tLoss: 1.0214\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 52.310 \tLoss: 1.3983\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 62.872 \tLoss: 1.0183\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 54.789 \tLoss: 1.2743\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 62.284 \tLoss: 1.0363\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 46.053 \tLoss: 1.5206\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 63.205 \tLoss: 1.0430\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 55.529 \tLoss: 1.3726\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 62.330 \tLoss: 1.0398\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 57.974 \tLoss: 1.1614\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 62.819 \tLoss: 1.0239\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 54.108 \tLoss: 1.3745\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 61.799 \tLoss: 1.0441\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 61.416 \tLoss: 1.0228\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 63.231 \tLoss: 1.0408\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 61.342 \tLoss: 1.0919\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 64.575 \tLoss: 0.9910\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client17 Test =>                   \tAcc: 66.440 \tLoss: 0.9401\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  30, Avg Accuracy 62.093 | Avg Loss 1.086\n",
      " Test: Round  30, Avg Accuracy 50.697 | Avg Loss 1.624\n",
      "==========================================================\n",
      "idxs_users [ 6  2  7 14  1 13 19 16  4 18  0 12  9  3  5 10 11 15  8 17]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 2, 7, 14, 1, 13, 16, 4, 18, 12, 9, 3, 5, 10, 11, 15, 8, 17]\n",
      "fedserver选择的客户端index: [0, 1, 2, 3, 4, 5, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "acc: 52.54579734802246\n",
      "acc: 55.16567897796631\n",
      "acc: 55.25996780395508\n",
      "acc: 60.89035606384277\n",
      "acc: 58.77559280395508\n",
      "acc: 59.792564392089844\n",
      "acc: 61.004849433898926\n",
      "acc: 55.623653411865234\n",
      "acc: 47.75053882598877\n",
      "acc: 52.310075759887695\n",
      "acc: 54.78852367401123\n",
      "acc: 46.053340911865234\n",
      "acc: 55.529364585876465\n",
      "acc: 57.974138259887695\n",
      "acc: 54.10829734802246\n",
      "acc: 61.41567897796631\n",
      "acc: 61.34159469604492\n",
      "acc: 66.4399242401123\n",
      "====================== Fed Server==========================\n",
      " Train: Round  30, Avg Accuracy 62.093 | Avg Loss 1.086\n",
      " Test: Round  30, Avg Accuracy 56.487 | Avg Loss 1.265\n",
      "==========================================================\n",
      "Epoch 30 finished in 00:02:00\n",
      "Epoch 30 finished. Total time: 3789.98 seconds\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 63.109 \tLoss: 1.0273\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 57.078 \tLoss: 1.1305\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 63.539 \tLoss: 1.0121\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 60.493 \tLoss: 1.0965\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 63.068 \tLoss: 1.0244\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 60.634 \tLoss: 1.1829\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 62.985 \tLoss: 1.0329\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 57.402 \tLoss: 1.2621\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 62.073 \tLoss: 1.0179\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 54.081 \tLoss: 1.4069\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 61.765 \tLoss: 1.0358\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 48.963 \tLoss: 1.6818\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 62.767 \tLoss: 1.0208\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 55.475 \tLoss: 1.2356\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 65.085 \tLoss: 0.9795\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 63.079 \tLoss: 1.0800\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 63.274 \tLoss: 1.0246\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 58.365 \tLoss: 1.2595\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 63.150 \tLoss: 1.0054\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 55.691 \tLoss: 1.2147\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 64.090 \tLoss: 0.9992\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 59.968 \tLoss: 1.2215\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 63.851 \tLoss: 1.0055\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 59.402 \tLoss: 1.1967\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 63.504 \tLoss: 1.0375\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 54.512 \tLoss: 1.2925\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 61.978 \tLoss: 1.0319\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 59.597 \tLoss: 1.0558\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 51.726 \tLoss: 1.6469\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 8.466 \tLoss: 4.3617\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 62.732 \tLoss: 1.0104\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 59.227 \tLoss: 1.0923\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 63.608 \tLoss: 1.0129\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 52.734 \tLoss: 1.4031\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 65.214 \tLoss: 1.0040\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 54.688 \tLoss: 1.3572\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 55.205 \tLoss: 1.5791\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 12.291 \tLoss: 3.9966\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 63.842 \tLoss: 1.0181\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client18 Test =>                   \tAcc: 62.918 \tLoss: 1.0495\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 3, 4, 5, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  31, Avg Accuracy 62.328 | Avg Loss 1.076\n",
      " Test: Round  31, Avg Accuracy 52.201 | Avg Loss 1.562\n",
      "==========================================================\n",
      "idxs_users [ 8  1 16  3 11 15  6  4  2 13  9  7  5 14 19 10 12 17  0 18]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 1, 16, 3, 11, 15, 6, 4, 2, 13, 9, 7, 5, 14, 10, 12, 17, 18]\n",
      "fedserver选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 19]\n",
      "acc: 57.07839393615723\n",
      "acc: 60.492995262145996\n",
      "acc: 60.63442897796631\n",
      "acc: 57.40167045593262\n",
      "acc: 54.08135795593262\n",
      "acc: 48.962822914123535\n",
      "acc: 55.47548484802246\n",
      "acc: 63.07920265197754\n",
      "acc: 58.364763259887695\n",
      "acc: 55.691001892089844\n",
      "acc: 59.96767234802246\n",
      "acc: 59.401939392089844\n",
      "acc: 54.51239204406738\n",
      "acc: 59.597251892089844\n",
      "acc: 59.22683143615723\n",
      "acc: 52.734375\n",
      "acc: 54.6875\n",
      "acc: 62.917564392089844\n",
      "====================== Fed Server==========================\n",
      " Train: Round  31, Avg Accuracy 62.328 | Avg Loss 1.076\n",
      " Test: Round  31, Avg Accuracy 57.462 | Avg Loss 1.234\n",
      "==========================================================\n",
      "Epoch 31 finished in 00:02:01\n",
      "Epoch 31 finished. Total time: 3911.86 seconds\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 63.739 \tLoss: 0.9936\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 60.769 \tLoss: 1.2430\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 63.844 \tLoss: 1.0149\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 55.199 \tLoss: 1.2481\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 65.731 \tLoss: 0.9867\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 51.030 \tLoss: 1.4231\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 63.778 \tLoss: 1.0037\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 58.270 \tLoss: 1.2346\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 65.630 \tLoss: 0.9901\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 60.655 \tLoss: 1.1346\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 63.210 \tLoss: 1.0104\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 59.577 \tLoss: 1.1083\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 64.359 \tLoss: 1.0160\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 54.762 \tLoss: 1.3542\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 64.559 \tLoss: 1.0032\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 59.483 \tLoss: 1.1602\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 64.501 \tLoss: 0.9942\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 54.688 \tLoss: 1.2938\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 63.201 \tLoss: 1.0310\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 55.745 \tLoss: 1.2313\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 65.738 \tLoss: 0.9838\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 57.698 \tLoss: 1.2201\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 52.835 \tLoss: 1.6338\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 6.843 \tLoss: 4.1197\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 64.299 \tLoss: 1.0107\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 56.156 \tLoss: 1.2024\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 64.956 \tLoss: 0.9714\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 61.355 \tLoss: 1.1066\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 62.654 \tLoss: 1.0173\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 57.429 \tLoss: 1.2049\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 64.079 \tLoss: 1.0033\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 57.893 \tLoss: 1.2652\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 53.382 \tLoss: 1.6421\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 10.614 \tLoss: 4.8081\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 62.937 \tLoss: 1.0155\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 52.425 \tLoss: 1.4947\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 65.901 \tLoss: 0.9811\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 61.375 \tLoss: 1.1005\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 63.964 \tLoss: 1.0083\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client12 Test =>                   \tAcc: 64.406 \tLoss: 1.0163\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  32, Avg Accuracy 63.165 | Avg Loss 1.066\n",
      " Test: Round  32, Avg Accuracy 52.087 | Avg Loss 1.592\n",
      "==========================================================\n",
      "idxs_users [ 6 10 18  8 17 15  2 13  1  5  7  0 16  9  3 11 19 14  4 12]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 10, 18, 8, 17, 15, 2, 13, 1, 5, 7, 0, 16, 3, 11, 14, 4, 12]\n",
      "fedserver选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 17, 18, 19]\n",
      "acc: 60.769126892089844\n",
      "acc: 55.19935321807861\n",
      "acc: 51.030442237854004\n",
      "acc: 58.270474433898926\n",
      "acc: 60.65463352203369\n",
      "acc: 59.57704734802246\n",
      "acc: 54.76158428192139\n",
      "acc: 59.48275852203369\n",
      "acc: 54.6875\n",
      "acc: 55.74488162994385\n",
      "acc: 57.69800662994385\n",
      "acc: 6.842672348022461\n",
      "acc: 56.15571117401123\n",
      "acc: 57.42860984802246\n",
      "acc: 57.89331912994385\n",
      "acc: 52.42456912994385\n",
      "acc: 61.37526893615723\n",
      "acc: 64.40598106384277\n",
      "====================== Fed Server==========================\n",
      " Train: Round  32, Avg Accuracy 63.165 | Avg Loss 1.066\n",
      " Test: Round  32, Avg Accuracy 54.689 | Avg Loss 1.392\n",
      "==========================================================\n",
      "Epoch 32 finished in 00:02:01\n",
      "Epoch 32 finished. Total time: 4033.01 seconds\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 63.826 \tLoss: 0.9916\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 56.822 \tLoss: 1.3601\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 63.019 \tLoss: 1.0157\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 60.594 \tLoss: 1.1246\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 63.116 \tLoss: 1.0154\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 59.503 \tLoss: 1.2319\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 64.750 \tLoss: 0.9865\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 58.930 \tLoss: 1.1981\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 64.207 \tLoss: 0.9871\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 58.210 \tLoss: 1.1493\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 64.104 \tLoss: 1.0122\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 56.021 \tLoss: 1.3988\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 64.607 \tLoss: 0.9957\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 55.395 \tLoss: 1.2757\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 64.467 \tLoss: 0.9946\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 59.186 \tLoss: 1.1576\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 65.715 \tLoss: 0.9787\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 50.916 \tLoss: 1.3406\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 52.964 \tLoss: 1.6504\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 9.833 \tLoss: 4.5158\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 65.804 \tLoss: 0.9719\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 57.213 \tLoss: 1.2229\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 64.003 \tLoss: 1.0018\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 51.529 \tLoss: 1.3483\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 64.313 \tLoss: 0.9921\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 55.186 \tLoss: 1.2554\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 65.202 \tLoss: 0.9891\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 56.115 \tLoss: 1.3303\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 63.587 \tLoss: 0.9889\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 59.011 \tLoss: 1.2140\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 65.595 \tLoss: 0.9672\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 62.803 \tLoss: 1.0259\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 62.872 \tLoss: 1.0164\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 56.412 \tLoss: 1.2356\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 63.288 \tLoss: 1.0215\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 59.820 \tLoss: 1.1680\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 54.752 \tLoss: 1.6099\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 11.436 \tLoss: 3.7364\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 65.418 \tLoss: 0.9945\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client2 Test =>                   \tAcc: 65.053 \tLoss: 1.0109\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  33, Avg Accuracy 63.280 | Avg Loss 1.059\n",
      " Test: Round  33, Avg Accuracy 52.637 | Avg Loss 1.541\n",
      "==========================================================\n",
      "idxs_users [11  5  6  1  9 18  8 12 10 19 17 15 16  7 13  4 14  3  0  2]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 5, 6, 1, 9, 18, 8, 12, 10, 17, 15, 16, 7, 13, 4, 14, 3, 2]\n",
      "fedserver选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 19]\n",
      "acc: 56.82246780395508\n",
      "acc: 60.59401893615723\n",
      "acc: 59.502963066101074\n",
      "acc: 58.930495262145996\n",
      "acc: 58.20985984802246\n",
      "acc: 56.021013259887695\n",
      "acc: 55.39466571807861\n",
      "acc: 59.18642234802246\n",
      "acc: 50.915947914123535\n",
      "acc: 57.21309280395508\n",
      "acc: 51.528825759887695\n",
      "acc: 55.18588352203369\n",
      "acc: 56.115302085876465\n",
      "acc: 59.011314392089844\n",
      "acc: 62.80307102203369\n",
      "acc: 56.411638259887695\n",
      "acc: 59.81950378417969\n",
      "acc: 65.05253219604492\n",
      "====================== Fed Server==========================\n",
      " Train: Round  33, Avg Accuracy 63.280 | Avg Loss 1.059\n",
      " Test: Round  33, Avg Accuracy 57.707 | Avg Loss 1.225\n",
      "==========================================================\n",
      "Epoch 33 finished in 00:02:01\n",
      "Epoch 33 finished. Total time: 4154.17 seconds\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 66.542 \tLoss: 0.9726\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 57.254 \tLoss: 1.2366\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 63.991 \tLoss: 0.9932\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 58.035 \tLoss: 1.2086\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 65.515 \tLoss: 0.9674\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 57.745 \tLoss: 1.2054\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 53.495 \tLoss: 1.6069\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 5.826 \tLoss: 3.7085\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 64.221 \tLoss: 0.9856\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 60.581 \tLoss: 1.1214\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 64.106 \tLoss: 0.9896\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 54.694 \tLoss: 1.3162\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 64.828 \tLoss: 0.9912\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 61.530 \tLoss: 1.1614\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 64.828 \tLoss: 0.9772\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 57.489 \tLoss: 1.0762\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 65.342 \tLoss: 0.9540\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 58.244 \tLoss: 1.1993\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 65.232 \tLoss: 0.9770\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 50.431 \tLoss: 1.3231\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 64.658 \tLoss: 0.9745\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 60.089 \tLoss: 1.1704\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 64.793 \tLoss: 0.9880\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 52.829 \tLoss: 1.4363\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 65.751 \tLoss: 0.9646\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 58.641 \tLoss: 1.2643\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 64.554 \tLoss: 0.9842\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 55.395 \tLoss: 1.1845\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 53.357 \tLoss: 1.6451\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 11.591 \tLoss: 4.8064\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 64.733 \tLoss: 0.9789\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 57.685 \tLoss: 1.1821\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 66.560 \tLoss: 0.9581\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 52.660 \tLoss: 1.4571\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 65.179 \tLoss: 0.9840\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 57.489 \tLoss: 1.1181\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 64.779 \tLoss: 0.9878\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 56.923 \tLoss: 1.1569\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 65.046 \tLoss: 1.0179\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client3 Test =>                   \tAcc: 66.359 \tLoss: 0.9245\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  34, Avg Accuracy 63.876 | Avg Loss 1.045\n",
      " Test: Round  34, Avg Accuracy 52.452 | Avg Loss 1.543\n",
      "==========================================================\n",
      "idxs_users [11  5 17  0 12 14  6 10  4  1 13  2 18 15 19  7  9 16  8  3]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 17, 12, 14, 6, 10, 4, 1, 13, 2, 18, 15, 19, 7, 9, 16, 8, 3]\n",
      "fedserver选择的客户端index: [0, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "acc: 57.253501892089844\n",
      "acc: 57.745150566101074\n",
      "acc: 60.580549240112305\n",
      "acc: 54.69423484802246\n",
      "acc: 61.53017234802246\n",
      "acc: 57.489224433898926\n",
      "acc: 58.243534088134766\n",
      "acc: 50.431034088134766\n",
      "acc: 60.088900566101074\n",
      "acc: 52.82866382598877\n",
      "acc: 58.64089393615723\n",
      "acc: 55.39466571807861\n",
      "acc: 11.590786695480347\n",
      "acc: 57.684536933898926\n",
      "acc: 52.66029071807861\n",
      "acc: 57.489224433898926\n",
      "acc: 56.92349147796631\n",
      "acc: 66.35910606384277\n",
      "====================== Fed Server==========================\n",
      " Train: Round  34, Avg Accuracy 63.876 | Avg Loss 1.045\n",
      " Test: Round  34, Avg Accuracy 54.868 | Avg Loss 1.408\n",
      "==========================================================\n",
      "Epoch 34 finished in 00:02:01\n",
      "Epoch 34 finished. Total time: 4275.34 seconds\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 54.584 \tLoss: 1.6101\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 5.415 \tLoss: 4.1472\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 63.585 \tLoss: 0.9999\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 63.160 \tLoss: 1.0506\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 64.975 \tLoss: 0.9668\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 62.897 \tLoss: 1.0886\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 64.706 \tLoss: 0.9807\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 60.453 \tLoss: 1.2247\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 65.028 \tLoss: 0.9747\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 57.658 \tLoss: 1.2877\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 64.894 \tLoss: 0.9718\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 55.024 \tLoss: 1.3020\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 64.352 \tLoss: 0.9827\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 58.506 \tLoss: 1.1690\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 65.604 \tLoss: 0.9594\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 54.694 \tLoss: 1.3190\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 65.349 \tLoss: 0.9751\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 57.058 \tLoss: 1.2670\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 65.965 \tLoss: 0.9590\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 55.590 \tLoss: 1.2142\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 66.229 \tLoss: 0.9314\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 59.287 \tLoss: 1.0760\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 64.134 \tLoss: 0.9947\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 59.422 \tLoss: 1.1175\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 64.752 \tLoss: 0.9699\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 59.065 \tLoss: 1.1368\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 64.460 \tLoss: 0.9719\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 57.314 \tLoss: 1.3214\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 66.590 \tLoss: 0.9383\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 60.163 \tLoss: 1.1661\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 65.106 \tLoss: 0.9651\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 50.660 \tLoss: 1.4419\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 66.126 \tLoss: 0.9429\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 55.765 \tLoss: 1.2330\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 64.710 \tLoss: 0.9667\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 57.132 \tLoss: 1.2606\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 64.706 \tLoss: 0.9910\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 64.231 \tLoss: 1.0578\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 52.479 \tLoss: 1.6761\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client19 Test =>                   \tAcc: 68.373 \tLoss: 0.8859\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  35, Avg Accuracy 63.917 | Avg Loss 1.036\n",
      " Test: Round  35, Avg Accuracy 55.459 | Avg Loss 1.361\n",
      "==========================================================\n",
      "idxs_users [ 0  3 11  2  6  1 12  7 13 17  4 14 16 15 10 18  9  8  5 19]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 11, 2, 6, 1, 12, 7, 13, 17, 4, 14, 16, 15, 10, 18, 9, 8, 5]\n",
      "fedserver选择的客户端index: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n",
      "acc: 63.16002082824707\n",
      "acc: 62.89735984802246\n",
      "acc: 60.45258617401123\n",
      "acc: 57.657596588134766\n",
      "acc: 55.024245262145996\n",
      "acc: 58.50619602203369\n",
      "acc: 54.69423484802246\n",
      "acc: 57.058189392089844\n",
      "acc: 55.58997821807861\n",
      "acc: 59.28744602203369\n",
      "acc: 59.42214393615723\n",
      "acc: 59.06519412994385\n",
      "acc: 57.31411647796631\n",
      "acc: 60.16298484802246\n",
      "acc: 50.66002178192139\n",
      "acc: 55.76508617401123\n",
      "acc: 57.13227367401123\n",
      "acc: 64.23087310791016\n",
      "====================== Fed Server==========================\n",
      " Train: Round  35, Avg Accuracy 63.917 | Avg Loss 1.036\n",
      " Test: Round  35, Avg Accuracy 58.227 | Avg Loss 1.207\n",
      "==========================================================\n",
      "Epoch 35 finished in 00:02:00\n",
      "Epoch 35 finished. Total time: 4396.32 seconds\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 65.790 \tLoss: 0.9597\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 62.412 \tLoss: 1.0199\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 66.236 \tLoss: 0.9613\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 62.157 \tLoss: 1.0915\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 66.335 \tLoss: 0.9493\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 57.718 \tLoss: 1.2320\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 65.163 \tLoss: 0.9817\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 60.244 \tLoss: 1.1574\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 63.874 \tLoss: 0.9915\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 58.324 \tLoss: 1.2007\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 51.721 \tLoss: 1.7252\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 6.782 \tLoss: 4.2668\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 66.494 \tLoss: 0.9389\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 61.611 \tLoss: 1.0298\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 64.903 \tLoss: 0.9710\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 59.328 \tLoss: 1.1649\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 54.580 \tLoss: 1.6301\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 11.294 \tLoss: 4.3330\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 65.632 \tLoss: 0.9560\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 52.324 \tLoss: 1.6036\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 66.455 \tLoss: 0.9560\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 54.459 \tLoss: 1.2494\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 66.484 \tLoss: 0.9466\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 57.274 \tLoss: 1.2626\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 65.443 \tLoss: 0.9686\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 62.958 \tLoss: 1.1169\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 65.471 \tLoss: 0.9652\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 56.452 \tLoss: 1.3407\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 64.407 \tLoss: 0.9578\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 55.920 \tLoss: 1.2016\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 64.851 \tLoss: 0.9635\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 59.005 \tLoss: 1.1347\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 65.388 \tLoss: 0.9600\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 53.751 \tLoss: 1.4735\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 65.188 \tLoss: 0.9756\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 54.162 \tLoss: 1.5019\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 65.786 \tLoss: 0.9577\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 57.469 \tLoss: 1.1653\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 65.506 \tLoss: 0.9509\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client9 Test =>                   \tAcc: 68.359 \tLoss: 0.9192\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  36, Avg Accuracy 64.285 | Avg Loss 1.033\n",
      " Test: Round  36, Avg Accuracy 52.291 | Avg Loss 1.585\n",
      "==========================================================\n",
      "idxs_users [10 13  8  1  5 19  4 14  0 17 16  7 12  2  6 15 18 11  3  9]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 13, 8, 1, 5, 4, 14, 17, 16, 7, 12, 2, 6, 15, 18, 11, 3, 9]\n",
      "fedserver选择的客户端index: [0, 1, 2, 3, 4, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "acc: 62.41244602203369\n",
      "acc: 62.15651893615723\n",
      "acc: 57.71821117401123\n",
      "acc: 60.24380397796631\n",
      "acc: 58.32435321807861\n",
      "acc: 61.61099147796631\n",
      "acc: 59.32785606384277\n",
      "acc: 52.32354545593262\n",
      "acc: 54.458513259887695\n",
      "acc: 57.27370643615723\n",
      "acc: 62.957974433898926\n",
      "acc: 56.45204734802246\n",
      "acc: 55.919989585876465\n",
      "acc: 59.00457954406738\n",
      "acc: 53.751346588134766\n",
      "acc: 54.162177085876465\n",
      "acc: 57.46901893615723\n",
      "acc: 68.359375\n",
      "====================== Fed Server==========================\n",
      " Train: Round  36, Avg Accuracy 64.285 | Avg Loss 1.033\n",
      " Test: Round  36, Avg Accuracy 58.551 | Avg Loss 1.215\n",
      "==========================================================\n",
      "Epoch 36 finished in 00:02:01\n",
      "Epoch 36 finished. Total time: 4517.42 seconds\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 53.109 \tLoss: 1.6597\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 9.597 \tLoss: 3.8425\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 66.845 \tLoss: 0.9196\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 61.530 \tLoss: 1.1590\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 66.482 \tLoss: 0.9351\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 61.005 \tLoss: 1.1171\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 65.528 \tLoss: 0.9692\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 59.564 \tLoss: 1.1350\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 65.988 \tLoss: 0.9432\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 60.062 \tLoss: 1.1347\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 66.248 \tLoss: 0.9596\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 54.142 \tLoss: 1.2821\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 65.809 \tLoss: 0.9552\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 59.112 \tLoss: 1.1885\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 65.005 \tLoss: 0.9561\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 58.405 \tLoss: 1.1543\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 63.674 \tLoss: 0.9852\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 57.388 \tLoss: 1.2051\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 66.475 \tLoss: 0.9515\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 57.880 \tLoss: 1.1614\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 53.824 \tLoss: 1.6460\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 11.200 \tLoss: 3.9917\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 64.026 \tLoss: 0.9874\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 58.075 \tLoss: 1.2695\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 65.119 \tLoss: 0.9721\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 56.863 \tLoss: 1.2086\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 66.255 \tLoss: 0.9452\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 55.624 \tLoss: 1.2836\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 65.097 \tLoss: 0.9545\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 60.533 \tLoss: 1.1943\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 66.599 \tLoss: 0.9602\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 55.314 \tLoss: 1.4797\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 66.411 \tLoss: 0.9491\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 53.758 \tLoss: 1.3867\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 67.204 \tLoss: 0.9275\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 62.096 \tLoss: 1.0821\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 66.696 \tLoss: 0.9433\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 55.085 \tLoss: 1.2532\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 65.209 \tLoss: 0.9573\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client8 Test =>                   \tAcc: 69.019 \tLoss: 0.8683\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 3, 4, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  37, Avg Accuracy 64.580 | Avg Loss 1.024\n",
      " Test: Round  37, Avg Accuracy 53.596 | Avg Loss 1.495\n",
      "==========================================================\n",
      "idxs_users [19  9 17 14 10  7 13  2  5  1  0  3 15  6 12 11 16  4 18  8]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 17, 14, 10, 7, 13, 2, 5, 1, 3, 15, 6, 12, 11, 16, 4, 18, 8]\n",
      "fedserver选择的客户端index: [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "acc: 61.53017234802246\n",
      "acc: 61.004849433898926\n",
      "acc: 59.56357765197754\n",
      "acc: 60.06196117401123\n",
      "acc: 54.141971588134766\n",
      "acc: 59.112338066101074\n",
      "acc: 58.40517234802246\n",
      "acc: 57.388200759887695\n",
      "acc: 57.879849433898926\n",
      "acc: 58.075161933898926\n",
      "acc: 56.862876892089844\n",
      "acc: 55.623653411865234\n",
      "acc: 60.53340530395508\n",
      "acc: 55.313846588134766\n",
      "acc: 53.75808143615723\n",
      "acc: 62.09590530395508\n",
      "acc: 55.08485984802246\n",
      "acc: 69.01939582824707\n",
      "====================== Fed Server==========================\n",
      " Train: Round  37, Avg Accuracy 64.580 | Avg Loss 1.024\n",
      " Test: Round  37, Avg Accuracy 58.636 | Avg Loss 1.198\n",
      "==========================================================\n",
      "Epoch 37 finished in 00:02:02\n",
      "Epoch 37 finished. Total time: 4640.37 seconds\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 65.393 \tLoss: 0.9425\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 62.217 \tLoss: 1.0021\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 65.301 \tLoss: 0.9386\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 62.392 \tLoss: 1.0346\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 66.381 \tLoss: 0.9315\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 58.735 \tLoss: 1.2087\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 52.528 \tLoss: 1.7137\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 7.348 \tLoss: 6.5335\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 66.108 \tLoss: 0.9444\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 63.490 \tLoss: 1.1025\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 52.884 \tLoss: 1.6667\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 10.870 \tLoss: 4.1240\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 64.777 \tLoss: 0.9521\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 61.651 \tLoss: 1.0925\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 66.305 \tLoss: 0.9484\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 58.392 \tLoss: 1.3676\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 66.452 \tLoss: 0.9474\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 56.432 \tLoss: 1.2645\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 66.183 \tLoss: 0.9469\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 54.223 \tLoss: 1.4156\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 67.024 \tLoss: 0.9409\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 56.061 \tLoss: 1.4048\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 64.947 \tLoss: 0.9519\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 62.729 \tLoss: 1.0727\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 65.931 \tLoss: 0.9219\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 47.501 \tLoss: 1.8026\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 65.561 \tLoss: 0.9692\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 60.008 \tLoss: 1.1720\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 65.965 \tLoss: 0.9541\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 62.197 \tLoss: 1.1458\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 67.068 \tLoss: 0.9373\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 62.096 \tLoss: 1.0957\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 66.880 \tLoss: 0.9455\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 49.124 \tLoss: 1.7059\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 67.528 \tLoss: 0.9151\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 58.829 \tLoss: 1.1830\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 66.581 \tLoss: 0.9504\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 57.745 \tLoss: 1.2009\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 65.915 \tLoss: 0.9236\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client13 Test =>                   \tAcc: 67.726 \tLoss: 0.9400\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  38, Avg Accuracy 64.786 | Avg Loss 1.017\n",
      " Test: Round  38, Avg Accuracy 53.416 | Avg Loss 1.692\n",
      "==========================================================\n",
      "idxs_users [15 10 11 19  8  0  6 16 17  7  2 14  9  5  3  1 12  4 18 13]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15, 10, 11, 8, 6, 16, 17, 7, 2, 14, 9, 5, 3, 1, 12, 4, 18, 13]\n",
      "fedserver选择的客户端index: [0, 1, 2, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "acc: 62.21713352203369\n",
      "acc: 62.39224147796631\n",
      "acc: 58.735182762145996\n",
      "acc: 63.49003219604492\n",
      "acc: 61.651400566101074\n",
      "acc: 58.39170265197754\n",
      "acc: 56.43184280395508\n",
      "acc: 54.22279071807861\n",
      "acc: 56.06142234802246\n",
      "acc: 62.728986740112305\n",
      "acc: 47.501346588134766\n",
      "acc: 60.00808143615723\n",
      "acc: 62.19692897796631\n",
      "acc: 62.09590530395508\n",
      "acc: 49.12446117401123\n",
      "acc: 58.829471588134766\n",
      "acc: 57.745150566101074\n",
      "acc: 67.72629356384277\n",
      "====================== Fed Server==========================\n",
      " Train: Round  38, Avg Accuracy 64.786 | Avg Loss 1.017\n",
      " Test: Round  38, Avg Accuracy 58.975 | Avg Loss 1.234\n",
      "==========================================================\n",
      "Epoch 38 finished in 00:02:01\n",
      "Epoch 38 finished. Total time: 4761.54 seconds\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 67.029 \tLoss: 0.9324\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 63.901 \tLoss: 1.0353\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 65.232 \tLoss: 0.9525\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 60.857 \tLoss: 1.2427\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 52.879 \tLoss: 1.6884\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 11.261 \tLoss: 3.9274\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 67.197 \tLoss: 0.9234\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 57.543 \tLoss: 1.2234\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 67.463 \tLoss: 0.9125\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 62.864 \tLoss: 1.0490\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 65.643 \tLoss: 0.9419\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 59.052 \tLoss: 1.1022\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 66.183 \tLoss: 0.9519\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 58.230 \tLoss: 1.2707\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 66.480 \tLoss: 0.9312\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 61.220 \tLoss: 1.0767\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 66.273 \tLoss: 0.9431\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 57.334 \tLoss: 1.3066\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 67.070 \tLoss: 0.9237\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 62.742 \tLoss: 1.1048\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 65.466 \tLoss: 0.9499\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 60.729 \tLoss: 1.1269\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 66.376 \tLoss: 0.9267\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 67.181 \tLoss: 0.9275\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 67.401 \tLoss: 0.9350\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 63.834 \tLoss: 1.1152\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 54.115 \tLoss: 1.6676\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 9.557 \tLoss: 4.2715\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 68.081 \tLoss: 0.8977\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 62.082 \tLoss: 1.0362\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 66.859 \tLoss: 0.9323\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 59.126 \tLoss: 1.2081\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 65.974 \tLoss: 0.9277\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 61.981 \tLoss: 1.1190\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 68.095 \tLoss: 0.9132\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 54.613 \tLoss: 1.3076\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 66.795 \tLoss: 0.9247\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 56.998 \tLoss: 1.3103\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 67.727 \tLoss: 0.9054\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client13 Test =>                   \tAcc: 67.356 \tLoss: 0.9202\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  39, Avg Accuracy 65.417 | Avg Loss 1.004\n",
      " Test: Round  39, Avg Accuracy 55.659 | Avg Loss 1.464\n",
      "==========================================================\n",
      "idxs_users [17  2 19 10  4  3 14  1  5  6 15  8 12  0  9  7 18 11 16 13]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17, 19, 10, 4, 3, 14, 1, 5, 6, 15, 8, 12, 9, 7, 18, 11, 16, 13]\n",
      "fedserver选择的客户端index: [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19]\n",
      "acc: 63.900861740112305\n",
      "acc: 11.260775804519653\n",
      "acc: 57.54310321807861\n",
      "acc: 62.863685607910156\n",
      "acc: 59.051724433898926\n",
      "acc: 58.230064392089844\n",
      "acc: 61.22036647796631\n",
      "acc: 57.33432102203369\n",
      "acc: 62.74245643615723\n",
      "acc: 60.72871780395508\n",
      "acc: 67.18076515197754\n",
      "acc: 63.833513259887695\n",
      "acc: 62.082435607910156\n",
      "acc: 59.125807762145996\n",
      "acc: 61.981411933898926\n",
      "acc: 54.61341571807861\n",
      "acc: 56.997575759887695\n",
      "acc: 67.35587310791016\n",
      "====================== Fed Server==========================\n",
      " Train: Round  39, Avg Accuracy 65.417 | Avg Loss 1.004\n",
      " Test: Round  39, Avg Accuracy 58.225 | Avg Loss 1.287\n",
      "==========================================================\n",
      "Epoch 39 finished in 00:02:01\n",
      "Epoch 39 finished. Total time: 4883.05 seconds\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 67.431 \tLoss: 0.9133\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 56.822 \tLoss: 1.3013\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 65.896 \tLoss: 0.9376\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 60.655 \tLoss: 1.1500\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 67.649 \tLoss: 0.9386\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 57.853 \tLoss: 1.1379\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 52.284 \tLoss: 1.7043\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 10.789 \tLoss: 4.3536\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 65.809 \tLoss: 0.9510\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 62.237 \tLoss: 1.1485\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 67.417 \tLoss: 0.9337\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 57.058 \tLoss: 1.1781\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 55.119 \tLoss: 1.6383\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 11.045 \tLoss: 3.9112\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 67.006 \tLoss: 0.9043\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 63.982 \tLoss: 1.1045\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 67.098 \tLoss: 0.9150\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 61.907 \tLoss: 1.0392\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 65.983 \tLoss: 0.9387\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 60.823 \tLoss: 1.1280\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 67.459 \tLoss: 0.9257\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 58.136 \tLoss: 1.2099\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 67.518 \tLoss: 0.9315\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 58.345 \tLoss: 1.3696\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 67.911 \tLoss: 0.9104\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 60.594 \tLoss: 1.1856\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 68.504 \tLoss: 0.9068\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 60.379 \tLoss: 1.1983\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 68.608 \tLoss: 0.8925\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 61.611 \tLoss: 1.1644\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 65.554 \tLoss: 0.9375\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 65.086 \tLoss: 0.9956\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 67.006 \tLoss: 0.9203\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 60.392 \tLoss: 1.1678\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 67.475 \tLoss: 0.9173\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 56.176 \tLoss: 1.3111\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 67.420 \tLoss: 0.9223\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 51.232 \tLoss: 1.5146\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 67.459 \tLoss: 0.9114\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client10 Test =>                   \tAcc: 70.777 \tLoss: 0.8111\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  40, Avg Accuracy 65.830 | Avg Loss 0.998\n",
      " Test: Round  40, Avg Accuracy 54.715 | Avg Loss 1.502\n",
      "==========================================================\n",
      "idxs_users [12  2  8 19  3  5  0 13 16  6  7 11  9 17  4 14  1 18 15 10]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 2, 8, 3, 5, 13, 16, 6, 7, 11, 9, 17, 4, 14, 1, 18, 15, 10]\n",
      "fedserver选择的客户端index: [0, 1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "acc: 56.82246780395508\n",
      "acc: 60.65463352203369\n",
      "acc: 57.852909088134766\n",
      "acc: 62.237338066101074\n",
      "acc: 57.058189392089844\n",
      "acc: 63.98168182373047\n",
      "acc: 61.90732765197754\n",
      "acc: 60.82300662994385\n",
      "acc: 58.135775566101074\n",
      "acc: 58.344557762145996\n",
      "acc: 60.59401893615723\n",
      "acc: 60.378501892089844\n",
      "acc: 61.61099147796631\n",
      "acc: 65.08620643615723\n",
      "acc: 60.391971588134766\n",
      "acc: 56.17591571807861\n",
      "acc: 51.232489585876465\n",
      "acc: 70.77720832824707\n",
      "====================== Fed Server==========================\n",
      " Train: Round  40, Avg Accuracy 65.830 | Avg Loss 0.998\n",
      " Test: Round  40, Avg Accuracy 60.226 | Avg Loss 1.173\n",
      "==========================================================\n",
      "Epoch 40 finished in 00:02:02\n",
      "Epoch 40 finished. Total time: 5005.61 seconds\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 66.726 \tLoss: 0.9230\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 56.061 \tLoss: 1.2637\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 67.776 \tLoss: 0.9266\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 60.379 \tLoss: 1.0868\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 66.889 \tLoss: 0.9294\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 63.315 \tLoss: 1.1002\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 67.289 \tLoss: 0.9041\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 59.220 \tLoss: 1.2374\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 68.148 \tLoss: 0.9073\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 65.504 \tLoss: 1.0451\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 67.358 \tLoss: 0.9081\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 63.995 \tLoss: 1.0996\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 54.701 \tLoss: 1.6677\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 10.634 \tLoss: 4.8582\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 68.911 \tLoss: 0.8939\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 54.708 \tLoss: 1.2589\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 66.425 \tLoss: 0.9247\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 56.513 \tLoss: 1.2328\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 67.792 \tLoss: 0.9061\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 63.180 \tLoss: 1.0380\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 68.433 \tLoss: 0.9061\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 62.763 \tLoss: 1.0128\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 67.826 \tLoss: 0.9071\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 56.587 \tLoss: 1.2492\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 65.926 \tLoss: 0.9228\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 57.738 \tLoss: 1.1853\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 69.106 \tLoss: 0.8806\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 58.311 \tLoss: 1.2431\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 67.840 \tLoss: 0.8928\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 64.931 \tLoss: 1.0308\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 66.756 \tLoss: 0.9252\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 61.665 \tLoss: 1.1021\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 67.020 \tLoss: 0.9043\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 63.214 \tLoss: 1.0557\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 53.817 \tLoss: 1.6730\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 11.611 \tLoss: 4.1578\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 68.162 \tLoss: 0.8985\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 63.638 \tLoss: 1.0570\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 67.236 \tLoss: 0.9101\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client8 Test =>                   \tAcc: 71.013 \tLoss: 0.8219\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  41, Avg Accuracy 66.207 | Avg Loss 0.986\n",
      " Test: Round  41, Avg Accuracy 58.618 | Avg Loss 1.280\n",
      "==========================================================\n",
      "idxs_users [ 5 15  6  9 17 12  0 10  2 16  1 11 14 18  4  3 13 19  7  8]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 15, 6, 9, 17, 12, 10, 2, 16, 1, 11, 14, 18, 4, 3, 13, 7, 8]\n",
      "fedserver选择的客户端index: [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19]\n",
      "acc: 56.06142234802246\n",
      "acc: 60.378501892089844\n",
      "acc: 63.314924240112305\n",
      "acc: 59.220096588134766\n",
      "acc: 65.50377082824707\n",
      "acc: 63.995150566101074\n",
      "acc: 54.70770454406738\n",
      "acc: 56.512661933898926\n",
      "acc: 63.18022537231445\n",
      "acc: 62.762661933898926\n",
      "acc: 56.586745262145996\n",
      "acc: 57.73841571807861\n",
      "acc: 58.31088352203369\n",
      "acc: 64.93130397796631\n",
      "acc: 61.664870262145996\n",
      "acc: 63.213900566101074\n",
      "acc: 63.638200759887695\n",
      "acc: 71.01293182373047\n",
      "====================== Fed Server==========================\n",
      " Train: Round  41, Avg Accuracy 66.207 | Avg Loss 0.986\n",
      " Test: Round  41, Avg Accuracy 61.263 | Avg Loss 1.118\n",
      "==========================================================\n",
      "Epoch 41 finished in 00:01:59\n",
      "Epoch 41 finished. Total time: 5125.45 seconds\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 67.654 \tLoss: 0.8871\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 50.317 \tLoss: 1.6516\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 67.204 \tLoss: 0.9155\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 61.079 \tLoss: 1.1581\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 68.095 \tLoss: 0.9091\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 55.866 \tLoss: 1.2700\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 66.942 \tLoss: 0.9075\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 61.375 \tLoss: 1.1667\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 66.062 \tLoss: 0.9199\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 60.924 \tLoss: 1.2376\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 67.500 \tLoss: 0.8920\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 63.039 \tLoss: 1.0719\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 54.499 \tLoss: 1.6702\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 9.463 \tLoss: 3.9889\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 67.325 \tLoss: 0.9131\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 59.341 \tLoss: 1.1689\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 67.024 \tLoss: 0.9163\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 66.325 \tLoss: 1.0583\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 68.442 \tLoss: 0.8774\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 57.974 \tLoss: 1.3263\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 52.868 \tLoss: 1.7161\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 7.779 \tLoss: 3.9800\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 68.734 \tLoss: 0.8802\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 58.109 \tLoss: 1.1348\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 67.645 \tLoss: 0.9311\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 60.089 \tLoss: 1.1519\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 67.709 \tLoss: 0.8981\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 59.126 \tLoss: 1.2765\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 67.332 \tLoss: 0.9132\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 59.052 \tLoss: 1.1141\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 68.699 \tLoss: 0.9125\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 61.611 \tLoss: 1.1507\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 68.676 \tLoss: 0.8755\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 63.746 \tLoss: 0.9900\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 67.068 \tLoss: 0.9071\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 55.651 \tLoss: 1.2211\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 67.909 \tLoss: 0.9028\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 60.082 \tLoss: 1.1798\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 67.966 \tLoss: 0.9288\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client3 Test =>                   \tAcc: 69.174 \tLoss: 0.8480\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  42, Avg Accuracy 66.268 | Avg Loss 0.984\n",
      " Test: Round  42, Avg Accuracy 57.500 | Avg Loss 1.330\n",
      "==========================================================\n",
      "idxs_users [18  8 15 13  2  4  0 14  6 16 19 17  5 12 10 11  9  1  7  3]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18, 8, 15, 13, 2, 4, 14, 6, 16, 17, 5, 12, 10, 11, 9, 1, 7, 3]\n",
      "fedserver选择的客户端index: [0, 1, 2, 3, 4, 5, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "acc: 50.31654071807861\n",
      "acc: 61.078932762145996\n",
      "acc: 55.86610984802246\n",
      "acc: 61.37526893615723\n",
      "acc: 60.92403030395508\n",
      "acc: 63.03879356384277\n",
      "acc: 59.341325759887695\n",
      "acc: 66.32543182373047\n",
      "acc: 57.974138259887695\n",
      "acc: 58.10883617401123\n",
      "acc: 60.088900566101074\n",
      "acc: 59.125807762145996\n",
      "acc: 59.051724433898926\n",
      "acc: 61.61099147796631\n",
      "acc: 63.74595832824707\n",
      "acc: 55.65059280395508\n",
      "acc: 60.08216571807861\n",
      "acc: 69.1742992401123\n",
      "====================== Fed Server==========================\n",
      " Train: Round  42, Avg Accuracy 66.268 | Avg Loss 0.984\n",
      " Test: Round  42, Avg Accuracy 60.160 | Avg Loss 1.176\n",
      "==========================================================\n",
      "Epoch 42 finished in 00:02:00\n",
      "Epoch 42 finished. Total time: 5245.54 seconds\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 54.403 \tLoss: 1.6923\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 12.251 \tLoss: 4.3610\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 67.587 \tLoss: 0.9008\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 61.045 \tLoss: 1.1739\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 68.591 \tLoss: 0.8878\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 64.312 \tLoss: 0.9990\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 68.444 \tLoss: 0.8999\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 62.729 \tLoss: 1.0658\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 67.626 \tLoss: 0.8998\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 61.220 \tLoss: 1.1248\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 67.123 \tLoss: 0.9180\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 69.215 \tLoss: 0.9048\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 66.907 \tLoss: 0.9170\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 66.298 \tLoss: 1.0360\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 66.491 \tLoss: 0.9255\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 55.065 \tLoss: 1.2781\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 67.624 \tLoss: 0.9077\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 57.839 \tLoss: 1.2026\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 68.876 \tLoss: 0.8743\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 55.024 \tLoss: 1.3306\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 66.673 \tLoss: 0.9023\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 60.574 \tLoss: 1.1831\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 66.818 \tLoss: 0.9222\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 58.856 \tLoss: 1.2449\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 68.084 \tLoss: 0.8938\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 58.540 \tLoss: 1.2241\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 53.109 \tLoss: 1.6814\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 11.611 \tLoss: 4.3403\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 67.518 \tLoss: 0.8994\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 62.055 \tLoss: 1.0314\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 68.385 \tLoss: 0.9051\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 59.793 \tLoss: 1.2209\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 67.918 \tLoss: 0.8950\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 59.085 \tLoss: 1.1888\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 68.270 \tLoss: 0.8735\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 63.349 \tLoss: 1.0225\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 67.727 \tLoss: 0.8982\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 64.931 \tLoss: 0.9683\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 69.554 \tLoss: 0.8959\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client16 Test =>                   \tAcc: 70.696 \tLoss: 0.8161\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 3, 4, 5, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  43, Avg Accuracy 66.386 | Avg Loss 0.979\n",
      " Test: Round  43, Avg Accuracy 55.979 | Avg Loss 1.472\n",
      "==========================================================\n",
      "idxs_users [19 18  4 11 12  8  6  5  1  7  3 14 13  0 10  2 17  9 15 16]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18, 4, 11, 12, 8, 6, 5, 1, 7, 3, 14, 13, 10, 2, 17, 9, 15, 16]\n",
      "fedserver选择的客户端index: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19]\n",
      "acc: 61.04525852203369\n",
      "acc: 64.31169128417969\n",
      "acc: 62.728986740112305\n",
      "acc: 61.22036647796631\n",
      "acc: 69.21470832824707\n",
      "acc: 66.29849147796631\n",
      "acc: 55.06465530395508\n",
      "acc: 57.839439392089844\n",
      "acc: 55.024245262145996\n",
      "acc: 60.573814392089844\n",
      "acc: 58.856411933898926\n",
      "acc: 58.539870262145996\n",
      "acc: 62.055495262145996\n",
      "acc: 59.792564392089844\n",
      "acc: 59.08539867401123\n",
      "acc: 63.348599433898926\n",
      "acc: 64.93130397796631\n",
      "acc: 70.69639015197754\n",
      "====================== Fed Server==========================\n",
      " Train: Round  43, Avg Accuracy 66.386 | Avg Loss 0.979\n",
      " Test: Round  43, Avg Accuracy 61.702 | Avg Loss 1.112\n",
      "==========================================================\n",
      "Epoch 43 finished in 00:01:59\n",
      "Epoch 43 finished. Total time: 5364.85 seconds\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 67.831 \tLoss: 0.9052\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 58.190 \tLoss: 1.2643\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 66.988 \tLoss: 0.9000\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 62.076 \tLoss: 1.1469\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 67.155 \tLoss: 0.9089\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 62.588 \tLoss: 1.0114\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 69.403 \tLoss: 0.8786\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 56.553 \tLoss: 1.1611\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 53.876 \tLoss: 1.7031\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 5.630 \tLoss: 4.3350\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 69.708 \tLoss: 0.8764\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 58.169 \tLoss: 1.2953\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 67.932 \tLoss: 0.8930\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 62.574 \tLoss: 0.9737\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 68.920 \tLoss: 0.8840\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 60.695 \tLoss: 1.2738\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 68.488 \tLoss: 0.8921\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 56.452 \tLoss: 1.4005\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 67.631 \tLoss: 0.8952\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 59.207 \tLoss: 1.1018\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 68.803 \tLoss: 0.8657\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 58.250 \tLoss: 1.2815\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 69.285 \tLoss: 0.8769\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 63.254 \tLoss: 1.0736\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 68.212 \tLoss: 0.9020\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 62.372 \tLoss: 1.0971\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 69.403 \tLoss: 0.8929\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 59.853 \tLoss: 1.2043\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 68.300 \tLoss: 0.8782\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 55.725 \tLoss: 1.3800\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 68.297 \tLoss: 0.8898\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 56.863 \tLoss: 1.2907\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 69.154 \tLoss: 0.8606\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 59.887 \tLoss: 1.1362\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 69.072 \tLoss: 0.8642\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 58.446 \tLoss: 1.2245\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 53.782 \tLoss: 1.6929\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 13.625 \tLoss: 4.2258\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 68.465 \tLoss: 0.8859\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client1 Test =>                   \tAcc: 66.925 \tLoss: 0.8702\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  44, Avg Accuracy 67.035 | Avg Loss 0.967\n",
      " Test: Round  44, Avg Accuracy 54.405 | Avg Loss 1.516\n",
      "==========================================================\n",
      "idxs_users [ 2  3 15  4 19 16 10  6  5  8 17 11 14  7 18 12  9 13  0  1]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 15, 4, 16, 10, 6, 5, 8, 17, 11, 14, 7, 18, 12, 9, 13, 1]\n",
      "fedserver选择的客户端index: [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19]\n",
      "acc: 58.18965530395508\n",
      "acc: 62.075700759887695\n",
      "acc: 62.58755397796631\n",
      "acc: 56.55307102203369\n",
      "acc: 58.169450759887695\n",
      "acc: 62.57408332824707\n",
      "acc: 60.69504356384277\n",
      "acc: 56.45204734802246\n",
      "acc: 59.206626892089844\n",
      "acc: 58.25026893615723\n",
      "acc: 63.254310607910156\n",
      "acc: 62.372036933898926\n",
      "acc: 59.85317897796631\n",
      "acc: 55.724677085876465\n",
      "acc: 56.862876892089844\n",
      "acc: 59.88685321807861\n",
      "acc: 58.44558143615723\n",
      "acc: 66.92483806610107\n",
      "====================== Fed Server==========================\n",
      " Train: Round  44, Avg Accuracy 67.035 | Avg Loss 0.967\n",
      " Test: Round  44, Avg Accuracy 59.893 | Avg Loss 1.177\n",
      "==========================================================\n",
      "Epoch 44 finished in 00:01:59\n",
      "Epoch 44 finished. Total time: 5484.30 seconds\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 68.920 \tLoss: 0.8703\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 59.597 \tLoss: 1.1959\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 68.065 \tLoss: 0.9000\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 59.772 \tLoss: 1.1751\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 70.317 \tLoss: 0.8431\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 65.268 \tLoss: 0.9804\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 52.463 \tLoss: 1.7366\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 13.120 \tLoss: 4.6255\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 67.532 \tLoss: 0.9027\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 61.241 \tLoss: 1.1068\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 69.085 \tLoss: 0.8552\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 59.968 \tLoss: 1.1777\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 68.286 \tLoss: 0.8894\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 54.849 \tLoss: 1.3815\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 66.716 \tLoss: 0.9132\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 61.948 \tLoss: 1.0502\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 69.154 \tLoss: 0.8750\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 64.096 \tLoss: 1.0171\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 70.014 \tLoss: 0.8667\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 58.991 \tLoss: 1.2309\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 67.284 \tLoss: 0.8926\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 63.955 \tLoss: 1.0294\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 68.343 \tLoss: 0.8858\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 60.655 \tLoss: 1.0738\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 68.872 \tLoss: 0.8858\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 64.621 \tLoss: 1.0301\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 69.717 \tLoss: 0.8559\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 63.921 \tLoss: 1.0232\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 69.789 \tLoss: 0.8562\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 63.099 \tLoss: 1.1202\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 67.585 \tLoss: 0.8787\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 58.661 \tLoss: 1.2323\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 68.587 \tLoss: 0.8979\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 52.189 \tLoss: 1.5092\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 70.260 \tLoss: 0.8668\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 56.075 \tLoss: 1.4155\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 53.281 \tLoss: 1.7613\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 6.122 \tLoss: 4.2444\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 69.017 \tLoss: 0.8825\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client18 Test =>                   \tAcc: 66.689 \tLoss: 0.9627\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  45, Avg Accuracy 67.164 | Avg Loss 0.966\n",
      " Test: Round  45, Avg Accuracy 58.193 | Avg Loss 1.346\n",
      "==========================================================\n",
      "idxs_users [12  5  4  0  1  7 11 14 15 17  3 10  8  9 13  6  2 16 19 18]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 5, 4, 1, 7, 11, 14, 15, 17, 3, 10, 8, 9, 13, 6, 2, 16, 18]\n",
      "fedserver选择的客户端index: [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19]\n",
      "acc: 59.597251892089844\n",
      "acc: 59.77235984802246\n",
      "acc: 65.2680492401123\n",
      "acc: 61.24057102203369\n",
      "acc: 59.96767234802246\n",
      "acc: 54.849138259887695\n",
      "acc: 61.947736740112305\n",
      "acc: 64.0961742401123\n",
      "acc: 58.99110984802246\n",
      "acc: 63.95474147796631\n",
      "acc: 60.65463352203369\n",
      "acc: 64.62149810791016\n",
      "acc: 63.92106628417969\n",
      "acc: 63.09940719604492\n",
      "acc: 58.661099433898926\n",
      "acc: 52.188846588134766\n",
      "acc: 56.07489204406738\n",
      "acc: 66.68911647796631\n",
      "====================== Fed Server==========================\n",
      " Train: Round  45, Avg Accuracy 67.164 | Avg Loss 0.966\n",
      " Test: Round  45, Avg Accuracy 60.866 | Avg Loss 1.151\n",
      "==========================================================\n",
      "Epoch 45 finished in 00:01:59\n",
      "Epoch 45 finished. Total time: 5603.77 seconds\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 69.632 \tLoss: 0.8725\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 62.594 \tLoss: 1.0352\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 69.623 \tLoss: 0.8530\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 60.850 \tLoss: 1.1299\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 68.637 \tLoss: 0.8759\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 64.170 \tLoss: 1.1065\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 69.602 \tLoss: 0.8504\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 62.359 \tLoss: 1.0848\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 68.796 \tLoss: 0.8581\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 57.105 \tLoss: 1.2742\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 68.656 \tLoss: 0.8691\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 61.402 \tLoss: 1.2411\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 68.019 \tLoss: 0.8789\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 56.452 \tLoss: 1.4343\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 69.871 \tLoss: 0.8754\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 59.772 \tLoss: 1.1719\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 68.929 \tLoss: 0.8525\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 61.335 \tLoss: 1.1151\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 69.954 \tLoss: 0.8539\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 61.705 \tLoss: 1.1238\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 53.500 \tLoss: 1.7188\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 8.877 \tLoss: 5.0554\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 69.979 \tLoss: 0.8693\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 59.577 \tLoss: 1.2361\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 68.222 \tLoss: 0.8690\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 62.116 \tLoss: 0.9842\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 68.844 \tLoss: 0.8914\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 56.917 \tLoss: 1.2389\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 69.177 \tLoss: 0.8597\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 63.443 \tLoss: 1.0460\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 68.031 \tLoss: 0.9038\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 52.930 \tLoss: 1.4617\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 68.460 \tLoss: 0.8815\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 63.019 \tLoss: 0.9645\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 54.095 \tLoss: 1.6886\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 4.964 \tLoss: 3.9100\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 70.048 \tLoss: 0.8360\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 63.975 \tLoss: 1.1050\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 69.722 \tLoss: 0.8589\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client17 Test =>                   \tAcc: 69.370 \tLoss: 0.8474\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  46, Avg Accuracy 67.590 | Avg Loss 0.951\n",
      " Test: Round  46, Avg Accuracy 54.811 | Avg Loss 1.521\n",
      "==========================================================\n",
      "idxs_users [10 13  6  9 18  2 14  3 11  4 19  1  8  7 16  5 15  0 12 17]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 6, 9, 18, 2, 14, 3, 11, 4, 1, 8, 7, 16, 5, 15, 0, 12, 17]\n",
      "fedserver选择的客户端index: [0, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "acc: 62.59428787231445\n",
      "acc: 64.17025852203369\n",
      "acc: 62.35856628417969\n",
      "acc: 57.10533428192139\n",
      "acc: 61.40220832824707\n",
      "acc: 56.45204734802246\n",
      "acc: 59.77235984802246\n",
      "acc: 61.33485984802246\n",
      "acc: 61.70528030395508\n",
      "acc: 59.57704734802246\n",
      "acc: 62.11610984802246\n",
      "acc: 56.91675662994385\n",
      "acc: 63.442888259887695\n",
      "acc: 52.9296875\n",
      "acc: 63.018588066101074\n",
      "acc: 4.963631451129913\n",
      "acc: 63.97494602203369\n",
      "acc: 69.3696117401123\n",
      "====================== Fed Server==========================\n",
      " Train: Round  46, Avg Accuracy 67.590 | Avg Loss 0.951\n",
      " Test: Round  46, Avg Accuracy 57.956 | Avg Loss 1.299\n",
      "==========================================================\n",
      "Epoch 46 finished in 00:01:59\n",
      "Epoch 46 finished. Total time: 5723.26 seconds\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 68.063 \tLoss: 0.8682\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 54.304 \tLoss: 1.4336\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 69.219 \tLoss: 0.8635\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 58.600 \tLoss: 1.2984\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 70.326 \tLoss: 0.8496\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 64.170 \tLoss: 0.9655\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 69.060 \tLoss: 0.8630\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 67.632 \tLoss: 1.0147\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 69.543 \tLoss: 0.8575\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 62.412 \tLoss: 0.9839\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 70.331 \tLoss: 0.8558\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 55.334 \tLoss: 1.4072\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 67.438 \tLoss: 0.8948\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 56.708 \tLoss: 1.2884\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 68.768 \tLoss: 0.8622\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 63.706 \tLoss: 1.1212\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 69.060 \tLoss: 0.8638\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 61.086 \tLoss: 1.1070\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 69.589 \tLoss: 0.8631\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 60.998 \tLoss: 1.1869\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 68.964 \tLoss: 0.8748\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 64.386 \tLoss: 1.0062\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 69.671 \tLoss: 0.8531\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 63.800 \tLoss: 1.0339\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 54.412 \tLoss: 1.7001\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 6.701 \tLoss: 3.9090\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 68.856 \tLoss: 0.8737\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 63.726 \tLoss: 1.0457\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 68.038 \tLoss: 0.8813\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 62.453 \tLoss: 1.0746\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 68.591 \tLoss: 0.8678\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 66.009 \tLoss: 0.9930\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 68.435 \tLoss: 0.8507\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 60.567 \tLoss: 1.1302\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 52.730 \tLoss: 1.7508\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 12.177 \tLoss: 4.3784\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 69.766 \tLoss: 0.8541\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 61.631 \tLoss: 1.1164\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 68.890 \tLoss: 0.8702\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client17 Test =>                   \tAcc: 71.074 \tLoss: 0.8125\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  47, Avg Accuracy 67.487 | Avg Loss 0.951\n",
      " Test: Round  47, Avg Accuracy 56.360 | Avg Loss 1.445\n",
      "==========================================================\n",
      "idxs_users [14 18 10  6  4  7  5 12 11  2  8  9  0 16  3 15  1 19 13 17]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14, 18, 10, 6, 4, 7, 5, 12, 11, 2, 8, 9, 16, 3, 15, 1, 13, 17]\n",
      "fedserver选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 18, 19]\n",
      "acc: 54.30360984802246\n",
      "acc: 58.60048484802246\n",
      "acc: 64.17025852203369\n",
      "acc: 67.63200378417969\n",
      "acc: 62.41244602203369\n",
      "acc: 55.334052085876465\n",
      "acc: 56.707974433898926\n",
      "acc: 63.705549240112305\n",
      "acc: 61.08566856384277\n",
      "acc: 60.998114585876465\n",
      "acc: 64.38577556610107\n",
      "acc: 63.799838066101074\n",
      "acc: 63.72575378417969\n",
      "acc: 62.45285606384277\n",
      "acc: 66.00889015197754\n",
      "acc: 60.56707954406738\n",
      "acc: 61.63119602203369\n",
      "acc: 71.07354545593262\n",
      "====================== Fed Server==========================\n",
      " Train: Round  47, Avg Accuracy 67.487 | Avg Loss 0.951\n",
      " Test: Round  47, Avg Accuracy 62.144 | Avg Loss 1.112\n",
      "==========================================================\n",
      "Epoch 47 finished in 00:01:59\n",
      "Epoch 47 finished. Total time: 5842.48 seconds\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 69.862 \tLoss: 0.8369\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 57.429 \tLoss: 1.3979\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 70.209 \tLoss: 0.8385\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 64.817 \tLoss: 0.9776\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 52.277 \tLoss: 1.8198\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 10.789 \tLoss: 4.0546\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 54.251 \tLoss: 1.7499\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 8.075 \tLoss: 4.0534\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 71.611 \tLoss: 0.8241\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 65.228 \tLoss: 1.1769\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 70.501 \tLoss: 0.8436\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 62.588 \tLoss: 1.0841\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 70.522 \tLoss: 0.8599\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 60.439 \tLoss: 1.0955\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 70.669 \tLoss: 0.8418\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 60.123 \tLoss: 1.0817\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 69.076 \tLoss: 0.8453\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 61.712 \tLoss: 1.0115\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 70.296 \tLoss: 0.8394\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 66.844 \tLoss: 0.9579\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 70.960 \tLoss: 0.8309\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 55.805 \tLoss: 1.3437\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 68.318 \tLoss: 0.8747\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 59.597 \tLoss: 1.2523\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 69.529 \tLoss: 0.8610\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 57.799 \tLoss: 1.2689\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 69.260 \tLoss: 0.8529\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 61.045 \tLoss: 1.0323\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 69.396 \tLoss: 0.8516\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 58.567 \tLoss: 1.1663\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 69.380 \tLoss: 0.8609\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 65.847 \tLoss: 1.0108\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 69.182 \tLoss: 0.8674\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 62.682 \tLoss: 1.1044\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 70.726 \tLoss: 0.8373\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 63.719 \tLoss: 1.1016\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 68.026 \tLoss: 0.8751\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 54.708 \tLoss: 1.6752\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 69.017 \tLoss: 0.8567\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client6 Test =>                   \tAcc: 71.734 \tLoss: 0.8488\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  48, Avg Accuracy 68.153 | Avg Loss 0.943\n",
      " Test: Round  48, Avg Accuracy 56.002 | Avg Loss 1.462\n",
      "==========================================================\n",
      "idxs_users [ 7 16 19  0  4 13 15 10  3  9 17 14 12  1 18  8  2 11  5  6]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 16, 0, 4, 13, 15, 10, 3, 9, 17, 14, 12, 1, 8, 2, 11, 5, 6]\n",
      "fedserver选择的客户端index: [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19]\n",
      "acc: 57.42860984802246\n",
      "acc: 64.81681060791016\n",
      "acc: 8.075161695480347\n",
      "acc: 65.22764015197754\n",
      "acc: 62.58755397796631\n",
      "acc: 60.43911647796631\n",
      "acc: 60.122575759887695\n",
      "acc: 61.71201515197754\n",
      "acc: 66.84401893615723\n",
      "acc: 55.805495262145996\n",
      "acc: 59.597251892089844\n",
      "acc: 57.79903030395508\n",
      "acc: 61.04525852203369\n",
      "acc: 65.84725189208984\n",
      "acc: 62.68184280395508\n",
      "acc: 63.71901893615723\n",
      "acc: 54.70770454406738\n",
      "acc: 71.73356628417969\n",
      "====================== Fed Server==========================\n",
      " Train: Round  48, Avg Accuracy 68.153 | Avg Loss 0.943\n",
      " Test: Round  48, Avg Accuracy 58.899 | Avg Loss 1.304\n",
      "==========================================================\n",
      "Epoch 48 finished in 00:01:59\n",
      "Epoch 48 finished. Total time: 5962.20 seconds\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 70.765 \tLoss: 0.8076\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 64.036 \tLoss: 1.0297\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 69.646 \tLoss: 0.8380\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 60.264 \tLoss: 1.1604\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 69.536 \tLoss: 0.8622\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 65.383 \tLoss: 1.0397\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 71.147 \tLoss: 0.8248\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 61.672 \tLoss: 1.1673\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 70.717 \tLoss: 0.8411\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 60.769 \tLoss: 1.1888\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 71.250 \tLoss: 0.8266\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 62.062 \tLoss: 1.1544\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 53.164 \tLoss: 1.7767\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 11.160 \tLoss: 5.6448\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 70.200 \tLoss: 0.8289\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 62.608 \tLoss: 1.0513\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 70.083 \tLoss: 0.8487\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 65.753 \tLoss: 0.9547\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 70.416 \tLoss: 0.8532\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 64.190 \tLoss: 0.9639\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 68.640 \tLoss: 0.8624\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 65.713 \tLoss: 1.0018\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 69.120 \tLoss: 0.8584\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 64.386 \tLoss: 1.0245\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 70.825 \tLoss: 0.8508\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 63.288 \tLoss: 1.0104\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 69.885 \tLoss: 0.8455\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 60.729 \tLoss: 1.1477\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 69.823 \tLoss: 0.8327\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 62.237 \tLoss: 1.0823\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 53.833 \tLoss: 1.6860\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 8.506 \tLoss: 4.0946\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 69.472 \tLoss: 0.8341\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 61.604 \tLoss: 1.0205\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 69.931 \tLoss: 0.8566\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 56.432 \tLoss: 1.3650\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 70.101 \tLoss: 0.8565\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 59.968 \tLoss: 1.2179\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 69.720 \tLoss: 0.8487\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client12 Test =>                   \tAcc: 70.912 \tLoss: 0.8650\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  49, Avg Accuracy 68.414 | Avg Loss 0.932\n",
      " Test: Round  49, Avg Accuracy 56.892 | Avg Loss 1.503\n",
      "==========================================================\n",
      "idxs_users [ 9  1  2 16  7  4 19 14 17 15  6  3  8 18 13  0 10  5 11 12]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 1, 2, 16, 7, 4, 14, 17, 15, 6, 3, 8, 18, 13, 10, 5, 11, 12]\n",
      "fedserver选择的客户端index: [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19]\n",
      "acc: 64.03556060791016\n",
      "acc: 60.26400852203369\n",
      "acc: 65.38254356384277\n",
      "acc: 61.67160606384277\n",
      "acc: 60.769126892089844\n",
      "acc: 62.06223106384277\n",
      "acc: 62.60775852203369\n",
      "acc: 65.75296306610107\n",
      "acc: 64.19046306610107\n",
      "acc: 65.71255397796631\n",
      "acc: 64.38577556610107\n",
      "acc: 63.28798484802246\n",
      "acc: 60.72871780395508\n",
      "acc: 62.237338066101074\n",
      "acc: 61.60425662994385\n",
      "acc: 56.43184280395508\n",
      "acc: 59.96767234802246\n",
      "acc: 70.91190719604492\n",
      "====================== Fed Server==========================\n",
      " Train: Round  49, Avg Accuracy 68.414 | Avg Loss 0.932\n",
      " Test: Round  49, Avg Accuracy 62.889 | Avg Loss 1.080\n",
      "==========================================================\n",
      "Epoch 49 finished in 00:01:59\n",
      "Epoch 49 finished. Total time: 6081.68 seconds\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 68.674 \tLoss: 0.8408\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 65.854 \tLoss: 1.0610\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 70.402 \tLoss: 0.8255\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 62.769 \tLoss: 1.0156\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 55.921 \tLoss: 1.6940\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 6.412 \tLoss: 5.1442\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 69.945 \tLoss: 0.8368\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 57.584 \tLoss: 1.2513\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 69.106 \tLoss: 0.8499\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 61.200 \tLoss: 1.1165\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 70.540 \tLoss: 0.8404\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 65.719 \tLoss: 1.0092\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 69.575 \tLoss: 0.8536\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 66.554 \tLoss: 0.9501\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 71.064 \tLoss: 0.8362\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 58.661 \tLoss: 1.3149\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 69.779 \tLoss: 0.8408\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 58.991 \tLoss: 1.2844\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 70.607 \tLoss: 0.8387\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 61.065 \tLoss: 1.1176\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 69.235 \tLoss: 0.8626\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 58.156 \tLoss: 1.1895\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 70.756 \tLoss: 0.8372\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 62.985 \tLoss: 1.1708\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 53.428 \tLoss: 1.7559\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 8.055 \tLoss: 5.1127\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 69.076 \tLoss: 0.8661\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 62.278 \tLoss: 1.1110\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 70.903 \tLoss: 0.8248\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 64.682 \tLoss: 0.9653\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 69.736 \tLoss: 0.8266\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 61.261 \tLoss: 1.1029\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 70.370 \tLoss: 0.8334\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 56.466 \tLoss: 1.3940\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 70.526 \tLoss: 0.8571\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 63.679 \tLoss: 1.0552\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 70.271 \tLoss: 0.8329\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 55.455 \tLoss: 1.4178\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 70.331 \tLoss: 0.8389\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client18 Test =>                   \tAcc: 66.985 \tLoss: 0.9410\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  50, Avg Accuracy 68.512 | Avg Loss 0.930\n",
      " Test: Round  50, Avg Accuracy 55.389 | Avg Loss 1.593\n",
      "==========================================================\n",
      "idxs_users [14  9  0 10  6  8  3  7  2 16 11 12 19  5 17 13  4 15  1 18]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14, 9, 10, 6, 8, 3, 7, 2, 16, 11, 12, 5, 17, 13, 4, 15, 1, 18]\n",
      "fedserver选择的客户端index: [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19]\n",
      "acc: 65.8539867401123\n",
      "acc: 62.76939582824707\n",
      "acc: 57.583513259887695\n",
      "acc: 61.200161933898926\n",
      "acc: 65.71928787231445\n",
      "acc: 66.55441856384277\n",
      "acc: 58.661099433898926\n",
      "acc: 58.99110984802246\n",
      "acc: 61.065463066101074\n",
      "acc: 58.15598106384277\n",
      "acc: 62.98491287231445\n",
      "acc: 62.277748107910156\n",
      "acc: 64.6821117401123\n",
      "acc: 61.260775566101074\n",
      "acc: 56.46551704406738\n",
      "acc: 63.67860984802246\n",
      "acc: 55.45528030395508\n",
      "acc: 66.98545265197754\n",
      "====================== Fed Server==========================\n",
      " Train: Round  50, Avg Accuracy 68.512 | Avg Loss 0.930\n",
      " Test: Round  50, Avg Accuracy 61.686 | Avg Loss 1.137\n",
      "==========================================================\n",
      "Epoch 50 finished in 00:02:00\n",
      "Epoch 50 finished. Total time: 6201.75 seconds\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 70.165 \tLoss: 0.8278\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 64.446 \tLoss: 1.0295\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 69.949 \tLoss: 0.8265\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 67.208 \tLoss: 0.9229\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 69.768 \tLoss: 0.8316\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 65.228 \tLoss: 1.0092\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 70.014 \tLoss: 0.8375\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 60.709 \tLoss: 1.2041\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 69.607 \tLoss: 0.8526\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 59.894 \tLoss: 1.2151\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 70.696 \tLoss: 0.8167\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 62.547 \tLoss: 1.1327\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 70.122 \tLoss: 0.8256\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 58.742 \tLoss: 1.2266\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 69.989 \tLoss: 0.8333\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 65.194 \tLoss: 1.1023\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 71.312 \tLoss: 0.8385\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 60.533 \tLoss: 1.2400\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 71.147 \tLoss: 0.8244\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 66.325 \tLoss: 0.9691\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 70.110 \tLoss: 0.8341\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 65.032 \tLoss: 0.9740\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 70.094 \tLoss: 0.8494\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 64.736 \tLoss: 0.9837\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 53.284 \tLoss: 1.7540\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 10.985 \tLoss: 3.8598\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 71.009 \tLoss: 0.8185\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 64.547 \tLoss: 0.9800\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 52.429 \tLoss: 1.7464\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 11.631 \tLoss: 3.9698\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 69.917 \tLoss: 0.8279\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 62.473 \tLoss: 1.0349\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 71.376 \tLoss: 0.8006\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 58.486 \tLoss: 1.2304\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 69.920 \tLoss: 0.8348\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 64.379 \tLoss: 0.9926\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 71.937 \tLoss: 0.8152\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 64.251 \tLoss: 1.0780\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 71.537 \tLoss: 0.7920\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client9 Test =>                   \tAcc: 70.993 \tLoss: 0.8095\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  51, Avg Accuracy 68.719 | Avg Loss 0.919\n",
      " Test: Round  51, Avg Accuracy 60.674 | Avg Loss 1.228\n",
      "==========================================================\n",
      "idxs_users [14 16 13  2  5  7 18  6 11  4 10  3 19  1  0 15 17  8 12  9]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14, 16, 13, 2, 5, 7, 18, 6, 11, 4, 10, 3, 1, 15, 17, 8, 12, 9]\n",
      "fedserver选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 15, 16, 17, 18, 19]\n",
      "acc: 64.44639015197754\n",
      "acc: 67.20770454406738\n",
      "acc: 65.22764015197754\n",
      "acc: 60.708513259887695\n",
      "acc: 59.893588066101074\n",
      "acc: 62.54714393615723\n",
      "acc: 58.74191856384277\n",
      "acc: 65.19396591186523\n",
      "acc: 60.53340530395508\n",
      "acc: 66.32543182373047\n",
      "acc: 65.03232765197754\n",
      "acc: 64.73599147796631\n",
      "acc: 64.54741287231445\n",
      "acc: 62.473060607910156\n",
      "acc: 58.48599147796631\n",
      "acc: 64.37904071807861\n",
      "acc: 64.25107765197754\n",
      "acc: 70.99272537231445\n",
      "====================== Fed Server==========================\n",
      " Train: Round  51, Avg Accuracy 68.719 | Avg Loss 0.919\n",
      " Test: Round  51, Avg Accuracy 63.651 | Avg Loss 1.063\n",
      "==========================================================\n",
      "Epoch 51 finished in 00:01:59\n",
      "Epoch 51 finished. Total time: 6321.26 seconds\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 71.229 \tLoss: 0.8148\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 65.975 \tLoss: 1.0795\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 70.834 \tLoss: 0.8144\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 63.645 \tLoss: 1.1197\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 71.542 \tLoss: 0.8059\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 63.113 \tLoss: 1.1060\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 70.774 \tLoss: 0.8288\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 66.480 \tLoss: 0.9792\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 71.576 \tLoss: 0.8135\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 63.786 \tLoss: 1.1066\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 71.728 \tLoss: 0.8031\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 60.143 \tLoss: 1.1196\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 71.025 \tLoss: 0.8137\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 61.887 \tLoss: 1.1798\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 70.503 \tLoss: 0.8099\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 63.214 \tLoss: 1.1057\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 71.128 \tLoss: 0.8155\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 62.426 \tLoss: 1.0542\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 69.198 \tLoss: 0.8505\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 63.645 \tLoss: 0.9521\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 55.391 \tLoss: 1.7522\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 7.934 \tLoss: 3.7774\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 70.365 \tLoss: 0.8523\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 65.968 \tLoss: 1.0042\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 70.078 \tLoss: 0.8389\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 66.750 \tLoss: 0.9769\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 69.269 \tLoss: 0.8399\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 60.183 \tLoss: 1.2850\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 70.414 \tLoss: 0.8244\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 59.166 \tLoss: 1.1863\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 53.920 \tLoss: 1.7550\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 17.006 \tLoss: 5.4295\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 70.869 \tLoss: 0.8040\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 56.802 \tLoss: 1.2879\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 71.386 \tLoss: 0.8076\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 64.076 \tLoss: 1.0589\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 70.565 \tLoss: 0.8337\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 59.907 \tLoss: 1.1870\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 70.960 \tLoss: 0.8126\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client11 Test =>                   \tAcc: 70.602 \tLoss: 0.8503\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  52, Avg Accuracy 69.138 | Avg Loss 0.915\n",
      " Test: Round  52, Avg Accuracy 57.600 | Avg Loss 1.482\n",
      "==========================================================\n",
      "idxs_users [12  2  4 15  7  1 13 16  9  3  0  5  8  6 18 19 10 17 14 11]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 4, 15, 7, 1, 13, 16, 9, 3, 5, 8, 6, 18, 19, 10, 17, 14, 11]\n",
      "fedserver选择的客户端index: [0, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "acc: 65.97521591186523\n",
      "acc: 63.112876892089844\n",
      "acc: 66.48033332824707\n",
      "acc: 63.78636932373047\n",
      "acc: 60.14278030395508\n",
      "acc: 61.887123107910156\n",
      "acc: 63.213900566101074\n",
      "acc: 62.42591571807861\n",
      "acc: 63.644935607910156\n",
      "acc: 65.96848106384277\n",
      "acc: 66.74973106384277\n",
      "acc: 60.183189392089844\n",
      "acc: 59.16621780395508\n",
      "acc: 17.005657196044922\n",
      "acc: 56.802263259887695\n",
      "acc: 64.07596969604492\n",
      "acc: 59.907057762145996\n",
      "acc: 70.60210037231445\n",
      "====================== Fed Server==========================\n",
      " Train: Round  52, Avg Accuracy 69.138 | Avg Loss 0.915\n",
      " Test: Round  52, Avg Accuracy 60.618 | Avg Loss 1.330\n",
      "==========================================================\n",
      "Epoch 52 finished in 00:01:59\n",
      "Epoch 52 finished. Total time: 6440.88 seconds\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 69.736 \tLoss: 0.8399\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 54.647 \tLoss: 1.2757\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 71.530 \tLoss: 0.8123\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 66.676 \tLoss: 1.0305\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 71.039 \tLoss: 0.7827\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 67.241 \tLoss: 0.9928\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 53.989 \tLoss: 1.7533\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 7.469 \tLoss: 4.0942\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 70.085 \tLoss: 0.8187\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 61.241 \tLoss: 1.2045\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 71.351 \tLoss: 0.8307\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 64.871 \tLoss: 1.0535\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 71.298 \tLoss: 0.8250\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 63.470 \tLoss: 1.0778\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 72.040 \tLoss: 0.8074\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 60.217 \tLoss: 1.1664\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 71.420 \tLoss: 0.7790\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 64.116 \tLoss: 0.9948\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 71.420 \tLoss: 0.8156\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 67.531 \tLoss: 0.9390\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 72.378 \tLoss: 0.7960\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 66.265 \tLoss: 0.9557\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 54.030 \tLoss: 1.7824\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 14.116 \tLoss: 4.3418\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 71.278 \tLoss: 0.8080\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 60.594 \tLoss: 1.1094\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 70.439 \tLoss: 0.8271\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 63.901 \tLoss: 1.0561\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 71.048 \tLoss: 0.8075\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 62.433 \tLoss: 1.1027\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 70.414 \tLoss: 0.8442\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 61.133 \tLoss: 1.1418\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 71.801 \tLoss: 0.8034\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 61.631 \tLoss: 1.1505\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 71.585 \tLoss: 0.8038\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 65.834 \tLoss: 1.0387\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 69.598 \tLoss: 0.8293\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 58.116 \tLoss: 1.3024\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 71.234 \tLoss: 0.8199\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client15 Test =>                   \tAcc: 71.383 \tLoss: 0.7566\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  53, Avg Accuracy 69.386 | Avg Loss 0.909\n",
      " Test: Round  53, Avg Accuracy 57.219 | Avg Loss 1.433\n",
      "==========================================================\n",
      "idxs_users [ 8 11  9  0  6  5  7 18  1 16  4 19 10 14 13  2 12 17  3 15]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 11, 9, 6, 5, 7, 18, 1, 16, 4, 10, 14, 13, 2, 12, 17, 3, 15]\n",
      "fedserver选择的客户端index: [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "acc: 54.647090911865234\n",
      "acc: 66.67564582824707\n",
      "acc: 67.24137878417969\n",
      "acc: 61.24057102203369\n",
      "acc: 64.87068939208984\n",
      "acc: 63.46982765197754\n",
      "acc: 60.216864585876465\n",
      "acc: 64.11637878417969\n",
      "acc: 67.53098106384277\n",
      "acc: 66.26481628417969\n",
      "acc: 60.59401893615723\n",
      "acc: 63.900861740112305\n",
      "acc: 62.432650566101074\n",
      "acc: 61.1328125\n",
      "acc: 61.63119602203369\n",
      "acc: 65.83378219604492\n",
      "acc: 58.11557102203369\n",
      "acc: 71.38335037231445\n",
      "====================== Fed Server==========================\n",
      " Train: Round  53, Avg Accuracy 69.386 | Avg Loss 0.909\n",
      " Test: Round  53, Avg Accuracy 63.405 | Avg Loss 1.075\n",
      "==========================================================\n",
      "Epoch 53 finished in 00:01:59\n",
      "Epoch 53 finished. Total time: 6560.35 seconds\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 55.209 \tLoss: 1.7508\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 5.846 \tLoss: 3.6615\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 70.083 \tLoss: 0.8179\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 62.433 \tLoss: 1.0386\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 72.314 \tLoss: 0.7855\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 67.066 \tLoss: 0.9788\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 71.248 \tLoss: 0.8104\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 61.571 \tLoss: 1.0773\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 69.979 \tLoss: 0.8218\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 61.806 \tLoss: 1.0039\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 70.954 \tLoss: 0.8132\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 63.194 \tLoss: 1.0250\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 72.705 \tLoss: 0.7909\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 58.425 \tLoss: 1.1534\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 72.383 \tLoss: 0.7986\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 61.537 \tLoss: 1.2052\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 72.530 \tLoss: 0.7852\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 63.605 \tLoss: 0.9526\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 71.390 \tLoss: 0.8144\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 64.702 \tLoss: 1.0588\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 71.664 \tLoss: 0.8079\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 61.490 \tLoss: 1.0810\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 72.031 \tLoss: 0.8007\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 65.308 \tLoss: 0.9927\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 70.995 \tLoss: 0.8245\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 59.112 \tLoss: 1.2269\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 70.972 \tLoss: 0.8050\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 61.981 \tLoss: 1.0893\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 69.876 \tLoss: 0.8259\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 61.200 \tLoss: 1.1370\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 52.925 \tLoss: 1.7940\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 9.072 \tLoss: 4.8479\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 69.710 \tLoss: 0.8364\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 62.628 \tLoss: 1.1373\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 70.062 \tLoss: 0.8166\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 67.437 \tLoss: 0.9471\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 72.601 \tLoss: 0.8067\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 66.871 \tLoss: 1.0023\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 72.622 \tLoss: 0.7913\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client4 Test =>                   \tAcc: 74.219 \tLoss: 0.7317\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  54, Avg Accuracy 69.613 | Avg Loss 0.905\n",
      " Test: Round  54, Avg Accuracy 57.368 | Avg Loss 1.404\n",
      "==========================================================\n",
      "idxs_users [ 0  6  9 13 15  3 17 16 10 11  7  8 18  2 14 19  5  1 12  4]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 9, 13, 15, 3, 17, 16, 10, 11, 7, 8, 18, 2, 14, 5, 1, 12, 4]\n",
      "fedserver选择的客户端index: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19]\n",
      "acc: 62.432650566101074\n",
      "acc: 67.06627082824707\n",
      "acc: 61.57058143615723\n",
      "acc: 61.80630397796631\n",
      "acc: 63.19369602203369\n",
      "acc: 58.425376892089844\n",
      "acc: 61.53690719604492\n",
      "acc: 63.604525566101074\n",
      "acc: 64.70231628417969\n",
      "acc: 61.489763259887695\n",
      "acc: 65.30845832824707\n",
      "acc: 59.112338066101074\n",
      "acc: 61.981411933898926\n",
      "acc: 61.200161933898926\n",
      "acc: 62.627963066101074\n",
      "acc: 67.43669128417969\n",
      "acc: 66.87095832824707\n",
      "acc: 74.21875\n",
      "====================== Fed Server==========================\n",
      " Train: Round  54, Avg Accuracy 69.613 | Avg Loss 0.905\n",
      " Test: Round  54, Avg Accuracy 63.588 | Avg Loss 1.047\n",
      "==========================================================\n",
      "Epoch 54 finished in 00:01:59\n",
      "Epoch 54 finished. Total time: 6680.24 seconds\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 71.505 \tLoss: 0.7911\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 55.354 \tLoss: 1.3186\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 71.121 \tLoss: 0.8025\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 66.790 \tLoss: 1.0202\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 54.485 \tLoss: 1.7822\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 6.802 \tLoss: 4.0747\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 71.992 \tLoss: 0.7826\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 61.651 \tLoss: 1.1240\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 72.112 \tLoss: 0.7860\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 61.712 \tLoss: 1.1339\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 71.684 \tLoss: 0.7953\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 59.382 \tLoss: 1.2229\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 72.413 \tLoss: 0.7881\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 64.076 \tLoss: 1.1702\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 71.824 \tLoss: 0.8032\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 63.914 \tLoss: 1.0324\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 72.475 \tLoss: 0.7902\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 65.558 \tLoss: 1.0016\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 71.160 \tLoss: 0.8331\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 62.803 \tLoss: 1.1595\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 70.887 \tLoss: 0.8267\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 61.786 \tLoss: 1.2012\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 72.838 \tLoss: 0.7880\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 59.799 \tLoss: 1.2170\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 71.592 \tLoss: 0.7993\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 60.264 \tLoss: 1.2933\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 53.743 \tLoss: 1.7787\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 9.207 \tLoss: 5.0822\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 71.723 \tLoss: 0.8101\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 60.210 \tLoss: 1.2024\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 71.094 \tLoss: 0.8042\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 62.042 \tLoss: 1.0850\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 71.059 \tLoss: 0.8391\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 64.911 \tLoss: 1.0134\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 72.100 \tLoss: 0.7973\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 65.436 \tLoss: 1.0137\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 71.372 \tLoss: 0.7936\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 65.362 \tLoss: 0.8771\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 70.620 \tLoss: 0.8100\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client8 Test =>                   \tAcc: 73.040 \tLoss: 0.7646\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  55, Avg Accuracy 69.890 | Avg Loss 0.900\n",
      " Test: Round  55, Avg Accuracy 57.372 | Avg Loss 1.478\n",
      "==========================================================\n",
      "idxs_users [13  1  0  9 10  7 18 16 17  5  2 12 11 19  6 14  3  4 15  8]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13, 1, 0, 9, 10, 7, 18, 17, 5, 2, 12, 11, 6, 14, 3, 4, 15, 8]\n",
      "fedserver选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19]\n",
      "acc: 55.35425662994385\n",
      "acc: 66.79014015197754\n",
      "acc: 6.802262902259827\n",
      "acc: 61.651400566101074\n",
      "acc: 61.71201515197754\n",
      "acc: 59.38173484802246\n",
      "acc: 64.07596969604492\n",
      "acc: 65.55765056610107\n",
      "acc: 62.80307102203369\n",
      "acc: 61.786099433898926\n",
      "acc: 59.799299240112305\n",
      "acc: 60.26400852203369\n",
      "acc: 60.21012878417969\n",
      "acc: 62.042025566101074\n",
      "acc: 64.91109943389893\n",
      "acc: 65.43642234802246\n",
      "acc: 65.36233806610107\n",
      "acc: 73.04014015197754\n",
      "====================== Fed Server==========================\n",
      " Train: Round  55, Avg Accuracy 69.890 | Avg Loss 0.900\n",
      " Test: Round  55, Avg Accuracy 59.832 | Avg Loss 1.272\n",
      "==========================================================\n",
      "Epoch 55 finished in 00:01:59\n",
      "Epoch 55 finished. Total time: 6799.90 seconds\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 71.673 \tLoss: 0.7995\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 62.884 \tLoss: 1.1246\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 71.282 \tLoss: 0.7955\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 68.494 \tLoss: 0.9739\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 71.406 \tLoss: 0.7936\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 70.198 \tLoss: 0.8857\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 73.164 \tLoss: 0.7849\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 66.224 \tLoss: 0.9635\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 71.537 \tLoss: 0.8009\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 62.197 \tLoss: 1.0830\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 73.711 \tLoss: 0.7571\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 63.369 \tLoss: 1.0924\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 71.450 \tLoss: 0.7839\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 65.288 \tLoss: 1.1184\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 71.990 \tLoss: 0.7605\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 63.874 \tLoss: 1.1256\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 72.973 \tLoss: 0.7771\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 59.287 \tLoss: 1.1596\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 72.084 \tLoss: 0.7875\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 57.860 \tLoss: 1.3796\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 70.935 \tLoss: 0.8127\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 61.806 \tLoss: 1.1508\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 71.556 \tLoss: 0.7986\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 65.012 \tLoss: 1.0784\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 70.044 \tLoss: 0.8085\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 59.247 \tLoss: 1.1525\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 70.032 \tLoss: 0.8210\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 62.237 \tLoss: 1.0682\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 71.590 \tLoss: 0.8031\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 56.762 \tLoss: 1.4700\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 71.179 \tLoss: 0.8053\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 61.651 \tLoss: 1.0832\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 53.718 \tLoss: 1.7462\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 7.994 \tLoss: 4.5845\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 70.924 \tLoss: 0.7977\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 67.356 \tLoss: 0.9021\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 72.369 \tLoss: 0.7808\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 67.315 \tLoss: 0.9532\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 53.663 \tLoss: 1.7960\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client19 Test =>                   \tAcc: 73.242 \tLoss: 0.7724\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  56, Avg Accuracy 69.864 | Avg Loss 0.891\n",
      " Test: Round  56, Avg Accuracy 60.899 | Avg Loss 1.274\n",
      "==========================================================\n",
      "idxs_users [ 6 11 16  1 15  9 12 13 17 18  7 14  2  3  5 10  0  8  4 19]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 11, 16, 1, 15, 9, 12, 13, 17, 18, 7, 14, 2, 3, 5, 10, 8, 4]\n",
      "fedserver选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18]\n",
      "acc: 62.88389015197754\n",
      "acc: 68.49407386779785\n",
      "acc: 70.19800567626953\n",
      "acc: 66.22440719604492\n",
      "acc: 62.19692897796631\n",
      "acc: 63.36880397796631\n",
      "acc: 65.28825378417969\n",
      "acc: 63.87392234802246\n",
      "acc: 59.28744602203369\n",
      "acc: 57.85964393615723\n",
      "acc: 61.80630397796631\n",
      "acc: 65.01212310791016\n",
      "acc: 59.247036933898926\n",
      "acc: 62.237338066101074\n",
      "acc: 56.76185321807861\n",
      "acc: 61.651400566101074\n",
      "acc: 67.35587310791016\n",
      "acc: 67.31546306610107\n",
      "====================== Fed Server==========================\n",
      " Train: Round  56, Avg Accuracy 69.864 | Avg Loss 0.891\n",
      " Test: Round  56, Avg Accuracy 63.392 | Avg Loss 1.098\n",
      "==========================================================\n",
      "Epoch 56 finished in 00:01:59\n",
      "Epoch 56 finished. Total time: 6919.38 seconds\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 72.617 \tLoss: 0.7688\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 62.567 \tLoss: 1.1827\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 71.193 \tLoss: 0.7941\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 61.928 \tLoss: 1.1478\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 72.353 \tLoss: 0.7765\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 58.695 \tLoss: 1.1829\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 71.733 \tLoss: 0.8035\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 68.494 \tLoss: 0.9419\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 72.394 \tLoss: 0.7680\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 59.826 \tLoss: 1.0794\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 72.495 \tLoss: 0.7791\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 67.767 \tLoss: 0.9248\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 53.049 \tLoss: 1.7955\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 9.658 \tLoss: 4.5196\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 54.602 \tLoss: 1.7684\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 14.756 \tLoss: 4.4794\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 71.923 \tLoss: 0.7962\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 66.009 \tLoss: 0.9326\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 73.173 \tLoss: 0.7869\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 62.823 \tLoss: 1.0776\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 71.742 \tLoss: 0.7771\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 63.800 \tLoss: 1.0305\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 72.358 \tLoss: 0.7823\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 65.948 \tLoss: 1.0021\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 72.125 \tLoss: 0.8054\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 63.275 \tLoss: 1.0566\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 71.376 \tLoss: 0.7982\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 68.238 \tLoss: 0.9928\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 72.645 \tLoss: 0.7837\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 68.083 \tLoss: 0.9128\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 71.551 \tLoss: 0.8040\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 63.840 \tLoss: 1.1035\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 73.355 \tLoss: 0.7622\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 66.460 \tLoss: 0.9967\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 71.693 \tLoss: 0.7766\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 64.743 \tLoss: 1.0881\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 71.831 \tLoss: 0.7793\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 60.850 \tLoss: 1.2552\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 72.856 \tLoss: 0.7849\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client18 Test =>                   \tAcc: 67.390 \tLoss: 0.9046\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  57, Avg Accuracy 70.353 | Avg Loss 0.885\n",
      " Test: Round  57, Avg Accuracy 58.406 | Avg Loss 1.439\n",
      "==========================================================\n",
      "idxs_users [ 1  5  7 11  8 16 19  0 15 10 13 12  2  3 17  6  9  4 14 18]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 5, 7, 11, 8, 19, 15, 10, 13, 12, 2, 3, 17, 6, 9, 4, 14, 18]\n",
      "fedserver选择的客户端index: [0, 1, 2, 3, 4, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "acc: 62.567349433898926\n",
      "acc: 61.92753219604492\n",
      "acc: 58.69477367401123\n",
      "acc: 68.49407386779785\n",
      "acc: 59.826239585876465\n",
      "acc: 9.657866477966309\n",
      "acc: 66.00889015197754\n",
      "acc: 62.823275566101074\n",
      "acc: 63.799838066101074\n",
      "acc: 65.94827556610107\n",
      "acc: 63.27451515197754\n",
      "acc: 68.23814582824707\n",
      "acc: 68.08324432373047\n",
      "acc: 63.840248107910156\n",
      "acc: 66.46012878417969\n",
      "acc: 64.74272537231445\n",
      "acc: 60.84994602203369\n",
      "acc: 67.38954734802246\n",
      "====================== Fed Server==========================\n",
      " Train: Round  57, Avg Accuracy 70.353 | Avg Loss 0.885\n",
      " Test: Round  57, Avg Accuracy 61.257 | Avg Loss 1.245\n",
      "==========================================================\n",
      "Epoch 57 finished in 00:01:59\n",
      "Epoch 57 finished. Total time: 7039.06 seconds\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 71.870 \tLoss: 0.7844\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 60.554 \tLoss: 1.2981\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 72.587 \tLoss: 0.7852\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 62.823 \tLoss: 1.0574\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 72.734 \tLoss: 0.7726\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 63.120 \tLoss: 1.0741\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 71.760 \tLoss: 0.7872\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 60.001 \tLoss: 1.2136\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 55.887 \tLoss: 1.7405\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 6.668 \tLoss: 4.5108\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 72.201 \tLoss: 0.7770\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 65.477 \tLoss: 1.0322\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 72.059 \tLoss: 0.7767\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 64.581 \tLoss: 1.0079\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 72.279 \tLoss: 0.7948\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 61.106 \tLoss: 1.0503\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 71.919 \tLoss: 0.7861\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 67.632 \tLoss: 0.9289\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 71.946 \tLoss: 0.7764\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 61.086 \tLoss: 1.0897\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 72.845 \tLoss: 0.7537\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 69.390 \tLoss: 0.9729\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 73.040 \tLoss: 0.7596\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 62.857 \tLoss: 1.1565\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 72.484 \tLoss: 0.7720\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 66.245 \tLoss: 1.0003\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 72.167 \tLoss: 0.7979\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 64.621 \tLoss: 1.1165\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 72.709 \tLoss: 0.7833\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 62.628 \tLoss: 1.0805\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 72.063 \tLoss: 0.7809\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 65.322 \tLoss: 1.0821\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 71.581 \tLoss: 0.7859\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 58.540 \tLoss: 1.3376\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 72.284 \tLoss: 0.7972\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 57.294 \tLoss: 1.3769\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 72.284 \tLoss: 0.7844\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 68.137 \tLoss: 0.9717\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 52.767 \tLoss: 1.8106\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client19 Test =>                   \tAcc: 75.741 \tLoss: 0.7479\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 3, 4, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  58, Avg Accuracy 70.473 | Avg Loss 0.880\n",
      " Test: Round  58, Avg Accuracy 60.958 | Avg Loss 1.279\n",
      "==========================================================\n",
      "idxs_users [ 2  7 14 13  0  3 16 10 15  1 17  9  4  6 18 12  8  5 11 19]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 7, 14, 13, 3, 16, 10, 15, 1, 17, 9, 4, 6, 18, 12, 8, 5, 11]\n",
      "fedserver选择的客户端index: [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n",
      "acc: 60.55360984802246\n",
      "acc: 62.823275566101074\n",
      "acc: 63.119611740112305\n",
      "acc: 60.001346588134766\n",
      "acc: 65.47683143615723\n",
      "acc: 64.58108806610107\n",
      "acc: 61.105873107910156\n",
      "acc: 67.63200378417969\n",
      "acc: 61.08566856384277\n",
      "acc: 69.38981628417969\n",
      "acc: 62.856950759887695\n",
      "acc: 66.2446117401123\n",
      "acc: 64.62149810791016\n",
      "acc: 62.627963066101074\n",
      "acc: 65.32192897796631\n",
      "acc: 58.539870262145996\n",
      "acc: 57.293911933898926\n",
      "acc: 68.13712310791016\n",
      "====================== Fed Server==========================\n",
      " Train: Round  58, Avg Accuracy 70.473 | Avg Loss 0.880\n",
      " Test: Round  58, Avg Accuracy 63.412 | Avg Loss 1.103\n",
      "==========================================================\n",
      "Epoch 58 finished in 00:01:59\n",
      "Epoch 58 finished. Total time: 7158.88 seconds\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 74.017 \tLoss: 0.7551\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 66.016 \tLoss: 0.9677\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 73.031 \tLoss: 0.7461\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 70.797 \tLoss: 0.8528\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 72.891 \tLoss: 0.7555\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 59.752 \tLoss: 1.1993\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 73.573 \tLoss: 0.7546\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 61.241 \tLoss: 1.0984\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 73.203 \tLoss: 0.7513\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 61.631 \tLoss: 1.1925\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 72.089 \tLoss: 0.7825\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 65.207 \tLoss: 1.0018\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 72.870 \tLoss: 0.7560\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 68.662 \tLoss: 0.9093\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 74.141 \tLoss: 0.7334\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 66.144 \tLoss: 1.0221\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 54.692 \tLoss: 1.8025\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 10.964 \tLoss: 4.4183\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 72.390 \tLoss: 0.7711\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 66.123 \tLoss: 1.0227\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 72.856 \tLoss: 0.7589\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 66.305 \tLoss: 0.9312\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 72.636 \tLoss: 0.7782\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 69.195 \tLoss: 0.9048\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 72.973 \tLoss: 0.7631\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 64.386 \tLoss: 1.1445\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 53.134 \tLoss: 1.8043\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 6.957 \tLoss: 4.5400\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 73.824 \tLoss: 0.7428\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 59.442 \tLoss: 1.2747\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 73.750 \tLoss: 0.7595\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 65.167 \tLoss: 1.0386\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 71.560 \tLoss: 0.7833\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 63.328 \tLoss: 1.0128\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 72.826 \tLoss: 0.7658\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 59.833 \tLoss: 1.1959\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 72.778 \tLoss: 0.7759\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 64.588 \tLoss: 0.9578\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 71.870 \tLoss: 0.7825\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client5 Test =>                   \tAcc: 72.656 \tLoss: 0.7908\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  59, Avg Accuracy 71.055 | Avg Loss 0.866\n",
      " Test: Round  59, Avg Accuracy 58.562 | Avg Loss 1.416\n",
      "==========================================================\n",
      "idxs_users [ 8 10 18  1  7  2  4  9  0 13 16  6 12 19 17 11  3 14 15  5]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 10, 18, 1, 7, 2, 4, 9, 13, 16, 6, 12, 17, 11, 3, 14, 15, 5]\n",
      "fedserver选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19]\n",
      "acc: 66.015625\n",
      "acc: 70.79741287231445\n",
      "acc: 59.75215530395508\n",
      "acc: 61.24057102203369\n",
      "acc: 61.63119602203369\n",
      "acc: 65.20743560791016\n",
      "acc: 68.66244602203369\n",
      "acc: 66.14358806610107\n",
      "acc: 66.12338352203369\n",
      "acc: 66.30522537231445\n",
      "acc: 69.19450378417969\n",
      "acc: 64.38577556610107\n",
      "acc: 59.442349433898926\n",
      "acc: 65.16702556610107\n",
      "acc: 63.32839393615723\n",
      "acc: 59.832974433898926\n",
      "acc: 64.58782386779785\n",
      "acc: 72.65625\n",
      "====================== Fed Server==========================\n",
      " Train: Round  59, Avg Accuracy 71.055 | Avg Loss 0.866\n",
      " Test: Round  59, Avg Accuracy 65.026 | Avg Loss 1.029\n",
      "==========================================================\n",
      "Epoch 59 finished in 00:01:59\n",
      "Epoch 59 finished. Total time: 7278.58 seconds\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 72.247 \tLoss: 0.7719\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 65.537 \tLoss: 1.1473\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 72.677 \tLoss: 0.7728\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 65.814 \tLoss: 0.9560\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 73.247 \tLoss: 0.7609\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 58.190 \tLoss: 1.2691\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 54.653 \tLoss: 1.7578\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 8.641 \tLoss: 4.0004\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 72.953 \tLoss: 0.7572\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 66.972 \tLoss: 0.9533\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 53.598 \tLoss: 1.8400\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 10.985 \tLoss: 4.7087\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 72.665 \tLoss: 0.7463\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 66.460 \tLoss: 1.0169\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 73.674 \tLoss: 0.7553\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 63.860 \tLoss: 1.1146\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 73.286 \tLoss: 0.7639\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 65.147 \tLoss: 0.9687\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 73.502 \tLoss: 0.7508\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 68.885 \tLoss: 0.9501\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 72.259 \tLoss: 0.7706\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 59.402 \tLoss: 1.1888\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 73.251 \tLoss: 0.7542\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 64.736 \tLoss: 0.9718\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 72.709 \tLoss: 0.7466\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 63.860 \tLoss: 1.1444\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 71.829 \tLoss: 0.7838\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 62.123 \tLoss: 1.2144\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 72.139 \tLoss: 0.7476\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 65.793 \tLoss: 1.0132\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 73.212 \tLoss: 0.7511\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 67.235 \tLoss: 0.9843\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 73.031 \tLoss: 0.7577\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 60.729 \tLoss: 1.1357\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 73.357 \tLoss: 0.7781\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 62.008 \tLoss: 1.1075\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 73.449 \tLoss: 0.7671\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 69.484 \tLoss: 0.8614\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 73.352 \tLoss: 0.7542\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client16 Test =>                   \tAcc: 73.633 \tLoss: 0.7390\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  60, Avg Accuracy 71.055 | Avg Loss 0.864\n",
      " Test: Round  60, Avg Accuracy 59.012 | Avg Loss 1.403\n",
      "==========================================================\n",
      "idxs_users [ 2 14  1  0 10 19 13  4 15  6 18  3 11  5  9 12 17  7  8 16]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 14, 1, 10, 13, 4, 15, 6, 18, 3, 11, 5, 9, 12, 17, 7, 8, 16]\n",
      "fedserver选择的客户端index: [0, 1, 2, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "acc: 65.53744602203369\n",
      "acc: 65.81357765197754\n",
      "acc: 58.18965530395508\n",
      "acc: 66.97198295593262\n",
      "acc: 66.46012878417969\n",
      "acc: 63.86045265197754\n",
      "acc: 65.14682102203369\n",
      "acc: 68.88469886779785\n",
      "acc: 59.401939392089844\n",
      "acc: 64.73599147796631\n",
      "acc: 63.86045265197754\n",
      "acc: 62.12284469604492\n",
      "acc: 65.79337310791016\n",
      "acc: 67.23464393615723\n",
      "acc: 60.72871780395508\n",
      "acc: 62.00835037231445\n",
      "acc: 69.48410606384277\n",
      "acc: 73.6328125\n",
      "====================== Fed Server==========================\n",
      " Train: Round  60, Avg Accuracy 71.055 | Avg Loss 0.864\n",
      " Test: Round  60, Avg Accuracy 64.993 | Avg Loss 1.041\n",
      "==========================================================\n",
      "Epoch 60 finished in 00:02:00\n",
      "Epoch 60 finished. Total time: 7399.50 seconds\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 74.129 \tLoss: 0.7708\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 58.075 \tLoss: 1.2764\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 72.817 \tLoss: 0.7553\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 60.964 \tLoss: 1.1816\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 73.263 \tLoss: 0.7582\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 62.628 \tLoss: 1.0756\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 73.624 \tLoss: 0.7343\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 66.615 \tLoss: 1.0185\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 74.635 \tLoss: 0.7437\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 69.976 \tLoss: 0.8242\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 53.897 \tLoss: 1.8170\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 8.796 \tLoss: 4.8725\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 73.465 \tLoss: 0.7533\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 60.850 \tLoss: 1.1794\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 73.460 \tLoss: 0.7542\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 57.469 \tLoss: 1.4910\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 73.603 \tLoss: 0.7508\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 60.985 \tLoss: 1.1016\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 73.267 \tLoss: 0.7640\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 64.500 \tLoss: 0.9880\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 71.889 \tLoss: 0.7799\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 67.713 \tLoss: 1.0194\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 73.686 \tLoss: 0.7320\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 56.021 \tLoss: 1.5073\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 74.301 \tLoss: 0.7217\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 66.103 \tLoss: 1.0056\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 72.562 \tLoss: 0.7595\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 56.176 \tLoss: 1.3770\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 73.251 \tLoss: 0.7414\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 62.271 \tLoss: 1.1158\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 74.373 \tLoss: 0.7405\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 66.952 \tLoss: 1.0196\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 73.950 \tLoss: 0.7388\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 62.527 \tLoss: 1.0555\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 53.006 \tLoss: 1.8281\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 14.716 \tLoss: 4.7992\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 72.856 \tLoss: 0.7732\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 60.594 \tLoss: 1.2401\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 73.640 \tLoss: 0.7688\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client16 Test =>                   \tAcc: 73.006 \tLoss: 0.7150\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  61, Avg Accuracy 71.484 | Avg Loss 0.859\n",
      " Test: Round  61, Avg Accuracy 60.085 | Avg Loss 1.332\n",
      "==========================================================\n",
      "idxs_users [ 7  5 15 17  4  0 18 11  1  3  2  9 12  6 14 13 10 19  8 16]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 5, 15, 17, 4, 18, 11, 1, 3, 2, 9, 12, 6, 14, 13, 10, 8, 16]\n",
      "fedserver选择的客户端index: [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19]\n",
      "acc: 58.075161933898926\n",
      "acc: 60.964439392089844\n",
      "acc: 62.627963066101074\n",
      "acc: 66.61503219604492\n",
      "acc: 69.97575378417969\n",
      "acc: 60.84994602203369\n",
      "acc: 57.46901893615723\n",
      "acc: 60.98464393615723\n",
      "acc: 64.50026893615723\n",
      "acc: 67.71282386779785\n",
      "acc: 56.021013259887695\n",
      "acc: 66.10317897796631\n",
      "acc: 56.17591571807861\n",
      "acc: 62.271013259887695\n",
      "acc: 66.95177841186523\n",
      "acc: 62.526939392089844\n",
      "acc: 60.59401893615723\n",
      "acc: 73.00646591186523\n",
      "====================== Fed Server==========================\n",
      " Train: Round  61, Avg Accuracy 71.484 | Avg Loss 0.859\n",
      " Test: Round  61, Avg Accuracy 62.968 | Avg Loss 1.122\n",
      "==========================================================\n",
      "Epoch 61 finished in 00:02:00\n",
      "Epoch 61 finished. Total time: 7519.94 seconds\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 72.773 \tLoss: 0.7655\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 64.736 \tLoss: 1.0238\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 73.058 \tLoss: 0.7533\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 66.615 \tLoss: 0.9869\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 74.058 \tLoss: 0.7429\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 63.955 \tLoss: 1.0547\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 72.606 \tLoss: 0.7375\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 66.164 \tLoss: 0.9772\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 72.691 \tLoss: 0.7684\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 62.258 \tLoss: 1.0327\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 72.695 \tLoss: 0.7560\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 66.420 \tLoss: 1.0062\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 53.504 \tLoss: 1.8342\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 9.658 \tLoss: 4.6505\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 73.881 \tLoss: 0.7462\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 62.547 \tLoss: 1.0743\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 73.173 \tLoss: 0.7309\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 63.120 \tLoss: 1.1189\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 75.126 \tLoss: 0.7344\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 64.830 \tLoss: 1.0787\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 74.239 \tLoss: 0.7367\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 56.115 \tLoss: 1.5081\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 74.584 \tLoss: 0.7342\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 63.746 \tLoss: 1.1114\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 54.189 \tLoss: 1.8083\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 14.130 \tLoss: 4.8942\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 74.453 \tLoss: 0.7312\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 62.998 \tLoss: 1.2095\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 72.994 \tLoss: 0.7528\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 65.874 \tLoss: 0.9906\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 73.477 \tLoss: 0.7485\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 59.692 \tLoss: 1.2336\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 73.872 \tLoss: 0.7365\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 65.187 \tLoss: 0.9261\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 73.591 \tLoss: 0.7558\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 65.497 \tLoss: 0.9883\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 75.499 \tLoss: 0.7113\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 67.511 \tLoss: 0.9273\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 74.467 \tLoss: 0.7503\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client11 Test =>                   \tAcc: 72.656 \tLoss: 0.8324\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  62, Avg Accuracy 71.747 | Avg Loss 0.852\n",
      " Test: Round  62, Avg Accuracy 58.433 | Avg Loss 1.479\n",
      "==========================================================\n",
      "idxs_users [ 5  6  2 14  3 13  0  1  9 18 10 17 19  7  8 12 15 16  4 11]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 6, 2, 14, 3, 13, 1, 9, 18, 10, 17, 7, 8, 12, 15, 16, 4, 11]\n",
      "fedserver选择的客户端index: [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19]\n",
      "acc: 64.73599147796631\n",
      "acc: 66.61503219604492\n",
      "acc: 63.95474147796631\n",
      "acc: 66.16379356384277\n",
      "acc: 62.25754356384277\n",
      "acc: 66.41971969604492\n",
      "acc: 62.54714393615723\n",
      "acc: 63.119611740112305\n",
      "acc: 64.83028030395508\n",
      "acc: 56.115302085876465\n",
      "acc: 63.74595832824707\n",
      "acc: 62.99838352203369\n",
      "acc: 65.87419128417969\n",
      "acc: 59.69154071807861\n",
      "acc: 65.18723106384277\n",
      "acc: 65.49703693389893\n",
      "acc: 67.51077556610107\n",
      "acc: 72.65625\n",
      "====================== Fed Server==========================\n",
      " Train: Round  62, Avg Accuracy 71.747 | Avg Loss 0.852\n",
      " Test: Round  62, Avg Accuracy 64.440 | Avg Loss 1.060\n",
      "==========================================================\n",
      "Epoch 62 finished in 00:02:00\n",
      "Epoch 62 finished. Total time: 7640.45 seconds\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 72.776 \tLoss: 0.7430\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 67.652 \tLoss: 0.9618\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 73.989 \tLoss: 0.7349\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 67.201 \tLoss: 0.9950\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 73.265 \tLoss: 0.7454\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 57.530 \tLoss: 1.4360\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 74.062 \tLoss: 0.7321\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 56.728 \tLoss: 1.6007\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 73.941 \tLoss: 0.7498\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 60.729 \tLoss: 1.1588\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 74.019 \tLoss: 0.7429\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 66.884 \tLoss: 1.0072\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 53.490 \tLoss: 1.8541\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 8.270 \tLoss: 5.0013\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 73.941 \tLoss: 0.7365\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 64.116 \tLoss: 1.1137\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 74.111 \tLoss: 0.7299\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 65.517 \tLoss: 1.0187\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 72.705 \tLoss: 0.7434\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 65.948 \tLoss: 0.9539\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 73.536 \tLoss: 0.7519\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 61.140 \tLoss: 1.0723\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 74.913 \tLoss: 0.7328\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 60.379 \tLoss: 1.2101\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 75.097 \tLoss: 0.7018\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 63.234 \tLoss: 1.1357\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 54.492 \tLoss: 1.7990\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 8.095 \tLoss: 4.0583\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 74.531 \tLoss: 0.7206\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 63.039 \tLoss: 1.0509\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 73.001 \tLoss: 0.7672\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 69.296 \tLoss: 0.8923\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 74.180 \tLoss: 0.7430\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 63.039 \tLoss: 1.0295\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 74.800 \tLoss: 0.7328\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 62.588 \tLoss: 1.0560\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 73.945 \tLoss: 0.7313\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 67.262 \tLoss: 0.9646\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 74.141 \tLoss: 0.7536\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client2 Test =>                   \tAcc: 72.245 \tLoss: 0.8227\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  63, Avg Accuracy 71.947 | Avg Loss 0.847\n",
      " Test: Round  63, Avg Accuracy 61.077 | Avg Loss 1.245\n",
      "==========================================================\n",
      "idxs_users [ 6  4 13 11 16  5 19 17 15  3  7 12  9  0 18 14  8 10  1  2]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 4, 13, 11, 16, 5, 17, 15, 3, 7, 12, 9, 18, 14, 8, 10, 1, 2]\n",
      "fedserver选择的客户端index: [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19]\n",
      "acc: 67.65220832824707\n",
      "acc: 67.20096969604492\n",
      "acc: 57.52963352203369\n",
      "acc: 56.72817897796631\n",
      "acc: 60.72871780395508\n",
      "acc: 66.88442897796631\n",
      "acc: 64.11637878417969\n",
      "acc: 65.51724147796631\n",
      "acc: 65.94827556610107\n",
      "acc: 61.13954734802246\n",
      "acc: 60.378501892089844\n",
      "acc: 63.23410606384277\n",
      "acc: 63.03879356384277\n",
      "acc: 69.29552841186523\n",
      "acc: 63.03879356384277\n",
      "acc: 62.58755397796631\n",
      "acc: 67.26158332824707\n",
      "acc: 72.24542045593262\n",
      "====================== Fed Server==========================\n",
      " Train: Round  63, Avg Accuracy 71.947 | Avg Loss 0.847\n",
      " Test: Round  63, Avg Accuracy 64.140 | Avg Loss 1.082\n",
      "==========================================================\n",
      "Epoch 63 finished in 00:02:00\n",
      "Epoch 63 finished. Total time: 7760.73 seconds\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 74.384 \tLoss: 0.7274\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 66.985 \tLoss: 0.9927\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 73.647 \tLoss: 0.7477\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 67.437 \tLoss: 0.9267\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 73.676 \tLoss: 0.7423\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 64.251 \tLoss: 1.1526\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 74.586 \tLoss: 0.7192\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 63.975 \tLoss: 1.1325\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 73.982 \tLoss: 0.7313\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 65.915 \tLoss: 1.0697\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 73.658 \tLoss: 0.7349\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 67.221 \tLoss: 0.9144\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 73.633 \tLoss: 0.7278\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 58.641 \tLoss: 1.2222\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 74.465 \tLoss: 0.7033\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 68.373 \tLoss: 0.9283\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 74.605 \tLoss: 0.7250\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 61.005 \tLoss: 1.1231\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 55.209 \tLoss: 1.8168\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 9.833 \tLoss: 5.0407\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 74.189 \tLoss: 0.7517\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 61.981 \tLoss: 1.1213\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 72.895 \tLoss: 0.7429\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 66.144 \tLoss: 0.9278\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 74.053 \tLoss: 0.7344\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 65.308 \tLoss: 1.0800\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 72.123 \tLoss: 0.7626\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 61.725 \tLoss: 1.1684\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 73.300 \tLoss: 0.7445\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 62.689 \tLoss: 1.0577\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 74.223 \tLoss: 0.7470\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 60.459 \tLoss: 1.1680\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 73.433 \tLoss: 0.7394\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 67.706 \tLoss: 1.0249\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 74.129 \tLoss: 0.7173\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 64.743 \tLoss: 0.9735\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 52.125 \tLoss: 1.9002\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 12.022 \tLoss: 6.0431\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 74.989 \tLoss: 0.7333\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client7 Test =>                   \tAcc: 70.744 \tLoss: 0.8289\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  64, Avg Accuracy 71.865 | Avg Loss 0.847\n",
      " Test: Round  64, Avg Accuracy 59.266 | Avg Loss 1.528\n",
      "==========================================================\n",
      "idxs_users [12  8 17  4 16  6 15  9  1  0 11 10 18  5  3  2 14 13 19  7]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 8, 17, 4, 16, 6, 15, 9, 1, 0, 11, 10, 18, 5, 3, 14, 13, 7]\n",
      "fedserver选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 19]\n",
      "acc: 66.98545265197754\n",
      "acc: 67.43669128417969\n",
      "acc: 64.25107765197754\n",
      "acc: 63.97494602203369\n",
      "acc: 65.91460037231445\n",
      "acc: 67.2211742401123\n",
      "acc: 58.64089393615723\n",
      "acc: 68.37284469604492\n",
      "acc: 61.004849433898926\n",
      "acc: 9.832974195480347\n",
      "acc: 61.981411933898926\n",
      "acc: 66.14358806610107\n",
      "acc: 65.30845832824707\n",
      "acc: 61.72548484802246\n",
      "acc: 62.68857765197754\n",
      "acc: 67.70608806610107\n",
      "acc: 64.74272537231445\n",
      "acc: 70.74353408813477\n",
      "====================== Fed Server==========================\n",
      " Train: Round  64, Avg Accuracy 71.865 | Avg Loss 0.847\n",
      " Test: Round  64, Avg Accuracy 61.926 | Avg Loss 1.260\n",
      "==========================================================\n",
      "Epoch 64 finished in 00:02:00\n",
      "Epoch 64 finished. Total time: 7881.01 seconds\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 73.716 \tLoss: 0.7454\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 68.413 \tLoss: 1.0254\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 51.512 \tLoss: 1.9096\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 11.395 \tLoss: 5.6559\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 73.242 \tLoss: 0.7642\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 57.314 \tLoss: 1.3873\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 74.869 \tLoss: 0.7259\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 63.780 \tLoss: 1.0820\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 53.187 \tLoss: 1.8566\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 10.399 \tLoss: 4.7619\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 73.752 \tLoss: 0.7466\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 66.615 \tLoss: 1.0164\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 74.315 \tLoss: 0.7207\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 68.043 \tLoss: 0.9229\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 73.534 \tLoss: 0.7399\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 61.160 \tLoss: 1.2319\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 74.361 \tLoss: 0.7212\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 66.110 \tLoss: 1.0399\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 74.628 \tLoss: 0.7203\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 66.460 \tLoss: 1.0151\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 74.743 \tLoss: 0.7238\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 62.547 \tLoss: 1.1539\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 74.715 \tLoss: 0.7169\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 67.120 \tLoss: 0.9690\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 74.727 \tLoss: 0.7355\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 61.375 \tLoss: 1.1871\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 74.292 \tLoss: 0.7234\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 64.675 \tLoss: 1.1262\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 74.467 \tLoss: 0.7237\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 62.157 \tLoss: 1.1295\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 74.262 \tLoss: 0.7236\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 64.251 \tLoss: 1.0831\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 75.147 \tLoss: 0.7244\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 64.958 \tLoss: 1.0294\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 74.049 \tLoss: 0.7329\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 64.366 \tLoss: 1.0290\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 75.708 \tLoss: 0.6978\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 69.040 \tLoss: 0.9469\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 73.902 \tLoss: 0.7245\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client7 Test =>                   \tAcc: 70.973 \tLoss: 0.8208\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  65, Avg Accuracy 72.156 | Avg Loss 0.844\n",
      " Test: Round  65, Avg Accuracy 58.770 | Avg Loss 1.532\n",
      "==========================================================\n",
      "idxs_users [ 2 19  5 10  0 13 17  4 12  8  3  9 15  6 18 14 11 16  1  7]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 5, 10, 13, 17, 4, 12, 8, 3, 9, 15, 6, 18, 14, 11, 16, 1, 7]\n",
      "fedserver选择的客户端index: [0, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "acc: 68.41325378417969\n",
      "acc: 57.31411647796631\n",
      "acc: 63.77963352203369\n",
      "acc: 66.61503219604492\n",
      "acc: 68.04283332824707\n",
      "acc: 61.159751892089844\n",
      "acc: 66.10991287231445\n",
      "acc: 66.46012878417969\n",
      "acc: 62.54714393615723\n",
      "acc: 67.12015056610107\n",
      "acc: 61.37526893615723\n",
      "acc: 64.67537689208984\n",
      "acc: 62.15651893615723\n",
      "acc: 64.25107765197754\n",
      "acc: 64.95824432373047\n",
      "acc: 64.36557102203369\n",
      "acc: 69.03960037231445\n",
      "acc: 70.97252082824707\n",
      "====================== Fed Server==========================\n",
      " Train: Round  65, Avg Accuracy 72.156 | Avg Loss 0.844\n",
      " Test: Round  65, Avg Accuracy 64.964 | Avg Loss 1.066\n",
      "==========================================================\n",
      "Epoch 65 finished in 00:02:01\n",
      "Epoch 65 finished. Total time: 8002.71 seconds\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 73.725 \tLoss: 0.7350\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 65.282 \tLoss: 0.9891\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 73.504 \tLoss: 0.7365\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 67.807 \tLoss: 0.9973\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 73.711 \tLoss: 0.7354\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 65.908 \tLoss: 0.9838\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 74.428 \tLoss: 0.7054\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 65.814 \tLoss: 0.9410\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 75.322 \tLoss: 0.7135\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 65.053 \tLoss: 1.0820\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 73.847 \tLoss: 0.7148\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 66.278 \tLoss: 0.9208\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 75.611 \tLoss: 0.7081\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 67.962 \tLoss: 0.9784\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 73.817 \tLoss: 0.7253\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 67.295 \tLoss: 1.0104\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 54.550 \tLoss: 1.8345\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 12.668 \tLoss: 4.2382\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 74.752 \tLoss: 0.7232\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 62.823 \tLoss: 1.1310\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 73.920 \tLoss: 0.7235\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 67.666 \tLoss: 1.0711\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 73.001 \tLoss: 0.7465\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 63.019 \tLoss: 1.1893\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 74.193 \tLoss: 0.7187\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 61.746 \tLoss: 1.1458\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 74.177 \tLoss: 0.7175\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 69.019 \tLoss: 0.9765\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 53.068 \tLoss: 1.8629\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 8.210 \tLoss: 5.6397\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 75.377 \tLoss: 0.7035\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 66.204 \tLoss: 1.0042\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 74.444 \tLoss: 0.7124\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 64.015 \tLoss: 1.0459\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 74.359 \tLoss: 0.7278\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 67.652 \tLoss: 0.9220\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 75.113 \tLoss: 0.7012\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 67.767 \tLoss: 0.9745\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 74.297 \tLoss: 0.7161\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client3 Test =>                   \tAcc: 73.283 \tLoss: 0.7425\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  66, Avg Accuracy 72.261 | Avg Loss 0.833\n",
      " Test: Round  66, Avg Accuracy 60.145 | Avg Loss 1.439\n",
      "==========================================================\n",
      "idxs_users [14  2  5  9 16  8  1 13  0 11 12  6 18  4 19 15  7 10 17  3]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14, 2, 5, 9, 16, 8, 1, 13, 11, 12, 6, 18, 4, 15, 7, 10, 17, 3]\n",
      "fedserver选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19]\n",
      "acc: 65.28151893615723\n",
      "acc: 67.8071117401123\n",
      "acc: 65.90786647796631\n",
      "acc: 65.81357765197754\n",
      "acc: 65.05253219604492\n",
      "acc: 66.27828693389893\n",
      "acc: 67.96201515197754\n",
      "acc: 67.29525852203369\n",
      "acc: 62.823275566101074\n",
      "acc: 67.66567897796631\n",
      "acc: 63.018588066101074\n",
      "acc: 61.745689392089844\n",
      "acc: 69.01939582824707\n",
      "acc: 66.20420265197754\n",
      "acc: 64.01535606384277\n",
      "acc: 67.65220832824707\n",
      "acc: 67.76670265197754\n",
      "acc: 73.28259658813477\n",
      "====================== Fed Server==========================\n",
      " Train: Round  66, Avg Accuracy 72.261 | Avg Loss 0.833\n",
      " Test: Round  66, Avg Accuracy 66.366 | Avg Loss 1.006\n",
      "==========================================================\n",
      "Epoch 66 finished in 00:02:00\n",
      "Epoch 66 finished. Total time: 8122.80 seconds\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 74.375 \tLoss: 0.7067\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 64.992 \tLoss: 0.9937\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 73.755 \tLoss: 0.7457\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 66.063 \tLoss: 0.9970\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 74.207 \tLoss: 0.7364\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 66.164 \tLoss: 1.0961\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 75.025 \tLoss: 0.6965\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 67.612 \tLoss: 0.9052\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 74.269 \tLoss: 0.7295\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 65.423 \tLoss: 1.0283\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 75.030 \tLoss: 0.7007\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 64.675 \tLoss: 1.0694\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 73.364 \tLoss: 0.7518\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 62.588 \tLoss: 1.0644\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 73.957 \tLoss: 0.7192\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 69.747 \tLoss: 0.8739\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 73.892 \tLoss: 0.7384\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 60.890 \tLoss: 1.2864\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 74.986 \tLoss: 0.7011\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 66.009 \tLoss: 1.0147\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 74.639 \tLoss: 0.7131\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 61.981 \tLoss: 1.0420\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 75.025 \tLoss: 0.7003\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 68.568 \tLoss: 0.9205\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 74.230 \tLoss: 0.7105\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 65.638 \tLoss: 0.9730\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 75.283 \tLoss: 0.6955\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 63.780 \tLoss: 1.0229\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 75.988 \tLoss: 0.7137\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 61.160 \tLoss: 1.1703\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 75.820 \tLoss: 0.6970\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 68.272 \tLoss: 0.9310\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 74.506 \tLoss: 0.7179\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 67.652 \tLoss: 0.9290\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 51.551 \tLoss: 1.9522\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 12.062 \tLoss: 6.3737\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 54.042 \tLoss: 1.8645\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 13.901 \tLoss: 3.8108\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 74.389 \tLoss: 0.7061\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client9 Test =>                   \tAcc: 73.646 \tLoss: 0.7674\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  67, Avg Accuracy 72.417 | Avg Loss 0.835\n",
      " Test: Round  67, Avg Accuracy 60.487 | Avg Loss 1.434\n",
      "==========================================================\n",
      "idxs_users [ 3 14 11 13 12  4  5 16  2  7 15 10  6  1 18 17  8 19  0  9]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 14, 11, 13, 12, 4, 5, 16, 2, 7, 15, 10, 6, 1, 18, 17, 8, 9]\n",
      "fedserver选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 19]\n",
      "acc: 64.99191856384277\n",
      "acc: 66.06276893615723\n",
      "acc: 66.16379356384277\n",
      "acc: 67.6117992401123\n",
      "acc: 65.42295265197754\n",
      "acc: 64.67537689208984\n",
      "acc: 62.58755397796631\n",
      "acc: 69.74676704406738\n",
      "acc: 60.89035606384277\n",
      "acc: 66.00889015197754\n",
      "acc: 61.981411933898926\n",
      "acc: 68.56815719604492\n",
      "acc: 65.63846969604492\n",
      "acc: 63.77963352203369\n",
      "acc: 61.159751892089844\n",
      "acc: 68.27182102203369\n",
      "acc: 67.65220832824707\n",
      "acc: 73.64628219604492\n",
      "====================== Fed Server==========================\n",
      " Train: Round  67, Avg Accuracy 72.417 | Avg Loss 0.835\n",
      " Test: Round  67, Avg Accuracy 65.826 | Avg Loss 1.005\n",
      "==========================================================\n",
      "Epoch 67 finished in 00:02:00\n",
      "Epoch 67 finished. Total time: 8242.89 seconds\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 74.580 \tLoss: 0.7090\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 63.955 \tLoss: 1.0445\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 75.126 \tLoss: 0.7388\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 62.803 \tLoss: 1.0790\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 74.233 \tLoss: 0.7201\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 64.891 \tLoss: 1.0186\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 75.581 \tLoss: 0.7040\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 63.295 \tLoss: 1.1192\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 53.178 \tLoss: 1.8800\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 10.493 \tLoss: 4.9279\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 75.028 \tLoss: 0.6966\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 68.413 \tLoss: 0.9519\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 74.428 \tLoss: 0.7213\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 66.049 \tLoss: 0.9970\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 76.510 \tLoss: 0.6947\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 64.036 \tLoss: 1.1152\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 75.234 \tLoss: 0.6860\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 67.901 \tLoss: 0.9187\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 75.473 \tLoss: 0.6977\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 62.958 \tLoss: 1.1705\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 76.163 \tLoss: 0.6995\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 60.587 \tLoss: 1.1564\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 74.892 \tLoss: 0.6942\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 64.776 \tLoss: 1.1147\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 75.083 \tLoss: 0.7161\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 64.776 \tLoss: 0.9271\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 75.524 \tLoss: 0.7084\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 65.638 \tLoss: 1.0875\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 74.743 \tLoss: 0.7195\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 69.982 \tLoss: 0.8821\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 54.233 \tLoss: 1.8348\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 9.227 \tLoss: 4.0893\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 74.295 \tLoss: 0.7284\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 64.096 \tLoss: 1.0734\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 73.426 \tLoss: 0.7233\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 64.015 \tLoss: 1.1815\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 73.773 \tLoss: 0.7138\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 70.447 \tLoss: 0.8780\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 74.040 \tLoss: 0.7263\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client6 Test =>                   \tAcc: 74.906 \tLoss: 0.7290\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  68, Avg Accuracy 72.777 | Avg Loss 0.826\n",
      " Test: Round  68, Avg Accuracy 59.377 | Avg Loss 1.411\n",
      "==========================================================\n",
      "idxs_users [10  2  3  7 19  9  5 18  4 11 17 13 15 12  8  0  1 16 14  6]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 2, 3, 7, 19, 9, 5, 18, 11, 17, 13, 15, 12, 8, 1, 16, 14, 6]\n",
      "fedserver选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19]\n",
      "acc: 63.95474147796631\n",
      "acc: 62.80307102203369\n",
      "acc: 64.89089393615723\n",
      "acc: 63.29471969604492\n",
      "acc: 10.492995738983154\n",
      "acc: 68.41325378417969\n",
      "acc: 66.0492992401123\n",
      "acc: 64.03556060791016\n",
      "acc: 62.957974433898926\n",
      "acc: 60.587284088134766\n",
      "acc: 64.77640056610107\n",
      "acc: 64.77640056610107\n",
      "acc: 65.63846969604492\n",
      "acc: 69.98248863220215\n",
      "acc: 64.0961742401123\n",
      "acc: 64.01535606384277\n",
      "acc: 70.44719886779785\n",
      "acc: 74.90571022033691\n",
      "====================== Fed Server==========================\n",
      " Train: Round  68, Avg Accuracy 72.777 | Avg Loss 0.826\n",
      " Test: Round  68, Avg Accuracy 62.562 | Avg Loss 1.247\n",
      "==========================================================\n",
      "Epoch 68 finished in 00:02:00\n",
      "Epoch 68 finished. Total time: 8363.14 seconds\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 74.853 \tLoss: 0.6923\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 60.964 \tLoss: 1.2854\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 76.896 \tLoss: 0.6742\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 63.349 \tLoss: 1.0309\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 76.216 \tLoss: 0.6825\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 58.648 \tLoss: 1.3539\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 74.060 \tLoss: 0.7227\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 64.776 \tLoss: 1.0222\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 73.550 \tLoss: 0.7103\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 57.388 \tLoss: 1.4183\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 75.742 \tLoss: 0.6985\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 71.404 \tLoss: 0.7939\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 74.593 \tLoss: 0.7185\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 63.524 \tLoss: 1.1111\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 75.561 \tLoss: 0.6865\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 60.008 \tLoss: 1.1972\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 75.048 \tLoss: 0.6999\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 62.217 \tLoss: 1.1965\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 75.216 \tLoss: 0.6898\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 64.467 \tLoss: 1.0787\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 75.117 \tLoss: 0.7081\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 62.803 \tLoss: 1.0823\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 75.053 \tLoss: 0.6972\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 67.827 \tLoss: 0.9575\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 76.075 \tLoss: 0.6970\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 66.831 \tLoss: 0.9810\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 75.182 \tLoss: 0.6969\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 65.127 \tLoss: 1.0459\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 52.040 \tLoss: 1.9629\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 11.880 \tLoss: 5.5401\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 74.616 \tLoss: 0.7044\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 65.127 \tLoss: 0.9747\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 54.738 \tLoss: 1.8503\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 7.348 \tLoss: 4.6095\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 75.871 \tLoss: 0.6959\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 66.750 \tLoss: 0.9379\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 75.894 \tLoss: 0.6737\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 68.218 \tLoss: 1.0563\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 75.430 \tLoss: 0.7192\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client2 Test =>                   \tAcc: 71.498 \tLoss: 0.8004\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  69, Avg Accuracy 73.088 | Avg Loss 0.819\n",
      " Test: Round  69, Avg Accuracy 58.489 | Avg Loss 1.517\n",
      "==========================================================\n",
      "idxs_users [ 7  9 12  3 14  8  1 16 13 11  5 17 18  6 19 10  0 15  4  2]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 9, 12, 3, 14, 8, 1, 16, 13, 11, 5, 17, 18, 6, 10, 15, 4, 2]\n",
      "fedserver选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19]\n",
      "acc: 60.964439392089844\n",
      "acc: 63.348599433898926\n",
      "acc: 58.64762878417969\n",
      "acc: 64.77640056610107\n",
      "acc: 57.388200759887695\n",
      "acc: 71.40355682373047\n",
      "acc: 63.52370643615723\n",
      "acc: 60.00808143615723\n",
      "acc: 62.21713352203369\n",
      "acc: 64.46659469604492\n",
      "acc: 62.80307102203369\n",
      "acc: 67.82731628417969\n",
      "acc: 66.8305492401123\n",
      "acc: 65.12661647796631\n",
      "acc: 65.12661647796631\n",
      "acc: 66.74973106384277\n",
      "acc: 68.21794128417969\n",
      "acc: 71.49784469604492\n",
      "====================== Fed Server==========================\n",
      " Train: Round  69, Avg Accuracy 73.088 | Avg Loss 0.819\n",
      " Test: Round  69, Avg Accuracy 64.496 | Avg Loss 1.074\n",
      "==========================================================\n",
      "Epoch 69 finished in 00:02:00\n",
      "Epoch 69 finished. Total time: 8483.26 seconds\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 74.922 \tLoss: 0.7118\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 65.659 \tLoss: 1.0898\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 75.099 \tLoss: 0.7050\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 65.463 \tLoss: 0.9995\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 75.464 \tLoss: 0.6977\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 67.861 \tLoss: 0.9568\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 75.044 \tLoss: 0.7016\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 65.854 \tLoss: 1.2199\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 75.680 \tLoss: 0.6805\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 68.157 \tLoss: 1.0362\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 74.740 \tLoss: 0.7041\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 67.356 \tLoss: 0.9520\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 53.141 \tLoss: 1.8795\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 7.368 \tLoss: 5.3514\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 74.897 \tLoss: 0.7053\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 64.891 \tLoss: 1.0388\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 75.122 \tLoss: 0.7090\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 63.524 \tLoss: 0.9988\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 75.542 \tLoss: 0.6932\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 65.383 \tLoss: 1.0205\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 55.326 \tLoss: 1.8513\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 10.715 \tLoss: 4.0578\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 75.404 \tLoss: 0.7088\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 61.126 \tLoss: 1.1872\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 74.281 \tLoss: 0.7194\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 64.621 \tLoss: 1.0108\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 74.949 \tLoss: 0.6768\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 70.912 \tLoss: 0.9088\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 75.542 \tLoss: 0.6978\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 58.311 \tLoss: 1.1834\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 74.926 \tLoss: 0.6994\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 63.288 \tLoss: 1.0589\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 75.338 \tLoss: 0.6952\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 66.009 \tLoss: 1.0562\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 74.635 \tLoss: 0.7091\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 61.140 \tLoss: 1.2673\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 76.089 \tLoss: 0.6862\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 60.978 \tLoss: 1.2292\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 73.872 \tLoss: 0.7178\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client6 Test =>                   \tAcc: 74.124 \tLoss: 0.7217\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  70, Avg Accuracy 73.001 | Avg Loss 0.817\n",
      " Test: Round  70, Avg Accuracy 59.357 | Avg Loss 1.450\n",
      "==========================================================\n",
      "idxs_users [ 5  3  7 11  1  8 19 12 15  9  0  2 16  4 10 17 13 14 18  6]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 3, 7, 11, 1, 8, 12, 15, 9, 2, 16, 4, 10, 17, 13, 14, 18, 6]\n",
      "fedserver选择的客户端index: [0, 1, 2, 3, 4, 5, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "acc: 65.6586742401123\n",
      "acc: 65.4633617401123\n",
      "acc: 67.86099147796631\n",
      "acc: 65.8539867401123\n",
      "acc: 68.15732765197754\n",
      "acc: 67.35587310791016\n",
      "acc: 64.89089393615723\n",
      "acc: 63.52370643615723\n",
      "acc: 65.38254356384277\n",
      "acc: 61.12607765197754\n",
      "acc: 64.62149810791016\n",
      "acc: 70.91190719604492\n",
      "acc: 58.31088352203369\n",
      "acc: 63.28798484802246\n",
      "acc: 66.00889015197754\n",
      "acc: 61.13954734802246\n",
      "acc: 60.977909088134766\n",
      "acc: 74.12446022033691\n",
      "====================== Fed Server==========================\n",
      " Train: Round  70, Avg Accuracy 73.001 | Avg Loss 0.817\n",
      " Test: Round  70, Avg Accuracy 65.259 | Avg Loss 1.052\n",
      "==========================================================\n",
      "Epoch 70 finished in 00:02:00\n",
      "Epoch 70 finished. Total time: 8603.32 seconds\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 73.656 \tLoss: 0.7097\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 64.527 \tLoss: 1.0861\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 74.906 \tLoss: 0.7000\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 64.056 \tLoss: 1.0453\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 75.751 \tLoss: 0.7159\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 56.782 \tLoss: 1.4867\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 76.071 \tLoss: 0.6864\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 63.995 \tLoss: 1.1045\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 52.829 \tLoss: 1.9087\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 17.262 \tLoss: 4.9994\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 76.875 \tLoss: 0.6835\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 66.164 \tLoss: 0.9731\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 75.365 \tLoss: 0.6918\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 67.416 \tLoss: 1.0020\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 74.952 \tLoss: 0.7047\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 62.668 \tLoss: 1.0805\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 75.273 \tLoss: 0.6926\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 64.736 \tLoss: 0.9668\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 75.317 \tLoss: 0.7053\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 66.029 \tLoss: 0.9613\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 75.110 \tLoss: 0.6911\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 64.056 \tLoss: 1.1380\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 76.089 \tLoss: 0.6717\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 64.089 \tLoss: 1.1230\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 75.600 \tLoss: 0.6897\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 61.456 \tLoss: 1.2752\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 74.975 \tLoss: 0.6951\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 66.103 \tLoss: 0.9666\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 75.547 \tLoss: 0.6958\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 62.965 \tLoss: 1.1393\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 75.551 \tLoss: 0.6927\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 58.190 \tLoss: 1.2078\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 54.676 \tLoss: 1.8262\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 8.991 \tLoss: 3.8785\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 76.319 \tLoss: 0.6620\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 66.359 \tLoss: 0.9758\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 76.406 \tLoss: 0.6993\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 64.621 \tLoss: 1.0175\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 76.857 \tLoss: 0.6786\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client17 Test =>                   \tAcc: 75.801 \tLoss: 0.7292\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 3, 4, 5, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  71, Avg Accuracy 73.406 | Avg Loss 0.810\n",
      " Test: Round  71, Avg Accuracy 58.600 | Avg Loss 1.445\n",
      "==========================================================\n",
      "idxs_users [ 6  3  7  2 19 10 13 15  8  5 12 11 18 16  1 14  0  9  4 17]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 3, 7, 2, 10, 13, 15, 8, 5, 12, 11, 18, 16, 1, 14, 9, 4, 17]\n",
      "fedserver选择的客户端index: [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19]\n",
      "acc: 64.52720832824707\n",
      "acc: 64.05576515197754\n",
      "acc: 56.782057762145996\n",
      "acc: 63.995150566101074\n",
      "acc: 66.16379356384277\n",
      "acc: 67.4164867401123\n",
      "acc: 62.668373107910156\n",
      "acc: 64.73599147796631\n",
      "acc: 66.02909469604492\n",
      "acc: 64.05576515197754\n",
      "acc: 64.08943939208984\n",
      "acc: 61.456088066101074\n",
      "acc: 66.10317897796631\n",
      "acc: 62.96470832824707\n",
      "acc: 58.18965530395508\n",
      "acc: 66.35910606384277\n",
      "acc: 64.62149810791016\n",
      "acc: 75.80145454406738\n",
      "====================== Fed Server==========================\n",
      " Train: Round  71, Avg Accuracy 73.406 | Avg Loss 0.810\n",
      " Test: Round  71, Avg Accuracy 64.445 | Avg Loss 1.071\n",
      "==========================================================\n",
      "Epoch 71 finished in 00:02:00\n",
      "Epoch 71 finished. Total time: 8723.98 seconds\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 76.232 \tLoss: 0.6851\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 65.827 \tLoss: 1.0023\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 73.272 \tLoss: 0.7320\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 69.430 \tLoss: 0.8798\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 76.705 \tLoss: 0.6531\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 63.726 \tLoss: 1.1192\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 76.489 \tLoss: 0.6774\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 69.545 \tLoss: 1.0306\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 75.409 \tLoss: 0.6792\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 66.029 \tLoss: 1.0673\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 52.649 \tLoss: 1.8957\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 8.971 \tLoss: 6.1693\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 74.297 \tLoss: 0.7011\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 66.224 \tLoss: 0.9784\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 76.342 \tLoss: 0.6954\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 67.120 \tLoss: 1.0275\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 75.591 \tLoss: 0.6807\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 67.848 \tLoss: 0.9108\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 74.412 \tLoss: 0.7089\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 70.232 \tLoss: 0.8508\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 73.647 \tLoss: 0.7230\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 69.019 \tLoss: 0.9632\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 76.004 \tLoss: 0.6830\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 62.412 \tLoss: 1.2178\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 74.784 \tLoss: 0.6840\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 60.183 \tLoss: 1.2921\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 74.837 \tLoss: 0.7096\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 60.803 \tLoss: 1.1986\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 75.356 \tLoss: 0.6902\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 56.782 \tLoss: 1.5687\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 53.451 \tLoss: 1.8893\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 7.449 \tLoss: 4.2253\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 75.234 \tLoss: 0.7003\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 65.423 \tLoss: 1.0676\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 76.953 \tLoss: 0.6725\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 57.759 \tLoss: 1.4453\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 76.089 \tLoss: 0.6780\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 66.790 \tLoss: 1.0069\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 77.300 \tLoss: 0.6740\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client7 Test =>                   \tAcc: 72.932 \tLoss: 0.7945\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  72, Avg Accuracy 73.253 | Avg Loss 0.811\n",
      " Test: Round  72, Avg Accuracy 59.058 | Avg Loss 1.538\n",
      "==========================================================\n",
      "idxs_users [18  3  9  4  1 19 15 16 10  8  5  6 13  2 17  0 14 11 12  7]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18, 3, 9, 4, 1, 15, 16, 10, 8, 5, 6, 13, 2, 17, 14, 11, 12, 7]\n",
      "fedserver选择的客户端index: [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19]\n",
      "acc: 65.82704734802246\n",
      "acc: 69.43022537231445\n",
      "acc: 63.72575378417969\n",
      "acc: 69.54471969604492\n",
      "acc: 66.02909469604492\n",
      "acc: 66.22440719604492\n",
      "acc: 67.12015056610107\n",
      "acc: 67.84752082824707\n",
      "acc: 70.23168182373047\n",
      "acc: 69.01939582824707\n",
      "acc: 62.41244602203369\n",
      "acc: 60.183189392089844\n",
      "acc: 60.802802085876465\n",
      "acc: 56.782057762145996\n",
      "acc: 65.42295265197754\n",
      "acc: 57.758620262145996\n",
      "acc: 66.79014015197754\n",
      "acc: 72.93238067626953\n",
      "====================== Fed Server==========================\n",
      " Train: Round  72, Avg Accuracy 73.253 | Avg Loss 0.811\n",
      " Test: Round  72, Avg Accuracy 65.449 | Avg Loss 1.079\n",
      "==========================================================\n",
      "Epoch 72 finished in 00:02:00\n",
      "Epoch 72 finished. Total time: 8844.11 seconds\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 75.924 \tLoss: 0.6818\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 65.073 \tLoss: 1.0663\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 75.487 \tLoss: 0.6926\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 70.898 \tLoss: 0.8851\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 74.141 \tLoss: 0.7146\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 59.968 \tLoss: 1.3079\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 76.636 \tLoss: 0.6650\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 68.683 \tLoss: 0.9348\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 76.108 \tLoss: 0.6943\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 64.446 \tLoss: 1.1406\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 76.480 \tLoss: 0.6766\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 64.776 \tLoss: 0.9511\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 75.048 \tLoss: 0.6985\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 60.614 \tLoss: 1.3170\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 77.355 \tLoss: 0.6677\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 61.166 \tLoss: 1.3014\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 77.638 \tLoss: 0.6557\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 61.274 \tLoss: 1.2671\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 51.404 \tLoss: 1.9712\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 15.989 \tLoss: 4.2123\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 75.317 \tLoss: 0.6884\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 62.958 \tLoss: 1.0724\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 75.919 \tLoss: 0.6814\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 66.144 \tLoss: 1.0506\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 74.733 \tLoss: 0.7020\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 62.002 \tLoss: 1.1039\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 76.358 \tLoss: 0.6585\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 63.079 \tLoss: 1.1051\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 53.872 \tLoss: 1.8765\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 10.513 \tLoss: 4.8198\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 74.423 \tLoss: 0.7105\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 66.635 \tLoss: 0.9420\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 76.445 \tLoss: 0.6688\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 65.180 \tLoss: 1.0226\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 76.576 \tLoss: 0.6788\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 65.733 \tLoss: 0.9907\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 75.600 \tLoss: 0.6842\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 66.676 \tLoss: 0.9750\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 77.447 \tLoss: 0.6633\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client4 Test =>                   \tAcc: 76.037 \tLoss: 0.6675\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  73, Avg Accuracy 73.646 | Avg Loss 0.807\n",
      " Test: Round  73, Avg Accuracy 59.246 | Avg Loss 1.458\n",
      "==========================================================\n",
      "idxs_users [ 2 16  5  8 18 15 14 17 12 19 11  1  3  7  0  6  9 10 13  4]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 16, 5, 8, 18, 15, 14, 17, 12, 11, 1, 3, 7, 6, 9, 10, 13, 4]\n",
      "fedserver选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 15, 16, 17, 18, 19]\n",
      "acc: 65.0727367401123\n",
      "acc: 70.8984375\n",
      "acc: 59.96767234802246\n",
      "acc: 68.68265056610107\n",
      "acc: 64.44639015197754\n",
      "acc: 64.77640056610107\n",
      "acc: 60.614224433898926\n",
      "acc: 61.166486740112305\n",
      "acc: 61.274245262145996\n",
      "acc: 62.957974433898926\n",
      "acc: 66.14358806610107\n",
      "acc: 62.00161647796631\n",
      "acc: 63.07920265197754\n",
      "acc: 66.6352367401123\n",
      "acc: 65.180495262146\n",
      "acc: 65.73275852203369\n",
      "acc: 66.67564582824707\n",
      "acc: 76.03717613220215\n",
      "====================== Fed Server==========================\n",
      " Train: Round  73, Avg Accuracy 73.646 | Avg Loss 0.807\n",
      " Test: Round  73, Avg Accuracy 65.075 | Avg Loss 1.061\n",
      "==========================================================\n",
      "Epoch 73 finished in 00:02:00\n",
      "Epoch 73 finished. Total time: 8964.45 seconds\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 75.758 \tLoss: 0.6684\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 55.866 \tLoss: 1.5570\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 76.988 \tLoss: 0.6558\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 66.494 \tLoss: 1.0981\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 75.103 \tLoss: 0.6955\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 66.083 \tLoss: 1.0639\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 50.958 \tLoss: 1.9897\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 10.533 \tLoss: 4.7693\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 75.048 \tLoss: 0.6814\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 64.716 \tLoss: 1.0660\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 75.673 \tLoss: 0.6903\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 51.367 \tLoss: 1.9353\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 75.361 \tLoss: 0.6709\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 66.009 \tLoss: 1.1016\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 77.231 \tLoss: 0.6466\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 63.019 \tLoss: 1.1421\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 75.885 \tLoss: 0.6904\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 72.326 \tLoss: 0.8335\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 54.722 \tLoss: 1.8551\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 6.216 \tLoss: 4.3398\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 76.317 \tLoss: 0.6696\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 68.683 \tLoss: 0.9614\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 76.450 \tLoss: 0.6750\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 65.167 \tLoss: 1.0659\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 77.555 \tLoss: 0.6608\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 59.577 \tLoss: 1.3045\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 76.737 \tLoss: 0.6677\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 66.884 \tLoss: 0.9990\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 75.972 \tLoss: 0.6753\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 66.285 \tLoss: 1.0187\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 75.898 \tLoss: 0.6805\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 65.692 \tLoss: 0.9981\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 77.227 \tLoss: 0.6591\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 68.487 \tLoss: 0.9316\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 76.303 \tLoss: 0.6809\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 71.047 \tLoss: 0.9498\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 75.234 \tLoss: 0.6759\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 66.204 \tLoss: 0.9636\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 75.499 \tLoss: 0.6786\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client18 Test =>                   \tAcc: 71.127 \tLoss: 0.8572\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  74, Avg Accuracy 73.796 | Avg Loss 0.798\n",
      " Test: Round  74, Avg Accuracy 62.182 | Avg Loss 1.311\n",
      "==========================================================\n",
      "idxs_users [13 11  6 19 15  2 16  9  5  0  7 12 17 10  1 14  4  8  3 18]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13, 11, 6, 15, 2, 16, 9, 5, 7, 12, 17, 10, 1, 14, 4, 8, 3, 18]\n",
      "fedserver选择的客户端index: [0, 1, 2, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "acc: 55.86610984802246\n",
      "acc: 66.49380397796631\n",
      "acc: 66.08297443389893\n",
      "acc: 64.71578693389893\n",
      "acc: 51.3671875\n",
      "acc: 66.00889015197754\n",
      "acc: 63.018588066101074\n",
      "acc: 72.32623863220215\n",
      "acc: 68.68265056610107\n",
      "acc: 65.16702556610107\n",
      "acc: 59.57704734802246\n",
      "acc: 66.88442897796631\n",
      "acc: 66.28502082824707\n",
      "acc: 65.69234943389893\n",
      "acc: 68.48733806610107\n",
      "acc: 71.04660606384277\n",
      "acc: 66.20420265197754\n",
      "acc: 71.1274242401123\n",
      "====================== Fed Server==========================\n",
      " Train: Round  74, Avg Accuracy 73.796 | Avg Loss 0.798\n",
      " Test: Round  74, Avg Accuracy 65.280 | Avg Loss 1.103\n",
      "==========================================================\n",
      "Epoch 74 finished in 00:02:00\n",
      "Epoch 74 finished. Total time: 9084.64 seconds\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 75.898 \tLoss: 0.6833\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 69.275 \tLoss: 0.9408\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 75.926 \tLoss: 0.6827\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 64.406 \tLoss: 1.1326\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 76.310 \tLoss: 0.6598\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 67.046 \tLoss: 0.9912\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 77.132 \tLoss: 0.6626\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 64.116 \tLoss: 1.1103\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 75.614 \tLoss: 0.6792\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 64.271 \tLoss: 1.0098\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 76.992 \tLoss: 0.6622\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 71.612 \tLoss: 0.8308\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 76.645 \tLoss: 0.6732\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 69.060 \tLoss: 0.9165\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 53.316 \tLoss: 1.9302\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 11.200 \tLoss: 5.5214\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 54.899 \tLoss: 1.8725\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 9.947 \tLoss: 5.8379\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 77.061 \tLoss: 0.6560\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 68.043 \tLoss: 0.9320\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 77.378 \tLoss: 0.6462\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 64.036 \tLoss: 1.1285\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 77.647 \tLoss: 0.6687\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 62.729 \tLoss: 1.1253\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 76.347 \tLoss: 0.6591\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 61.591 \tLoss: 1.2414\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 75.742 \tLoss: 0.6805\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 63.935 \tLoss: 1.0560\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 75.738 \tLoss: 0.6762\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 68.097 \tLoss: 0.9990\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 77.647 \tLoss: 0.6450\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 71.208 \tLoss: 0.8421\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 77.656 \tLoss: 0.6494\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 64.992 \tLoss: 1.0165\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 76.119 \tLoss: 0.6892\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 64.918 \tLoss: 1.1664\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 75.602 \tLoss: 0.6811\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 68.413 \tLoss: 0.9721\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 77.374 \tLoss: 0.6396\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client9 Test =>                   \tAcc: 76.839 \tLoss: 0.7124\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  75, Avg Accuracy 74.352 | Avg Loss 0.790\n",
      " Test: Round  75, Avg Accuracy 60.754 | Avg Loss 1.524\n",
      "==========================================================\n",
      "idxs_users [14  6 13 17 16  8 10 19  0  1 11 18  7  2 12  4 15  3  5  9]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14, 6, 13, 17, 16, 8, 10, 1, 11, 18, 7, 2, 12, 4, 15, 3, 5, 9]\n",
      "fedserver选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "acc: 69.27532386779785\n",
      "acc: 64.40598106384277\n",
      "acc: 67.04606628417969\n",
      "acc: 64.11637878417969\n",
      "acc: 64.27128219604492\n",
      "acc: 71.61233806610107\n",
      "acc: 69.05980682373047\n",
      "acc: 68.04283332824707\n",
      "acc: 64.03556060791016\n",
      "acc: 62.728986740112305\n",
      "acc: 61.590786933898926\n",
      "acc: 63.934536933898926\n",
      "acc: 68.09671306610107\n",
      "acc: 71.20824432373047\n",
      "acc: 64.99191856384277\n",
      "acc: 64.91783332824707\n",
      "acc: 68.41325378417969\n",
      "acc: 76.83863067626953\n",
      "====================== Fed Server==========================\n",
      " Train: Round  75, Avg Accuracy 74.352 | Avg Loss 0.790\n",
      " Test: Round  75, Avg Accuracy 66.921 | Avg Loss 1.007\n",
      "==========================================================\n",
      "Epoch 75 finished in 00:02:00\n",
      "Epoch 75 finished. Total time: 9204.71 seconds\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 75.372 \tLoss: 0.6889\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 63.860 \tLoss: 1.1155\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 76.864 \tLoss: 0.6657\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 64.399 \tLoss: 1.1087\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 51.271 \tLoss: 1.9332\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 9.813 \tLoss: 7.3283\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 76.356 \tLoss: 0.6693\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 64.291 \tLoss: 1.0591\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 76.029 \tLoss: 0.6571\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 72.185 \tLoss: 0.9128\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 76.597 \tLoss: 0.6535\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 63.409 \tLoss: 1.0871\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 77.332 \tLoss: 0.6518\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 65.753 \tLoss: 1.0109\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 75.687 \tLoss: 0.6845\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 67.107 \tLoss: 1.0905\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 76.866 \tLoss: 0.6670\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 68.609 \tLoss: 0.9230\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 76.505 \tLoss: 0.6474\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 68.649 \tLoss: 0.9434\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 75.312 \tLoss: 0.6694\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 62.035 \tLoss: 1.1802\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 77.971 \tLoss: 0.6416\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 59.671 \tLoss: 1.4056\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 77.300 \tLoss: 0.6440\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 69.504 \tLoss: 0.9299\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 53.925 \tLoss: 1.9265\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 13.369 \tLoss: 4.0521\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 76.845 \tLoss: 0.6786\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 61.456 \tLoss: 1.2494\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 77.440 \tLoss: 0.6455\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 69.040 \tLoss: 1.0083\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 75.756 \tLoss: 0.6644\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 62.763 \tLoss: 1.1390\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 75.878 \tLoss: 0.6855\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 68.669 \tLoss: 0.9732\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 75.464 \tLoss: 0.6661\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 68.784 \tLoss: 0.8865\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 76.142 \tLoss: 0.6632\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client17 Test =>                   \tAcc: 75.795 \tLoss: 0.7018\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  76, Avg Accuracy 74.046 | Avg Loss 0.790\n",
      " Test: Round  76, Avg Accuracy 60.191 | Avg Loss 1.561\n",
      "==========================================================\n",
      "idxs_users [ 5 11 19 10 13 14  9  8 16  1  3 18  4  0  7 12  6  2 15 17]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 11, 10, 13, 14, 9, 8, 16, 1, 3, 18, 4, 7, 12, 6, 2, 15, 17]\n",
      "fedserver选择的客户端index: [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19]\n",
      "acc: 63.86045265197754\n",
      "acc: 64.399245262146\n",
      "acc: 64.2914867401123\n",
      "acc: 72.18480682373047\n",
      "acc: 63.409213066101074\n",
      "acc: 65.75296306610107\n",
      "acc: 67.10668182373047\n",
      "acc: 68.60856628417969\n",
      "acc: 68.64897537231445\n",
      "acc: 62.03529071807861\n",
      "acc: 59.67133617401123\n",
      "acc: 69.50431060791016\n",
      "acc: 61.456088066101074\n",
      "acc: 69.03960037231445\n",
      "acc: 62.762661933898926\n",
      "acc: 68.66918182373047\n",
      "acc: 68.7836742401123\n",
      "acc: 75.79471969604492\n",
      "====================== Fed Server==========================\n",
      " Train: Round  76, Avg Accuracy 74.046 | Avg Loss 0.790\n",
      " Test: Round  76, Avg Accuracy 66.443 | Avg Loss 1.040\n",
      "==========================================================\n",
      "Epoch 76 finished in 00:02:00\n",
      "Epoch 76 finished. Total time: 9324.83 seconds\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 53.750 \tLoss: 1.9563\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 11.611 \tLoss: 4.1977\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 76.484 \tLoss: 0.6567\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 60.217 \tLoss: 1.2158\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 76.992 \tLoss: 0.6574\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 65.719 \tLoss: 0.9886\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 54.676 \tLoss: 1.8788\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 11.005 \tLoss: 5.5247\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 77.178 \tLoss: 0.6476\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 66.110 \tLoss: 0.9359\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 76.728 \tLoss: 0.6756\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 61.301 \tLoss: 1.2332\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 77.162 \tLoss: 0.6501\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 70.737 \tLoss: 0.9089\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 77.493 \tLoss: 0.6516\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 62.513 \tLoss: 1.1701\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 74.573 \tLoss: 0.6891\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 62.729 \tLoss: 1.1438\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 77.240 \tLoss: 0.6622\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 65.443 \tLoss: 0.9833\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 77.217 \tLoss: 0.6445\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 65.854 \tLoss: 1.0718\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 77.353 \tLoss: 0.6377\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 70.508 \tLoss: 0.9437\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 77.907 \tLoss: 0.6329\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 70.057 \tLoss: 0.8835\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 76.372 \tLoss: 0.6516\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 64.453 \tLoss: 1.1275\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 76.108 \tLoss: 0.6730\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 69.861 \tLoss: 0.8999\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 76.098 \tLoss: 0.6583\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 63.544 \tLoss: 1.1425\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 77.295 \tLoss: 0.6487\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 65.073 \tLoss: 1.1204\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 78.150 \tLoss: 0.6210\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 65.928 \tLoss: 1.0760\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 75.439 \tLoss: 0.6904\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 61.180 \tLoss: 1.2506\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 75.455 \tLoss: 0.6900\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client5 Test =>                   \tAcc: 75.882 \tLoss: 0.7164\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  77, Avg Accuracy 74.484 | Avg Loss 0.784\n",
      " Test: Round  77, Avg Accuracy 59.975 | Avg Loss 1.468\n",
      "==========================================================\n",
      "idxs_users [19 13  3  0  1  2  4  7 14 15 12  9  8 18 10  6 11 17 16  5]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13, 3, 1, 2, 4, 7, 14, 15, 12, 9, 8, 18, 10, 6, 11, 17, 16, 5]\n",
      "fedserver选择的客户端index: [1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "acc: 60.216864585876465\n",
      "acc: 65.71928787231445\n",
      "acc: 66.10991287231445\n",
      "acc: 61.301185607910156\n",
      "acc: 70.7367992401123\n",
      "acc: 62.51346969604492\n",
      "acc: 62.728986740112305\n",
      "acc: 65.44315719604492\n",
      "acc: 65.8539867401123\n",
      "acc: 70.5078125\n",
      "acc: 70.05657386779785\n",
      "acc: 64.453125\n",
      "acc: 69.86126136779785\n",
      "acc: 63.543911933898926\n",
      "acc: 65.0727367401123\n",
      "acc: 65.92807102203369\n",
      "acc: 61.17995643615723\n",
      "acc: 75.88227272033691\n",
      "====================== Fed Server==========================\n",
      " Train: Round  77, Avg Accuracy 74.484 | Avg Loss 0.784\n",
      " Test: Round  77, Avg Accuracy 65.951 | Avg Loss 1.045\n",
      "==========================================================\n",
      "Epoch 77 finished in 00:02:00\n",
      "Epoch 77 finished. Total time: 9445.08 seconds\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 76.392 \tLoss: 0.6750\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 69.114 \tLoss: 1.0157\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 76.939 \tLoss: 0.6660\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 67.039 \tLoss: 0.9343\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 77.725 \tLoss: 0.6242\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 67.140 \tLoss: 1.0383\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 75.903 \tLoss: 0.6686\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 63.645 \tLoss: 1.1052\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 52.479 \tLoss: 1.9807\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 8.405 \tLoss: 4.2861\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 76.714 \tLoss: 0.6399\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 66.635 \tLoss: 1.0355\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 76.753 \tLoss: 0.6661\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 68.999 \tLoss: 0.8686\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 53.405 \tLoss: 1.9232\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 11.860 \tLoss: 4.4608\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 74.940 \tLoss: 0.6818\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 63.571 \tLoss: 1.0926\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 77.530 \tLoss: 0.6400\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 64.386 \tLoss: 1.1100\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 76.693 \tLoss: 0.6652\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 70.568 \tLoss: 0.9066\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 77.631 \tLoss: 0.6516\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 70.878 \tLoss: 0.9100\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 77.204 \tLoss: 0.6595\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 65.093 \tLoss: 1.0507\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 75.825 \tLoss: 0.6739\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 66.676 \tLoss: 1.0129\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 76.631 \tLoss: 0.6704\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 65.362 \tLoss: 1.0194\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 77.091 \tLoss: 0.6468\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 64.231 \tLoss: 1.0408\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 77.261 \tLoss: 0.6595\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 65.699 \tLoss: 0.9611\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 77.309 \tLoss: 0.6437\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 66.716 \tLoss: 1.0242\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 76.719 \tLoss: 0.6556\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 63.719 \tLoss: 1.2720\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 76.181 \tLoss: 0.6564\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client8 Test =>                   \tAcc: 76.623 \tLoss: 0.6785\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  78, Avg Accuracy 74.366 | Avg Loss 0.787\n",
      " Test: Round  78, Avg Accuracy 60.756 | Avg Loss 1.372\n",
      "==========================================================\n",
      "idxs_users [13 16 12 14 19  9 10  0  3 18  4 17  6  2  5  1 15  7 11  8]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13, 16, 12, 14, 9, 10, 3, 18, 4, 17, 6, 2, 5, 1, 15, 7, 11, 8]\n",
      "fedserver选择的客户端index: [0, 1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "acc: 69.11368560791016\n",
      "acc: 67.03933143615723\n",
      "acc: 67.14035606384277\n",
      "acc: 63.644935607910156\n",
      "acc: 66.6352367401123\n",
      "acc: 68.99919128417969\n",
      "acc: 63.57085037231445\n",
      "acc: 64.38577556610107\n",
      "acc: 70.56842613220215\n",
      "acc: 70.87823295593262\n",
      "acc: 65.09294128417969\n",
      "acc: 66.67564582824707\n",
      "acc: 65.36233806610107\n",
      "acc: 64.23087310791016\n",
      "acc: 65.69908332824707\n",
      "acc: 66.71605682373047\n",
      "acc: 63.71901893615723\n",
      "acc: 76.62311363220215\n",
      "====================== Fed Server==========================\n",
      " Train: Round  78, Avg Accuracy 74.366 | Avg Loss 0.787\n",
      " Test: Round  78, Avg Accuracy 67.005 | Avg Loss 1.004\n",
      "==========================================================\n",
      "Epoch 78 finished in 00:02:00\n",
      "Epoch 78 finished. Total time: 9565.36 seconds\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 77.778 \tLoss: 0.6335\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 65.127 \tLoss: 0.9794\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 77.583 \tLoss: 0.6311\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 63.874 \tLoss: 1.0962\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 78.091 \tLoss: 0.6208\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 63.706 \tLoss: 1.1577\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 77.829 \tLoss: 0.6400\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 66.501 \tLoss: 1.1204\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 77.325 \tLoss: 0.6387\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 66.278 \tLoss: 0.9669\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 77.491 \tLoss: 0.6344\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 68.002 \tLoss: 0.9624\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 76.450 \tLoss: 0.6489\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 71.269 \tLoss: 0.8544\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 77.086 \tLoss: 0.6340\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 64.211 \tLoss: 1.0770\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 77.178 \tLoss: 0.6465\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 67.080 \tLoss: 1.0279\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 78.150 \tLoss: 0.6252\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 64.096 \tLoss: 1.2113\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 76.700 \tLoss: 0.6601\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 65.383 \tLoss: 1.2188\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 76.602 \tLoss: 0.6570\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 68.009 \tLoss: 0.9683\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 76.078 \tLoss: 0.6573\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 62.998 \tLoss: 1.1053\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 50.319 \tLoss: 2.0287\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 12.042 \tLoss: 3.9871\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 54.262 \tLoss: 1.9146\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 7.543 \tLoss: 4.8872\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 75.655 \tLoss: 0.6398\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 68.979 \tLoss: 0.9881\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 77.670 \tLoss: 0.6332\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 66.204 \tLoss: 1.0550\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 77.123 \tLoss: 0.6585\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 66.554 \tLoss: 0.9478\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 76.811 \tLoss: 0.6658\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 71.404 \tLoss: 0.8639\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 77.066 \tLoss: 0.6549\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client4 Test =>                   \tAcc: 77.290 \tLoss: 0.6517\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  79, Avg Accuracy 74.662 | Avg Loss 0.776\n",
      " Test: Round  79, Avg Accuracy 60.892 | Avg Loss 1.393\n",
      "==========================================================\n",
      "idxs_users [ 8 10  9 13  1 17 16 12  7 18 11  2  3 19  0  6 14 15  5  4]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 10, 9, 13, 1, 17, 16, 12, 7, 18, 11, 2, 3, 6, 14, 15, 5, 4]\n",
      "fedserver选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19]\n",
      "acc: 65.12661647796631\n",
      "acc: 63.87392234802246\n",
      "acc: 63.705549240112305\n",
      "acc: 66.50053787231445\n",
      "acc: 66.27828693389893\n",
      "acc: 68.0024242401123\n",
      "acc: 71.26885795593262\n",
      "acc: 64.21066856384277\n",
      "acc: 67.07974147796631\n",
      "acc: 64.0961742401123\n",
      "acc: 65.38254356384277\n",
      "acc: 68.00915908813477\n",
      "acc: 62.99838352203369\n",
      "acc: 68.9789867401123\n",
      "acc: 66.20420265197754\n",
      "acc: 66.55441856384277\n",
      "acc: 71.40355682373047\n",
      "acc: 77.28987121582031\n",
      "====================== Fed Server==========================\n",
      " Train: Round  79, Avg Accuracy 74.662 | Avg Loss 0.776\n",
      " Test: Round  79, Avg Accuracy 67.054 | Avg Loss 1.014\n",
      "==========================================================\n",
      "Epoch 79 finished in 00:02:00\n",
      "Epoch 79 finished. Total time: 9685.62 seconds\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 76.436 \tLoss: 0.6477\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 71.323 \tLoss: 0.9135\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 77.739 \tLoss: 0.6232\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 64.285 \tLoss: 1.0769\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 76.489 \tLoss: 0.6630\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 66.514 \tLoss: 1.1118\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 76.870 \tLoss: 0.6419\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 70.326 \tLoss: 0.9128\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 77.750 \tLoss: 0.6274\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 62.352 \tLoss: 1.1250\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 76.932 \tLoss: 0.6560\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 65.362 \tLoss: 0.9918\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 77.983 \tLoss: 0.6308\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 62.352 \tLoss: 1.2752\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 76.432 \tLoss: 0.6439\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 67.922 \tLoss: 1.0017\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 78.012 \tLoss: 0.6242\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 66.844 \tLoss: 1.0203\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 54.285 \tLoss: 1.8985\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 11.550 \tLoss: 4.2513\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 77.162 \tLoss: 0.6217\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 61.530 \tLoss: 1.2071\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 76.730 \tLoss: 0.6709\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 64.702 \tLoss: 1.0990\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 77.461 \tLoss: 0.6415\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 69.289 \tLoss: 0.8670\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 79.023 \tLoss: 0.6042\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 63.133 \tLoss: 1.1431\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 76.714 \tLoss: 0.6485\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 72.501 \tLoss: 0.7806\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 78.235 \tLoss: 0.6289\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 66.440 \tLoss: 1.0188\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 78.194 \tLoss: 0.6261\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 69.275 \tLoss: 0.9594\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 52.367 \tLoss: 1.9843\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 12.547 \tLoss: 4.2995\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 77.174 \tLoss: 0.6448\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 67.201 \tLoss: 0.9401\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 77.472 \tLoss: 0.6577\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client14 Test =>                   \tAcc: 75.579 \tLoss: 0.7131\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  80, Avg Accuracy 74.973 | Avg Loss 0.769\n",
      " Test: Round  80, Avg Accuracy 60.855 | Avg Loss 1.377\n",
      "==========================================================\n",
      "idxs_users [ 6  2 11 13  7 15  1  4 16  0 17  5 10  9  8 18 12 19  3 14]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 2, 11, 13, 7, 15, 1, 4, 17, 5, 10, 9, 8, 18, 12, 19, 3, 14]\n",
      "fedserver选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "acc: 71.3227367401123\n",
      "acc: 64.28475189208984\n",
      "acc: 66.51400852203369\n",
      "acc: 70.32596969604492\n",
      "acc: 62.35183143615723\n",
      "acc: 65.36233806610107\n",
      "acc: 62.35183143615723\n",
      "acc: 67.92160606384277\n",
      "acc: 61.53017234802246\n",
      "acc: 64.70231628417969\n",
      "acc: 69.28879356384277\n",
      "acc: 63.13308143615723\n",
      "acc: 72.50134658813477\n",
      "acc: 66.4399242401123\n",
      "acc: 69.27532386779785\n",
      "acc: 12.547144412994385\n",
      "acc: 67.20096969604492\n",
      "acc: 75.57920265197754\n",
      "====================== Fed Server==========================\n",
      " Train: Round  80, Avg Accuracy 74.973 | Avg Loss 0.769\n",
      " Test: Round  80, Avg Accuracy 64.035 | Avg Loss 1.191\n",
      "==========================================================\n",
      "Epoch 80 finished in 00:02:00\n",
      "Epoch 80 finished. Total time: 9805.94 seconds\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 76.347 \tLoss: 0.6540\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 69.484 \tLoss: 0.8855\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 77.105 \tLoss: 0.6349\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 66.985 \tLoss: 1.0881\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 75.882 \tLoss: 0.6580\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 68.609 \tLoss: 0.9340\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 77.514 \tLoss: 0.6339\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 70.191 \tLoss: 0.8471\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 77.261 \tLoss: 0.6435\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 65.719 \tLoss: 1.0320\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 52.714 \tLoss: 1.9775\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 11.591 \tLoss: 5.1368\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 77.277 \tLoss: 0.6318\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 61.840 \tLoss: 1.2743\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 76.544 \tLoss: 0.6434\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 67.706 \tLoss: 0.9251\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 78.511 \tLoss: 0.6504\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 64.918 \tLoss: 0.9881\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 77.463 \tLoss: 0.6262\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 64.426 \tLoss: 1.0579\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 53.555 \tLoss: 1.9809\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 9.597 \tLoss: 3.9612\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 78.242 \tLoss: 0.6136\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 66.864 \tLoss: 1.0644\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 76.762 \tLoss: 0.6432\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 66.103 \tLoss: 0.9763\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 77.070 \tLoss: 0.6378\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 66.319 \tLoss: 1.0091\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 78.389 \tLoss: 0.6221\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 70.993 \tLoss: 0.8960\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 76.103 \tLoss: 0.6509\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 62.668 \tLoss: 1.1205\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 78.589 \tLoss: 0.6271\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 66.440 \tLoss: 0.9739\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 78.238 \tLoss: 0.6214\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 68.959 \tLoss: 0.9726\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 78.277 \tLoss: 0.6092\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 67.652 \tLoss: 1.0012\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 76.505 \tLoss: 0.6366\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client17 Test =>                   \tAcc: 75.606 \tLoss: 0.7036\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  81, Avg Accuracy 74.917 | Avg Loss 0.770\n",
      " Test: Round  81, Avg Accuracy 61.296 | Avg Loss 1.378\n",
      "==========================================================\n",
      "idxs_users [ 3 16  6 10  2 19 12  5 15 13  0 18  4  8 11 14  7  1  9 17]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 16, 6, 10, 2, 12, 5, 15, 13, 18, 4, 8, 11, 14, 7, 1, 9, 17]\n",
      "fedserver选择的客户端index: [0, 1, 2, 3, 4, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "acc: 69.48410606384277\n",
      "acc: 66.98545265197754\n",
      "acc: 68.60856628417969\n",
      "acc: 70.19127082824707\n",
      "acc: 65.71928787231445\n",
      "acc: 61.83997821807861\n",
      "acc: 67.70608806610107\n",
      "acc: 64.91783332824707\n",
      "acc: 64.42618560791016\n",
      "acc: 66.86422443389893\n",
      "acc: 66.10317897796631\n",
      "acc: 66.31869602203369\n",
      "acc: 70.99272537231445\n",
      "acc: 62.668373107910156\n",
      "acc: 66.4399242401123\n",
      "acc: 68.95878219604492\n",
      "acc: 67.65220832824707\n",
      "acc: 75.60614204406738\n",
      "====================== Fed Server==========================\n",
      " Train: Round  81, Avg Accuracy 74.917 | Avg Loss 0.770\n",
      " Test: Round  81, Avg Accuracy 67.305 | Avg Loss 0.986\n",
      "==========================================================\n",
      "Epoch 81 finished in 00:02:00\n",
      "Epoch 81 finished. Total time: 9926.05 seconds\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 53.405 \tLoss: 1.9667\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 6.607 \tLoss: 4.2859\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 77.305 \tLoss: 0.6340\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 66.945 \tLoss: 0.9637\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 77.792 \tLoss: 0.6331\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 71.053 \tLoss: 0.9831\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 77.475 \tLoss: 0.6367\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 65.308 \tLoss: 0.9830\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 77.452 \tLoss: 0.6242\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 69.235 \tLoss: 1.0653\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 78.828 \tLoss: 0.6195\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 66.952 \tLoss: 1.0014\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 78.711 \tLoss: 0.6180\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 66.595 \tLoss: 1.0251\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 75.804 \tLoss: 0.6649\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 64.190 \tLoss: 1.0860\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 76.792 \tLoss: 0.6490\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 65.968 \tLoss: 1.0618\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 52.454 \tLoss: 1.9812\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 7.563 \tLoss: 4.4556\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 77.822 \tLoss: 0.6401\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 67.787 \tLoss: 1.1455\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 77.509 \tLoss: 0.6411\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 58.270 \tLoss: 1.2546\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 76.592 \tLoss: 0.6432\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 67.262 \tLoss: 0.9510\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 78.164 \tLoss: 0.6342\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 67.693 \tLoss: 1.0080\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 78.573 \tLoss: 0.6185\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 66.379 \tLoss: 1.0278\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 76.677 \tLoss: 0.6485\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 65.484 \tLoss: 0.9594\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 77.755 \tLoss: 0.6286\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 64.291 \tLoss: 1.1368\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 78.332 \tLoss: 0.6022\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 67.120 \tLoss: 0.9761\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 77.914 \tLoss: 0.6172\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 64.621 \tLoss: 1.0996\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 77.247 \tLoss: 0.6362\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client14 Test =>                   \tAcc: 77.371 \tLoss: 0.6931\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 3, 4, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  82, Avg Accuracy 75.130 | Avg Loss 0.767\n",
      " Test: Round  82, Avg Accuracy 60.109 | Avg Loss 1.390\n",
      "==========================================================\n",
      "idxs_users [ 0 18  8 15 11  1 17  5  2 19  4 10 16 12  7  3 13  9  6 14]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18, 8, 15, 11, 1, 17, 5, 2, 4, 10, 16, 12, 7, 3, 13, 9, 6, 14]\n",
      "fedserver选择的客户端index: [1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "acc: 66.94504356384277\n",
      "acc: 71.05334091186523\n",
      "acc: 65.30845832824707\n",
      "acc: 69.23491287231445\n",
      "acc: 66.95177841186523\n",
      "acc: 66.59482765197754\n",
      "acc: 64.19046306610107\n",
      "acc: 65.96848106384277\n",
      "acc: 67.78690719604492\n",
      "acc: 58.270474433898926\n",
      "acc: 67.26158332824707\n",
      "acc: 67.69261932373047\n",
      "acc: 66.37931060791016\n",
      "acc: 65.48356628417969\n",
      "acc: 64.2914867401123\n",
      "acc: 67.12015056610107\n",
      "acc: 64.62149810791016\n",
      "acc: 77.37068939208984\n",
      "====================== Fed Server==========================\n",
      " Train: Round  82, Avg Accuracy 75.130 | Avg Loss 0.767\n",
      " Test: Round  82, Avg Accuracy 66.807 | Avg Loss 1.023\n",
      "==========================================================\n",
      "Epoch 82 finished in 00:02:00\n",
      "Epoch 82 finished. Total time: 10046.51 seconds\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 76.762 \tLoss: 0.6326\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 68.137 \tLoss: 0.9806\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 78.189 \tLoss: 0.6375\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 70.501 \tLoss: 0.8421\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 78.644 \tLoss: 0.5964\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 69.450 \tLoss: 0.9264\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 77.746 \tLoss: 0.6270\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 66.514 \tLoss: 0.9996\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 54.550 \tLoss: 1.9297\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 10.224 \tLoss: 3.7222\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 79.097 \tLoss: 0.6141\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 66.689 \tLoss: 1.1041\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 78.336 \tLoss: 0.6153\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 67.376 \tLoss: 0.9352\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 78.033 \tLoss: 0.6211\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 54.768 \tLoss: 1.6227\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 78.028 \tLoss: 0.6076\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 61.180 \tLoss: 1.2538\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 52.585 \tLoss: 1.9994\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 11.705 \tLoss: 4.2130\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 77.422 \tLoss: 0.6229\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 67.302 \tLoss: 1.0275\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 78.332 \tLoss: 0.6273\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 70.387 \tLoss: 0.8956\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 78.575 \tLoss: 0.6147\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 60.358 \tLoss: 1.2125\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 77.939 \tLoss: 0.6212\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 64.716 \tLoss: 1.0945\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 78.575 \tLoss: 0.6168\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 69.666 \tLoss: 0.9105\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 77.008 \tLoss: 0.6345\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 63.389 \tLoss: 1.1285\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 76.510 \tLoss: 0.6480\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 69.114 \tLoss: 0.9956\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 78.258 \tLoss: 0.6056\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 69.700 \tLoss: 0.9737\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 76.861 \tLoss: 0.6512\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 64.696 \tLoss: 1.1653\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 78.164 \tLoss: 0.6236\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client12 Test =>                   \tAcc: 74.333 \tLoss: 0.7571\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  83, Avg Accuracy 75.481 | Avg Loss 0.757\n",
      " Test: Round  83, Avg Accuracy 63.353 | Avg Loss 1.198\n",
      "==========================================================\n",
      "idxs_users [15  8  9  2  0  7  1 11 18 19  6 10 14 13  4  5  3 17 16 12]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15, 8, 9, 2, 7, 1, 11, 18, 6, 10, 14, 13, 4, 5, 3, 17, 16, 12]\n",
      "fedserver选择的客户端index: [0, 1, 2, 3, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "acc: 68.13712310791016\n",
      "acc: 70.50107765197754\n",
      "acc: 69.45043182373047\n",
      "acc: 66.51400852203369\n",
      "acc: 66.68911647796631\n",
      "acc: 67.37607765197754\n",
      "acc: 54.76831912994385\n",
      "acc: 61.17995643615723\n",
      "acc: 67.30199432373047\n",
      "acc: 70.38658332824707\n",
      "acc: 60.35829734802246\n",
      "acc: 64.71578693389893\n",
      "acc: 69.66594886779785\n",
      "acc: 63.38900852203369\n",
      "acc: 69.11368560791016\n",
      "acc: 69.69962310791016\n",
      "acc: 64.69558143615723\n",
      "acc: 74.33324432373047\n",
      "====================== Fed Server==========================\n",
      " Train: Round  83, Avg Accuracy 75.481 | Avg Loss 0.757\n",
      " Test: Round  83, Avg Accuracy 66.571 | Avg Loss 1.046\n",
      "==========================================================\n",
      "Epoch 83 finished in 00:02:00\n",
      "Epoch 83 finished. Total time: 10166.81 seconds\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 54.497 \tLoss: 1.9369\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 11.025 \tLoss: 4.8493\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 77.842 \tLoss: 0.6161\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 68.063 \tLoss: 0.9455\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 78.984 \tLoss: 0.6151\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 61.725 \tLoss: 1.2249\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 52.677 \tLoss: 2.0063\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 12.662 \tLoss: 5.0363\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 77.291 \tLoss: 0.6381\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 62.742 \tLoss: 1.1265\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 77.613 \tLoss: 0.6201\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 71.134 \tLoss: 0.8739\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 78.589 \tLoss: 0.5909\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 66.359 \tLoss: 1.0214\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 77.790 \tLoss: 0.6319\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 71.154 \tLoss: 0.8569\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 78.033 \tLoss: 0.6286\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 62.042 \tLoss: 1.1754\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 78.238 \tLoss: 0.5857\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 65.753 \tLoss: 1.0737\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 77.978 \tLoss: 0.6167\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 66.588 \tLoss: 1.0183\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 76.845 \tLoss: 0.6289\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 62.628 \tLoss: 1.2344\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 77.578 \tLoss: 0.6430\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 64.150 \tLoss: 1.0956\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 77.695 \tLoss: 0.6324\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 65.106 \tLoss: 1.0773\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 78.472 \tLoss: 0.6118\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 63.227 \tLoss: 1.1941\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 77.670 \tLoss: 0.6285\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 67.787 \tLoss: 1.0338\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 78.325 \tLoss: 0.6247\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 67.282 \tLoss: 1.0141\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 77.787 \tLoss: 0.6318\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 65.598 \tLoss: 1.0677\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 77.877 \tLoss: 0.6411\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 68.494 \tLoss: 0.9805\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 78.812 \tLoss: 0.6163\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client1 Test =>                   \tAcc: 74.495 \tLoss: 0.7013\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 3, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  84, Avg Accuracy 75.530 | Avg Loss 0.757\n",
      " Test: Round  84, Avg Accuracy 60.529 | Avg Loss 1.467\n",
      "==========================================================\n",
      "idxs_users [ 0  6 18 19  2  4 17  5  3  9 10 12 14 15 13 11  7 16  8  1]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 18, 2, 4, 17, 5, 3, 9, 10, 12, 14, 15, 13, 11, 7, 16, 8, 1]\n",
      "fedserver选择的客户端index: [1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "acc: 68.06303787231445\n",
      "acc: 61.72548484802246\n",
      "acc: 62.74245643615723\n",
      "acc: 71.13415908813477\n",
      "acc: 66.35910606384277\n",
      "acc: 71.15436363220215\n",
      "acc: 62.042025566101074\n",
      "acc: 65.75296306610107\n",
      "acc: 66.58809280395508\n",
      "acc: 62.627963066101074\n",
      "acc: 64.15005397796631\n",
      "acc: 65.10641193389893\n",
      "acc: 63.227370262145996\n",
      "acc: 67.78690719604492\n",
      "acc: 67.28178787231445\n",
      "acc: 65.59806060791016\n",
      "acc: 68.49407386779785\n",
      "acc: 74.49488067626953\n",
      "====================== Fed Server==========================\n",
      " Train: Round  84, Avg Accuracy 75.530 | Avg Loss 0.757\n",
      " Test: Round  84, Avg Accuracy 66.352 | Avg Loss 1.040\n",
      "==========================================================\n",
      "Epoch 84 finished in 00:02:00\n",
      "Epoch 84 finished. Total time: 10286.89 seconds\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 78.424 \tLoss: 0.6049\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 62.392 \tLoss: 1.2400\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 77.636 \tLoss: 0.6161\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 56.903 \tLoss: 1.4365\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 78.690 \tLoss: 0.6085\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 65.793 \tLoss: 1.1101\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 54.182 \tLoss: 1.9463\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 5.981 \tLoss: 5.1556\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 78.633 \tLoss: 0.6184\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 59.833 \tLoss: 1.3640\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 78.486 \tLoss: 0.6081\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 66.265 \tLoss: 1.0200\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 78.389 \tLoss: 0.6170\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 63.409 \tLoss: 1.0962\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 78.146 \tLoss: 0.6196\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 65.713 \tLoss: 1.0320\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 78.224 \tLoss: 0.6124\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 66.575 \tLoss: 1.0405\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 79.409 \tLoss: 0.6070\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 66.346 \tLoss: 1.1289\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 77.183 \tLoss: 0.6265\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 62.608 \tLoss: 1.2957\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 79.127 \tLoss: 0.6159\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 64.137 \tLoss: 1.1335\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 77.360 \tLoss: 0.6217\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 69.100 \tLoss: 0.9752\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 79.122 \tLoss: 0.5893\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 68.494 \tLoss: 0.9368\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 76.884 \tLoss: 0.6410\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 68.864 \tLoss: 0.9675\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 78.348 \tLoss: 0.6264\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 68.178 \tLoss: 1.0475\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 78.194 \tLoss: 0.6291\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 68.878 \tLoss: 0.9055\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 78.472 \tLoss: 0.6052\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 70.481 \tLoss: 0.8881\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 53.716 \tLoss: 2.0182\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 9.186 \tLoss: 3.9233\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 77.854 \tLoss: 0.6271\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client2 Test =>                   \tAcc: 73.788 \tLoss: 0.7658\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  85, Avg Accuracy 75.824 | Avg Loss 0.753\n",
      " Test: Round  85, Avg Accuracy 63.031 | Avg Loss 1.226\n",
      "==========================================================\n",
      "idxs_users [12 18 17  0 14 15 10  1 11  7  8 13  6  9  5 16  3  4 19  2]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 18, 17, 14, 15, 10, 1, 11, 7, 8, 13, 6, 9, 5, 16, 3, 4, 2]\n",
      "fedserver选择的客户端index: [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19]\n",
      "acc: 62.39224147796631\n",
      "acc: 56.903286933898926\n",
      "acc: 65.79337310791016\n",
      "acc: 59.832974433898926\n",
      "acc: 66.26481628417969\n",
      "acc: 63.409213066101074\n",
      "acc: 65.71255397796631\n",
      "acc: 66.57462310791016\n",
      "acc: 66.34563636779785\n",
      "acc: 62.60775852203369\n",
      "acc: 64.13658332824707\n",
      "acc: 69.10021591186523\n",
      "acc: 68.49407386779785\n",
      "acc: 68.86449432373047\n",
      "acc: 68.17753219604492\n",
      "acc: 68.87796306610107\n",
      "acc: 70.48087310791016\n",
      "acc: 73.78771591186523\n",
      "====================== Fed Server==========================\n",
      " Train: Round  85, Avg Accuracy 75.824 | Avg Loss 0.753\n",
      " Test: Round  85, Avg Accuracy 65.986 | Avg Loss 1.077\n",
      "==========================================================\n",
      "Epoch 85 finished in 00:02:00\n",
      "Epoch 85 finished. Total time: 10407.38 seconds\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 78.169 \tLoss: 0.6063\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 62.608 \tLoss: 1.1905\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 77.040 \tLoss: 0.6334\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 67.928 \tLoss: 1.0498\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 77.721 \tLoss: 0.6160\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 69.841 \tLoss: 0.9285\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 77.769 \tLoss: 0.6305\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 69.471 \tLoss: 0.9142\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 78.902 \tLoss: 0.5988\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 63.820 \tLoss: 1.2913\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 78.702 \tLoss: 0.6132\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 62.931 \tLoss: 1.2069\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 51.838 \tLoss: 1.9784\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 15.302 \tLoss: 5.0264\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 78.169 \tLoss: 0.6173\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 73.006 \tLoss: 0.7798\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 78.341 \tLoss: 0.6140\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 67.295 \tLoss: 1.0182\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 79.131 \tLoss: 0.5986\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 59.638 \tLoss: 1.2785\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 54.607 \tLoss: 1.9720\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 12.958 \tLoss: 4.9687\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 78.780 \tLoss: 0.6152\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 66.433 \tLoss: 1.0743\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 79.076 \tLoss: 0.6056\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 64.386 \tLoss: 1.1788\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 78.458 \tLoss: 0.6126\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 65.484 \tLoss: 1.1373\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 78.026 \tLoss: 0.6112\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 65.228 \tLoss: 1.1607\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 79.814 \tLoss: 0.5777\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 69.861 \tLoss: 0.8511\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 77.500 \tLoss: 0.6314\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 66.730 \tLoss: 1.0839\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 76.627 \tLoss: 0.6311\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 66.965 \tLoss: 0.9863\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 77.528 \tLoss: 0.6120\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 62.082 \tLoss: 1.1075\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 78.888 \tLoss: 0.6007\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client7 Test =>                   \tAcc: 75.101 \tLoss: 0.7721\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  86, Avg Accuracy 75.754 | Avg Loss 0.749\n",
      " Test: Round  86, Avg Accuracy 60.862 | Avg Loss 1.499\n",
      "==========================================================\n",
      "idxs_users [11 14 13  5  1  4 19 16  3 18  0 10 17 12 15  9  2  6  8  7]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 14, 13, 5, 1, 4, 19, 16, 3, 18, 17, 12, 15, 9, 2, 6, 8, 7]\n",
      "fedserver选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "acc: 62.60775852203369\n",
      "acc: 67.92834091186523\n",
      "acc: 69.84105682373047\n",
      "acc: 69.47063636779785\n",
      "acc: 63.82004356384277\n",
      "acc: 62.931034088134766\n",
      "acc: 15.301724195480347\n",
      "acc: 73.00646591186523\n",
      "acc: 67.29525852203369\n",
      "acc: 59.637661933898926\n",
      "acc: 64.38577556610107\n",
      "acc: 65.48356628417969\n",
      "acc: 65.22764015197754\n",
      "acc: 69.86126136779785\n",
      "acc: 66.72952556610107\n",
      "acc: 66.96524810791016\n",
      "acc: 62.082435607910156\n",
      "acc: 75.10102272033691\n",
      "====================== Fed Server==========================\n",
      " Train: Round  86, Avg Accuracy 75.754 | Avg Loss 0.749\n",
      " Test: Round  86, Avg Accuracy 63.760 | Avg Loss 1.276\n",
      "==========================================================\n",
      "Epoch 86 finished in 00:02:00\n",
      "Epoch 86 finished. Total time: 10527.86 seconds\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 78.279 \tLoss: 0.6156\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 60.473 \tLoss: 1.2690\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 78.775 \tLoss: 0.6055\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 62.082 \tLoss: 1.1871\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 78.433 \tLoss: 0.6195\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 66.440 \tLoss: 1.0651\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 79.308 \tLoss: 0.6016\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 68.588 \tLoss: 0.9732\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 79.131 \tLoss: 0.6045\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 66.070 \tLoss: 1.0818\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 77.969 \tLoss: 0.6115\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 60.143 \tLoss: 1.3842\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 78.720 \tLoss: 0.6048\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 61.867 \tLoss: 1.2525\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 79.131 \tLoss: 0.6045\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 65.362 \tLoss: 1.0941\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 53.704 \tLoss: 1.9421\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 12.783 \tLoss: 5.2747\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 79.106 \tLoss: 0.6045\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 70.898 \tLoss: 0.8087\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 78.146 \tLoss: 0.6088\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 69.073 \tLoss: 0.9150\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 78.633 \tLoss: 0.6028\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 65.733 \tLoss: 1.0792\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 78.837 \tLoss: 0.6040\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 64.581 \tLoss: 1.0778\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 78.826 \tLoss: 0.6007\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 69.767 \tLoss: 0.8916\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 79.570 \tLoss: 0.6012\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 67.672 \tLoss: 1.0412\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 77.734 \tLoss: 0.6160\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 66.224 \tLoss: 1.0295\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 79.067 \tLoss: 0.5991\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 62.958 \tLoss: 1.1430\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 54.115 \tLoss: 1.9655\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 9.658 \tLoss: 4.8390\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 80.379 \tLoss: 0.5548\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 63.679 \tLoss: 1.1187\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 78.775 \tLoss: 0.6027\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client1 Test =>                   \tAcc: 75.135 \tLoss: 0.7125\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  87, Avg Accuracy 76.332 | Avg Loss 0.738\n",
      " Test: Round  87, Avg Accuracy 59.688 | Avg Loss 1.514\n",
      "==========================================================\n",
      "idxs_users [10 17  5  4 16 11 18  3  0 15 14 13  2 12  8  6  7 19  9  1]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 17, 5, 4, 16, 11, 18, 3, 15, 14, 13, 2, 12, 8, 6, 7, 9, 1]\n",
      "fedserver选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19]\n",
      "acc: 60.47279071807861\n",
      "acc: 62.082435607910156\n",
      "acc: 66.4399242401123\n",
      "acc: 68.5883617401123\n",
      "acc: 66.06950378417969\n",
      "acc: 60.14278030395508\n",
      "acc: 61.86691856384277\n",
      "acc: 65.36233806610107\n",
      "acc: 70.8984375\n",
      "acc: 69.07327556610107\n",
      "acc: 65.73275852203369\n",
      "acc: 64.58108806610107\n",
      "acc: 69.76697158813477\n",
      "acc: 67.67241287231445\n",
      "acc: 66.22440719604492\n",
      "acc: 62.957974433898926\n",
      "acc: 63.67860984802246\n",
      "acc: 75.13469886779785\n",
      "====================== Fed Server==========================\n",
      " Train: Round  87, Avg Accuracy 76.332 | Avg Loss 0.738\n",
      " Test: Round  87, Avg Accuracy 65.930 | Avg Loss 1.062\n",
      "==========================================================\n",
      "Epoch 87 finished in 00:02:00\n",
      "Epoch 87 finished. Total time: 10648.31 seconds\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 77.932 \tLoss: 0.6047\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 66.070 \tLoss: 0.9956\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 78.883 \tLoss: 0.6010\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 66.831 \tLoss: 1.0914\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 78.617 \tLoss: 0.6243\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 69.114 \tLoss: 0.8930\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 78.853 \tLoss: 0.5977\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 66.400 \tLoss: 1.0569\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 79.800 \tLoss: 0.5779\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 59.537 \tLoss: 1.3293\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 77.999 \tLoss: 0.6002\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 66.770 \tLoss: 1.0993\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 79.538 \tLoss: 0.5812\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 67.693 \tLoss: 1.0103\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 77.925 \tLoss: 0.6193\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 70.346 \tLoss: 0.9688\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 79.067 \tLoss: 0.5824\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 68.433 \tLoss: 0.9433\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 79.586 \tLoss: 0.5713\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 61.968 \tLoss: 1.2120\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 52.796 \tLoss: 1.9854\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 12.628 \tLoss: 4.8630\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 77.992 \tLoss: 0.5902\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 69.545 \tLoss: 1.0224\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 79.743 \tLoss: 0.5544\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 64.655 \tLoss: 1.1901\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 79.375 \tLoss: 0.5918\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 67.686 \tLoss: 1.0452\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 78.957 \tLoss: 0.6051\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 66.831 \tLoss: 0.9488\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 78.286 \tLoss: 0.6137\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 66.049 \tLoss: 1.0014\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 77.431 \tLoss: 0.6296\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 68.555 \tLoss: 0.9371\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 53.219 \tLoss: 1.9853\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 12.157 \tLoss: 4.8306\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 78.961 \tLoss: 0.6031\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 67.039 \tLoss: 0.9945\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 78.732 \tLoss: 0.5928\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client17 Test =>                   \tAcc: 76.994 \tLoss: 0.6875\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  88, Avg Accuracy 76.185 | Avg Loss 0.736\n",
      " Test: Round  88, Avg Accuracy 64.150 | Avg Loss 1.241\n",
      "==========================================================\n",
      "idxs_users [ 8 12 15  4  1 14 13  5 10 18 19  6  9  7 16 11  3  0  2 17]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 12, 15, 4, 1, 14, 13, 5, 10, 18, 6, 9, 7, 16, 11, 3, 2, 17]\n",
      "fedserver选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 18, 19]\n",
      "acc: 66.06950378417969\n",
      "acc: 66.8305492401123\n",
      "acc: 69.11368560791016\n",
      "acc: 66.39951515197754\n",
      "acc: 59.536638259887695\n",
      "acc: 66.76993560791016\n",
      "acc: 67.69261932373047\n",
      "acc: 70.3461742401123\n",
      "acc: 68.43345832824707\n",
      "acc: 61.96794128417969\n",
      "acc: 69.54471969604492\n",
      "acc: 64.65517234802246\n",
      "acc: 67.68588352203369\n",
      "acc: 66.8305492401123\n",
      "acc: 66.0492992401123\n",
      "acc: 68.5546875\n",
      "acc: 67.03933143615723\n",
      "acc: 76.99353408813477\n",
      "====================== Fed Server==========================\n",
      " Train: Round  88, Avg Accuracy 76.185 | Avg Loss 0.736\n",
      " Test: Round  88, Avg Accuracy 67.251 | Avg Loss 1.024\n",
      "==========================================================\n",
      "Epoch 88 finished in 00:02:01\n",
      "Epoch 88 finished. Total time: 10769.44 seconds\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 80.002 \tLoss: 0.5790\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 70.090 \tLoss: 0.9815\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 79.492 \tLoss: 0.5766\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 65.093 \tLoss: 1.1671\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 77.838 \tLoss: 0.6135\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 71.363 \tLoss: 0.8594\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 79.180 \tLoss: 0.5828\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 63.416 \tLoss: 1.1091\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 78.819 \tLoss: 0.6139\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 62.136 \tLoss: 1.2314\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 79.161 \tLoss: 0.5940\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 65.423 \tLoss: 1.0181\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 52.656 \tLoss: 2.0444\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 11.746 \tLoss: 3.9847\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 79.913 \tLoss: 0.5911\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 68.534 \tLoss: 0.9041\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 52.957 \tLoss: 1.9638\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 7.934 \tLoss: 4.5042\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 79.076 \tLoss: 0.5735\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 66.750 \tLoss: 1.0456\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 78.796 \tLoss: 0.6168\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 66.426 \tLoss: 1.0085\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 80.133 \tLoss: 0.5789\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 68.514 \tLoss: 1.0164\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 79.122 \tLoss: 0.5929\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 70.696 \tLoss: 0.8971\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 78.915 \tLoss: 0.6118\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 66.339 \tLoss: 1.0749\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 78.529 \tLoss: 0.5986\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 68.178 \tLoss: 1.0111\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 79.704 \tLoss: 0.5845\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 71.053 \tLoss: 0.8430\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 79.210 \tLoss: 0.5920\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 66.009 \tLoss: 0.9824\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 78.633 \tLoss: 0.6058\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 71.154 \tLoss: 0.9304\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 78.761 \tLoss: 0.5827\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 65.032 \tLoss: 1.1811\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 78.796 \tLoss: 0.5856\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client2 Test =>                   \tAcc: 74.845 \tLoss: 0.7355\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  89, Avg Accuracy 76.485 | Avg Loss 0.734\n",
      " Test: Round  89, Avg Accuracy 61.286 | Avg Loss 1.364\n",
      "==========================================================\n",
      "idxs_users [18 17  3 11 14 16 19 10  0  9  5  1 12  4 13  6 15  7  8  2]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18, 17, 3, 11, 14, 16, 10, 9, 5, 1, 12, 4, 13, 6, 15, 7, 8, 2]\n",
      "fedserver选择的客户端index: [0, 1, 2, 3, 4, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "acc: 70.09024810791016\n",
      "acc: 65.09294128417969\n",
      "acc: 71.36314582824707\n",
      "acc: 63.41594886779785\n",
      "acc: 62.136314392089844\n",
      "acc: 65.42295265197754\n",
      "acc: 68.53448295593262\n",
      "acc: 66.74973106384277\n",
      "acc: 66.42645454406738\n",
      "acc: 68.51427841186523\n",
      "acc: 70.69639015197754\n",
      "acc: 66.33890056610107\n",
      "acc: 68.17753219604492\n",
      "acc: 71.05334091186523\n",
      "acc: 66.00889015197754\n",
      "acc: 71.15436363220215\n",
      "acc: 65.03232765197754\n",
      "acc: 74.84509658813477\n",
      "====================== Fed Server==========================\n",
      " Train: Round  89, Avg Accuracy 76.485 | Avg Loss 0.734\n",
      " Test: Round  89, Avg Accuracy 67.836 | Avg Loss 1.000\n",
      "==========================================================\n",
      "Epoch 89 finished in 00:02:00\n",
      "Epoch 89 finished. Total time: 10889.72 seconds\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 78.520 \tLoss: 0.5786\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 68.959 \tLoss: 0.9216\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 79.079 \tLoss: 0.5791\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 61.389 \tLoss: 1.3235\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 79.665 \tLoss: 0.5836\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 68.184 \tLoss: 0.9815\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 78.375 \tLoss: 0.6051\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 69.821 \tLoss: 0.8945\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 80.005 \tLoss: 0.5971\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 67.645 \tLoss: 0.9715\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 52.636 \tLoss: 2.0252\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 13.820 \tLoss: 4.9975\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 79.478 \tLoss: 0.5738\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 69.060 \tLoss: 0.9864\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 78.911 \tLoss: 0.5915\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 66.453 \tLoss: 1.0087\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 78.585 \tLoss: 0.6005\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 63.941 \tLoss: 1.1289\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 80.358 \tLoss: 0.5740\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 69.545 \tLoss: 0.9330\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 79.488 \tLoss: 0.5947\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 69.821 \tLoss: 1.1500\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 78.575 \tLoss: 0.5940\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 65.423 \tLoss: 1.1706\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 77.755 \tLoss: 0.6218\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 69.235 \tLoss: 0.9068\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 78.488 \tLoss: 0.6017\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 69.154 \tLoss: 0.9686\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 78.022 \tLoss: 0.6243\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 66.730 \tLoss: 1.0369\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 77.642 \tLoss: 0.6072\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 66.110 \tLoss: 1.0645\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 53.766 \tLoss: 1.9568\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 10.533 \tLoss: 6.8145\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 80.358 \tLoss: 0.5822\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 62.998 \tLoss: 1.1758\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 80.556 \tLoss: 0.5464\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 71.781 \tLoss: 0.9116\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 79.830 \tLoss: 0.5823\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client15 Test =>                   \tAcc: 74.960 \tLoss: 0.6704\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 3, 4, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  90, Avg Accuracy 76.505 | Avg Loss 0.731\n",
      " Test: Round  90, Avg Accuracy 61.809 | Avg Loss 1.550\n",
      "==========================================================\n",
      "idxs_users [13 17  8  3  4 19  1 14 11 10 12  7  5  6 16  2  0 18  9 15]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13, 17, 8, 3, 4, 1, 14, 11, 10, 12, 7, 5, 6, 16, 2, 18, 9, 15]\n",
      "fedserver选择的客户端index: [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19]\n",
      "acc: 68.95878219604492\n",
      "acc: 61.388739585876465\n",
      "acc: 68.18426704406738\n",
      "acc: 69.82085037231445\n",
      "acc: 67.64547443389893\n",
      "acc: 69.05980682373047\n",
      "acc: 66.45339393615723\n",
      "acc: 63.94127082824707\n",
      "acc: 69.54471969604492\n",
      "acc: 69.82085037231445\n",
      "acc: 65.42295265197754\n",
      "acc: 69.23491287231445\n",
      "acc: 69.15409469604492\n",
      "acc: 66.72952556610107\n",
      "acc: 66.10991287231445\n",
      "acc: 62.99838352203369\n",
      "acc: 71.78071022033691\n",
      "acc: 74.95959091186523\n",
      "====================== Fed Server==========================\n",
      " Train: Round  90, Avg Accuracy 76.505 | Avg Loss 0.731\n",
      " Test: Round  90, Avg Accuracy 67.845 | Avg Loss 1.011\n",
      "==========================================================\n",
      "Epoch 90 finished in 00:01:59\n",
      "Epoch 90 finished. Total time: 11009.63 seconds\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 80.264 \tLoss: 0.5765\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 63.766 \tLoss: 1.1358\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 78.545 \tLoss: 0.5967\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 62.278 \tLoss: 1.4816\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 52.776 \tLoss: 2.0375\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 13.625 \tLoss: 5.3166\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 79.977 \tLoss: 0.5751\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 65.187 \tLoss: 1.1501\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 79.012 \tLoss: 0.5925\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 64.238 \tLoss: 1.0204\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 79.835 \tLoss: 0.5690\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 66.049 \tLoss: 1.0533\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 78.686 \tLoss: 0.5840\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 70.871 \tLoss: 0.8277\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 79.141 \tLoss: 0.5925\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 69.780 \tLoss: 0.9762\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 50.921 \tLoss: 2.1158\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 7.893 \tLoss: 4.6433\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 79.214 \tLoss: 0.5764\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 65.692 \tLoss: 1.0571\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 79.010 \tLoss: 0.5798\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 60.749 \tLoss: 1.1020\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 79.258 \tLoss: 0.5902\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 68.918 \tLoss: 1.0829\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 78.729 \tLoss: 0.6008\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 71.659 \tLoss: 0.8128\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 79.184 \tLoss: 0.5837\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 73.357 \tLoss: 0.8175\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 79.083 \tLoss: 0.5967\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 65.012 \tLoss: 1.0306\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 81.305 \tLoss: 0.5404\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 70.036 \tLoss: 0.9832\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 78.984 \tLoss: 0.5853\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 60.850 \tLoss: 1.2888\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 78.550 \tLoss: 0.5865\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 71.249 \tLoss: 0.8728\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 79.635 \tLoss: 0.5715\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 66.164 \tLoss: 0.9267\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 80.202 \tLoss: 0.5720\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client17 Test =>                   \tAcc: 76.738 \tLoss: 0.6802\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  91, Avg Accuracy 76.616 | Avg Loss 0.731\n",
      " Test: Round  91, Avg Accuracy 61.512 | Avg Loss 1.440\n",
      "==========================================================\n",
      "idxs_users [13 11  0 18  3  7 10  5 19  1  2  4 16  8 14  9 12  6 15 17]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13, 11, 18, 3, 7, 10, 5, 19, 1, 4, 16, 8, 14, 9, 12, 6, 15, 17]\n",
      "fedserver选择的客户端index: [0, 1, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "acc: 63.76616287231445\n",
      "acc: 62.277748107910156\n",
      "acc: 65.18723106384277\n",
      "acc: 64.23760795593262\n",
      "acc: 66.0492992401123\n",
      "acc: 70.87149810791016\n",
      "acc: 69.78044128417969\n",
      "acc: 7.893318951129913\n",
      "acc: 65.69234943389893\n",
      "acc: 68.91837310791016\n",
      "acc: 71.65948295593262\n",
      "acc: 73.35668182373047\n",
      "acc: 65.01212310791016\n",
      "acc: 70.03636932373047\n",
      "acc: 60.84994602203369\n",
      "acc: 71.24865341186523\n",
      "acc: 66.16379356384277\n",
      "acc: 76.73760795593262\n",
      "====================== Fed Server==========================\n",
      " Train: Round  91, Avg Accuracy 76.616 | Avg Loss 0.731\n",
      " Test: Round  91, Avg Accuracy 64.430 | Avg Loss 1.213\n",
      "==========================================================\n",
      "Epoch 91 finished in 00:02:00\n",
      "Epoch 91 finished. Total time: 11129.70 seconds\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 80.377 \tLoss: 0.5747\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 64.642 \tLoss: 1.0635\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 80.308 \tLoss: 0.5522\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 63.315 \tLoss: 1.1235\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 79.752 \tLoss: 0.5788\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 67.666 \tLoss: 1.0046\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 55.595 \tLoss: 1.9719\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 18.864 \tLoss: 4.4796\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 80.871 \tLoss: 0.5673\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 69.120 \tLoss: 0.9912\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 79.444 \tLoss: 0.5960\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 64.325 \tLoss: 1.0184\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 79.308 \tLoss: 0.5825\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 63.328 \tLoss: 1.1359\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 79.067 \tLoss: 0.5781\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 63.665 \tLoss: 1.1794\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 79.152 \tLoss: 0.5854\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 70.211 \tLoss: 0.9147\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 80.333 \tLoss: 0.5555\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 61.355 \tLoss: 1.3899\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 79.040 \tLoss: 0.5896\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 69.666 \tLoss: 0.9240\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 79.288 \tLoss: 0.5793\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 68.454 \tLoss: 0.9911\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 53.334 \tLoss: 2.0084\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 5.981 \tLoss: 5.4409\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 78.676 \tLoss: 0.6068\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 64.850 \tLoss: 1.2015\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 80.358 \tLoss: 0.5715\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 72.676 \tLoss: 0.8423\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 79.148 \tLoss: 0.5806\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 64.857 \tLoss: 1.0881\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 78.541 \tLoss: 0.5944\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 67.376 \tLoss: 0.9018\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 79.575 \tLoss: 0.5900\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 67.652 \tLoss: 0.9738\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 79.924 \tLoss: 0.5798\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 62.062 \tLoss: 1.1729\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 78.975 \tLoss: 0.6052\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client5 Test =>                   \tAcc: 76.872 \tLoss: 0.6974\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  92, Avg Accuracy 77.053 | Avg Loss 0.722\n",
      " Test: Round  92, Avg Accuracy 60.534 | Avg Loss 1.478\n",
      "==========================================================\n",
      "idxs_users [11  9 10  0  7  6  8 18 16 17 12 13 19  2  4 14  3 15  1  5]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 9, 10, 7, 6, 8, 18, 16, 17, 12, 13, 2, 4, 14, 3, 15, 1, 5]\n",
      "fedserver选择的客户端index: [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19]\n",
      "acc: 64.64170265197754\n",
      "acc: 63.314924240112305\n",
      "acc: 67.66567897796631\n",
      "acc: 69.12042045593262\n",
      "acc: 64.32516193389893\n",
      "acc: 63.32839393615723\n",
      "acc: 63.66514015197754\n",
      "acc: 70.21147537231445\n",
      "acc: 61.355064392089844\n",
      "acc: 69.66594886779785\n",
      "acc: 68.45366287231445\n",
      "acc: 64.85048484802246\n",
      "acc: 72.67645454406738\n",
      "acc: 64.85721969604492\n",
      "acc: 67.37607765197754\n",
      "acc: 67.65220832824707\n",
      "acc: 62.06223106384277\n",
      "acc: 76.87230682373047\n",
      "====================== Fed Server==========================\n",
      " Train: Round  92, Avg Accuracy 77.053 | Avg Loss 0.722\n",
      " Test: Round  92, Avg Accuracy 66.783 | Avg Loss 1.034\n",
      "==========================================================\n",
      "Epoch 92 finished in 00:02:00\n",
      "Epoch 92 finished. Total time: 11249.81 seconds\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 80.519 \tLoss: 0.5738\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 65.928 \tLoss: 1.0212\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 80.563 \tLoss: 0.5672\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 70.461 \tLoss: 0.9229\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 81.006 \tLoss: 0.5606\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 68.332 \tLoss: 1.0299\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 80.074 \tLoss: 0.5701\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 70.211 \tLoss: 0.9268\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 80.538 \tLoss: 0.5596\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 65.719 \tLoss: 1.0978\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 79.805 \tLoss: 0.5836\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 70.070 \tLoss: 0.9446\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 79.527 \tLoss: 0.5818\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 65.362 \tLoss: 1.0937\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 79.292 \tLoss: 0.5678\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 68.939 \tLoss: 0.9435\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 78.378 \tLoss: 0.5943\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 72.400 \tLoss: 0.8187\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 79.766 \tLoss: 0.5715\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 68.784 \tLoss: 1.0363\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 78.828 \tLoss: 0.5795\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 70.528 \tLoss: 0.9184\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 77.939 \tLoss: 0.6129\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 67.396 \tLoss: 1.0127\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 78.961 \tLoss: 0.5902\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 66.911 \tLoss: 1.0058\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 79.331 \tLoss: 0.5834\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 66.851 \tLoss: 1.0509\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 53.222 \tLoss: 2.0198\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 10.224 \tLoss: 4.9648\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 51.337 \tLoss: 2.0855\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 9.833 \tLoss: 4.4442\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 80.547 \tLoss: 0.5536\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 71.444 \tLoss: 0.8494\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 79.807 \tLoss: 0.5612\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 70.030 \tLoss: 0.9522\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 80.172 \tLoss: 0.5567\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 67.908 \tLoss: 1.0007\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 78.879 \tLoss: 0.5892\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client14 Test =>                   \tAcc: 75.842 \tLoss: 0.6869\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  93, Avg Accuracy 76.925 | Avg Loss 0.723\n",
      " Test: Round  93, Avg Accuracy 62.558 | Avg Loss 1.377\n",
      "==========================================================\n",
      "idxs_users [ 3 15 17  8 11 13  2 10 16  4  6  5  7 18  0 19  9 12  1 14]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 15, 17, 8, 11, 13, 2, 10, 16, 4, 6, 5, 7, 18, 9, 12, 1, 14]\n",
      "fedserver选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19]\n",
      "acc: 65.92807102203369\n",
      "acc: 70.46066856384277\n",
      "acc: 68.33243560791016\n",
      "acc: 70.21147537231445\n",
      "acc: 65.71928787231445\n",
      "acc: 70.07004356384277\n",
      "acc: 65.36233806610107\n",
      "acc: 68.93857765197754\n",
      "acc: 72.40032386779785\n",
      "acc: 68.7836742401123\n",
      "acc: 70.52801704406738\n",
      "acc: 67.39628219604492\n",
      "acc: 66.91136932373047\n",
      "acc: 66.85075378417969\n",
      "acc: 71.44396591186523\n",
      "acc: 70.02963352203369\n",
      "acc: 67.90813636779785\n",
      "acc: 75.84186363220215\n",
      "====================== Fed Server==========================\n",
      " Train: Round  93, Avg Accuracy 76.925 | Avg Loss 0.723\n",
      " Test: Round  93, Avg Accuracy 69.062 | Avg Loss 0.962\n",
      "==========================================================\n",
      "Epoch 93 finished in 00:02:00\n",
      "Epoch 93 finished. Total time: 11370.08 seconds\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 78.833 \tLoss: 0.5962\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 65.618 \tLoss: 0.9787\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 79.474 \tLoss: 0.5767\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 71.565 \tLoss: 0.9794\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 79.674 \tLoss: 0.5731\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 63.901 \tLoss: 1.3044\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 78.736 \tLoss: 0.5847\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 67.006 \tLoss: 1.0886\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 79.072 \tLoss: 0.5801\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 63.874 \tLoss: 1.0977\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 52.957 \tLoss: 2.0027\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 10.554 \tLoss: 4.4342\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 80.464 \tLoss: 0.5395\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 68.454 \tLoss: 1.0467\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 80.103 \tLoss: 0.5684\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 68.238 \tLoss: 0.9899\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 79.435 \tLoss: 0.5656\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 62.918 \tLoss: 1.2207\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 80.655 \tLoss: 0.5519\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 65.908 \tLoss: 1.1101\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 79.258 \tLoss: 0.5722\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 71.343 \tLoss: 0.9249\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 79.991 \tLoss: 0.5685\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 65.362 \tLoss: 1.0685\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 55.069 \tLoss: 2.0010\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 9.146 \tLoss: 4.6046\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 79.547 \tLoss: 0.5727\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 62.352 \tLoss: 1.2852\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 78.369 \tLoss: 0.6028\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 67.457 \tLoss: 0.9871\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 80.069 \tLoss: 0.5765\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 69.100 \tLoss: 0.9110\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 78.663 \tLoss: 0.6022\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 64.110 \tLoss: 1.1942\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 79.830 \tLoss: 0.5615\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 65.807 \tLoss: 1.1048\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 79.205 \tLoss: 0.5741\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 65.342 \tLoss: 1.0597\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 79.389 \tLoss: 0.5700\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client14 Test =>                   \tAcc: 75.822 \tLoss: 0.7084\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  94, Avg Accuracy 76.940 | Avg Loss 0.717\n",
      " Test: Round  94, Avg Accuracy 60.407 | Avg Loss 1.456\n",
      "==========================================================\n",
      "idxs_users [15  1  8 11 10 19  9 12  3 17  4 13  0  6  5  7 16 18  2 14]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15, 1, 8, 11, 10, 9, 12, 3, 17, 4, 13, 6, 5, 7, 16, 18, 2, 14]\n",
      "fedserver选择的客户端index: [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19]\n",
      "acc: 65.61826515197754\n",
      "acc: 71.56519317626953\n",
      "acc: 63.900861740112305\n",
      "acc: 67.00565719604492\n",
      "acc: 63.87392234802246\n",
      "acc: 68.45366287231445\n",
      "acc: 68.23814582824707\n",
      "acc: 62.917564392089844\n",
      "acc: 65.90786647796631\n",
      "acc: 71.34294128417969\n",
      "acc: 65.36233806610107\n",
      "acc: 62.35183143615723\n",
      "acc: 67.45689582824707\n",
      "acc: 69.10021591186523\n",
      "acc: 64.10964393615723\n",
      "acc: 65.80684280395508\n",
      "acc: 65.34213352203369\n",
      "acc: 75.82165908813477\n",
      "====================== Fed Server==========================\n",
      " Train: Round  94, Avg Accuracy 76.940 | Avg Loss 0.717\n",
      " Test: Round  94, Avg Accuracy 66.899 | Avg Loss 1.059\n",
      "==========================================================\n",
      "Epoch 94 finished in 00:02:00\n",
      "Epoch 94 finished. Total time: 11490.44 seconds\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 80.485 \tLoss: 0.5511\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 65.773 \tLoss: 1.0001\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 79.959 \tLoss: 0.5813\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 67.861 \tLoss: 1.0019\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 78.081 \tLoss: 0.5837\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 66.070 \tLoss: 1.0064\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 79.979 \tLoss: 0.5724\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 64.911 \tLoss: 1.0211\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 79.795 \tLoss: 0.5698\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 69.215 \tLoss: 0.9342\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 54.237 \tLoss: 2.0314\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 9.772 \tLoss: 4.7520\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 80.294 \tLoss: 0.5705\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 59.442 \tLoss: 1.4823\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 79.619 \tLoss: 0.5597\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 69.626 \tLoss: 0.9264\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 79.616 \tLoss: 0.5664\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 69.093 \tLoss: 1.0118\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 79.097 \tLoss: 0.5804\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 63.470 \tLoss: 1.1156\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 80.437 \tLoss: 0.5781\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 66.070 \tLoss: 1.1921\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 80.230 \tLoss: 0.5793\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 67.922 \tLoss: 0.9770\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 52.528 \tLoss: 2.0774\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 8.877 \tLoss: 5.1253\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 80.000 \tLoss: 0.5593\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 69.195 \tLoss: 0.9696\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 79.352 \tLoss: 0.5615\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 68.204 \tLoss: 1.0230\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 79.419 \tLoss: 0.5647\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 69.040 \tLoss: 0.9615\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 80.221 \tLoss: 0.5709\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 63.207 \tLoss: 1.1803\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 79.892 \tLoss: 0.5748\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 69.040 \tLoss: 0.9840\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 80.117 \tLoss: 0.5701\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 69.504 \tLoss: 0.9715\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 81.700 \tLoss: 0.5345\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client9 Test =>                   \tAcc: 76.623 \tLoss: 0.6939\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  95, Avg Accuracy 77.253 | Avg Loss 0.717\n",
      " Test: Round  95, Avg Accuracy 67.459 | Avg Loss 1.025\n",
      "==========================================================\n",
      "idxs_users [10  5  6 15  4  0  7 11  8 14  2 12 19 17 13  3 16 18  1  9]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 5, 6, 15, 4, 7, 11, 8, 14, 2, 12, 17, 13, 3, 16, 18, 1, 9]\n",
      "fedserver选择的客户端index: [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19]\n",
      "acc: 65.77316856384277\n",
      "acc: 67.86099147796631\n",
      "acc: 66.06950378417969\n",
      "acc: 64.91109943389893\n",
      "acc: 69.21470832824707\n",
      "acc: 59.442349433898926\n",
      "acc: 69.62553787231445\n",
      "acc: 69.09348106384277\n",
      "acc: 63.46982765197754\n",
      "acc: 66.06950378417969\n",
      "acc: 67.92160606384277\n",
      "acc: 69.19450378417969\n",
      "acc: 68.20447158813477\n",
      "acc: 69.03960037231445\n",
      "acc: 63.20716571807861\n",
      "acc: 69.03960037231445\n",
      "acc: 69.50431060791016\n",
      "acc: 76.62311363220215\n",
      "====================== Fed Server==========================\n",
      " Train: Round  95, Avg Accuracy 77.253 | Avg Loss 0.717\n",
      " Test: Round  95, Avg Accuracy 67.459 | Avg Loss 1.025\n",
      "==========================================================\n",
      "Epoch 95 finished in 00:02:00\n",
      "Epoch 95 finished. Total time: 11610.70 seconds\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 80.519 \tLoss: 0.5455\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 65.948 \tLoss: 0.9883\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 79.839 \tLoss: 0.5705\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 65.127 \tLoss: 0.9578\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 79.667 \tLoss: 0.5777\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 67.841 \tLoss: 1.0394\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 80.728 \tLoss: 0.5510\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 73.848 \tLoss: 0.8183\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 80.312 \tLoss: 0.5554\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 66.595 \tLoss: 1.1274\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 54.970 \tLoss: 1.9756\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 12.412 \tLoss: 4.3121\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 80.299 \tLoss: 0.5503\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 68.508 \tLoss: 0.9661\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 79.570 \tLoss: 0.5723\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 66.716 \tLoss: 1.1470\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 80.696 \tLoss: 0.5659\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 70.447 \tLoss: 0.9104\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 53.571 \tLoss: 2.0352\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 12.237 \tLoss: 6.7862\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 79.469 \tLoss: 0.5758\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 63.894 \tLoss: 1.1616\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 78.886 \tLoss: 0.5908\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 66.985 \tLoss: 1.0540\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 80.441 \tLoss: 0.5661\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 69.740 \tLoss: 0.8285\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 80.090 \tLoss: 0.5706\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 69.174 \tLoss: 0.9106\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 80.763 \tLoss: 0.5503\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 61.732 \tLoss: 1.2537\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 80.425 \tLoss: 0.5554\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 64.271 \tLoss: 1.1649\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 80.021 \tLoss: 0.5849\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 66.278 \tLoss: 1.0821\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 81.344 \tLoss: 0.5306\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 67.026 \tLoss: 1.0893\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 81.448 \tLoss: 0.5416\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 68.824 \tLoss: 0.9936\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 79.809 \tLoss: 0.5540\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client17 Test =>                   \tAcc: 78.442 \tLoss: 0.6524\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  96, Avg Accuracy 77.643 | Avg Loss 0.706\n",
      " Test: Round  96, Avg Accuracy 64.661 | Avg Loss 1.339\n",
      "==========================================================\n",
      "idxs_users [13 15  5  4 12  0 10  6 16 19  2 11  8 14  7 18  3  9  1 17]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13, 15, 5, 4, 12, 10, 6, 16, 2, 11, 8, 14, 7, 18, 3, 9, 1, 17]\n",
      "fedserver选择的客户端index: [0, 1, 2, 3, 4, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "acc: 65.94827556610107\n",
      "acc: 65.12661647796631\n",
      "acc: 67.84078693389893\n",
      "acc: 73.84832954406738\n",
      "acc: 66.59482765197754\n",
      "acc: 68.50754356384277\n",
      "acc: 66.71605682373047\n",
      "acc: 70.44719886779785\n",
      "acc: 63.894126892089844\n",
      "acc: 66.98545265197754\n",
      "acc: 69.74003219604492\n",
      "acc: 69.1742992401123\n",
      "acc: 61.73221969604492\n",
      "acc: 64.27128219604492\n",
      "acc: 66.27828693389893\n",
      "acc: 67.0258617401123\n",
      "acc: 68.82408332824707\n",
      "acc: 78.44154167175293\n",
      "====================== Fed Server==========================\n",
      " Train: Round  96, Avg Accuracy 77.643 | Avg Loss 0.706\n",
      " Test: Round  96, Avg Accuracy 67.855 | Avg Loss 1.008\n",
      "==========================================================\n",
      "Epoch 96 finished in 00:01:59\n",
      "Epoch 96 finished. Total time: 11730.64 seconds\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 80.611 \tLoss: 0.5533\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 63.759 \tLoss: 1.2059\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 54.115 \tLoss: 2.0223\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 13.665 \tLoss: 3.9636\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 79.839 \tLoss: 0.5510\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 70.117 \tLoss: 0.9054\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 80.260 \tLoss: 0.5540\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 66.359 \tLoss: 1.1059\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 80.402 \tLoss: 0.5573\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 62.877 \tLoss: 1.1276\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 79.991 \tLoss: 0.5603\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 67.753 \tLoss: 1.0609\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 81.372 \tLoss: 0.5498\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 64.446 \tLoss: 1.2499\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 80.676 \tLoss: 0.5455\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 64.036 \tLoss: 1.1059\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 52.624 \tLoss: 2.0889\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 7.152 \tLoss: 4.5284\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 79.131 \tLoss: 0.5581\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 68.528 \tLoss: 0.9696\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 81.140 \tLoss: 0.5307\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 67.531 \tLoss: 1.0393\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 80.512 \tLoss: 0.5524\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 70.501 \tLoss: 0.8848\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 79.632 \tLoss: 0.5790\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 67.080 \tLoss: 0.9626\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 81.183 \tLoss: 0.5256\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 69.215 \tLoss: 0.9177\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 80.315 \tLoss: 0.5471\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 65.383 \tLoss: 1.2010\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 79.830 \tLoss: 0.5642\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 70.232 \tLoss: 0.9702\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 80.246 \tLoss: 0.5740\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 64.089 \tLoss: 1.1706\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 80.542 \tLoss: 0.5412\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 70.582 \tLoss: 0.9439\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 80.607 \tLoss: 0.5550\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 61.005 \tLoss: 1.2101\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 81.153 \tLoss: 0.5433\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client7 Test =>                   \tAcc: 75.317 \tLoss: 0.7238\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 3, 4, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  97, Avg Accuracy 77.709 | Avg Loss 0.703\n",
      " Test: Round  97, Avg Accuracy 60.741 | Avg Loss 1.401\n",
      "==========================================================\n",
      "idxs_users [17  0 10  8 15 14 18  1 19  6 11 16  4  9 13  2  5 12  3  7]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17, 10, 8, 15, 14, 18, 1, 6, 11, 16, 4, 9, 13, 2, 5, 12, 3, 7]\n",
      "fedserver选择的客户端index: [0, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "acc: 63.75942897796631\n",
      "acc: 70.1171875\n",
      "acc: 66.35910606384277\n",
      "acc: 62.87715530395508\n",
      "acc: 67.75323295593262\n",
      "acc: 64.44639015197754\n",
      "acc: 64.03556060791016\n",
      "acc: 68.52774810791016\n",
      "acc: 67.53098106384277\n",
      "acc: 70.50107765197754\n",
      "acc: 67.07974147796631\n",
      "acc: 69.21470832824707\n",
      "acc: 65.38254356384277\n",
      "acc: 70.23168182373047\n",
      "acc: 64.08943939208984\n",
      "acc: 70.58189582824707\n",
      "acc: 61.004849433898926\n",
      "acc: 75.31654167175293\n",
      "====================== Fed Server==========================\n",
      " Train: Round  97, Avg Accuracy 77.709 | Avg Loss 0.703\n",
      " Test: Round  97, Avg Accuracy 67.156 | Avg Loss 1.042\n",
      "==========================================================\n",
      "Epoch 97 finished in 00:02:00\n",
      "Epoch 97 finished. Total time: 11850.92 seconds\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 80.097 \tLoss: 0.5745\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 71.424 \tLoss: 0.8711\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 79.844 \tLoss: 0.5614\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 66.379 \tLoss: 1.0119\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 80.342 \tLoss: 0.5477\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 72.299 \tLoss: 0.8882\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 80.030 \tLoss: 0.5748\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 59.011 \tLoss: 1.4015\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 80.554 \tLoss: 0.5349\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 71.127 \tLoss: 0.8777\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 80.317 \tLoss: 0.5372\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 66.379 \tLoss: 1.0799\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 79.297 \tLoss: 0.5742\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 64.918 \tLoss: 1.0637\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 79.557 \tLoss: 0.5695\u001b[00m\n",
      "\u001b[92m Client16 Test =>                   \tAcc: 71.323 \tLoss: 0.8614\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 80.680 \tLoss: 0.5499\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 68.743 \tLoss: 0.9741\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 52.240 \tLoss: 2.1110\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 12.864 \tLoss: 4.7782\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 53.010 \tLoss: 2.0709\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 10.143 \tLoss: 6.5365\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 79.602 \tLoss: 0.5673\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 69.329 \tLoss: 0.9477\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 80.411 \tLoss: 0.5488\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 65.719 \tLoss: 1.1776\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 80.133 \tLoss: 0.5521\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 69.215 \tLoss: 1.0147\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 80.816 \tLoss: 0.5288\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 64.325 \tLoss: 1.1447\u001b[00m\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 79.570 \tLoss: 0.5609\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 69.100 \tLoss: 1.0715\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 81.489 \tLoss: 0.5138\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 66.285 \tLoss: 1.1213\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 80.437 \tLoss: 0.5536\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 64.265 \tLoss: 1.0734\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 80.958 \tLoss: 0.5476\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 65.288 \tLoss: 1.1092\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 79.908 \tLoss: 0.5478\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client6 Test =>                   \tAcc: 76.839 \tLoss: 0.6531\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  98, Avg Accuracy 77.465 | Avg Loss 0.706\n",
      " Test: Round  98, Avg Accuracy 61.659 | Avg Loss 1.537\n",
      "==========================================================\n",
      "idxs_users [ 3 15 11 12 17 10 14 16  1 19  0 13  7  5  4  8  9  2 18  6]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 15, 11, 12, 17, 10, 14, 16, 1, 13, 7, 5, 4, 8, 9, 2, 18, 6]\n",
      "fedserver选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "acc: 71.42376136779785\n",
      "acc: 66.37931060791016\n",
      "acc: 72.2992992401123\n",
      "acc: 59.011314392089844\n",
      "acc: 71.1274242401123\n",
      "acc: 66.37931060791016\n",
      "acc: 64.91783332824707\n",
      "acc: 71.3227367401123\n",
      "acc: 68.74326515197754\n",
      "acc: 69.32920265197754\n",
      "acc: 65.71928787231445\n",
      "acc: 69.21470832824707\n",
      "acc: 64.32516193389893\n",
      "acc: 69.10021591186523\n",
      "acc: 66.28502082824707\n",
      "acc: 64.26454734802246\n",
      "acc: 65.28825378417969\n",
      "acc: 76.83863067626953\n",
      "====================== Fed Server==========================\n",
      " Train: Round  98, Avg Accuracy 77.465 | Avg Loss 0.706\n",
      " Test: Round  98, Avg Accuracy 67.887 | Avg Loss 1.019\n",
      "==========================================================\n",
      "Epoch 98 finished in 00:02:00\n",
      "Epoch 98 finished. Total time: 11970.96 seconds\n",
      "\u001b[91m Client8 Train => Local Epoch: 0 \tAcc: 80.935 \tLoss: 0.5533\u001b[00m\n",
      "\u001b[92m Client8 Test =>                   \tAcc: 66.689 \tLoss: 1.1501\u001b[00m\n",
      "\u001b[91m Client7 Train => Local Epoch: 0 \tAcc: 80.161 \tLoss: 0.5548\u001b[00m\n",
      "\u001b[92m Client7 Test =>                   \tAcc: 63.099 \tLoss: 1.2283\u001b[00m\n",
      "\u001b[91m Client17 Train => Local Epoch: 0 \tAcc: 81.023 \tLoss: 0.5485\u001b[00m\n",
      "\u001b[92m Client17 Test =>                   \tAcc: 59.341 \tLoss: 1.3717\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 54.784 \tLoss: 2.0022\u001b[00m\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 7.543 \tLoss: 5.9891\u001b[00m\n",
      "\u001b[91m Client9 Train => Local Epoch: 0 \tAcc: 81.457 \tLoss: 0.5160\u001b[00m\n",
      "\u001b[92m Client9 Test =>                   \tAcc: 68.609 \tLoss: 0.9426\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 80.473 \tLoss: 0.5576\u001b[00m\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 64.332 \tLoss: 1.2298\u001b[00m\n",
      "\u001b[91m Client12 Train => Local Epoch: 0 \tAcc: 81.939 \tLoss: 0.5290\u001b[00m\n",
      "\u001b[92m Client12 Test =>                   \tAcc: 71.127 \tLoss: 0.9238\u001b[00m\n",
      "\u001b[91m Client13 Train => Local Epoch: 0 \tAcc: 80.126 \tLoss: 0.5491\u001b[00m\n",
      "\u001b[92m Client13 Test =>                   \tAcc: 62.291 \tLoss: 1.2631\u001b[00m\n",
      "\u001b[91m Client6 Train => Local Epoch: 0 \tAcc: 80.269 \tLoss: 0.5421\u001b[00m\n",
      "\u001b[92m Client6 Test =>                   \tAcc: 66.817 \tLoss: 1.0946\u001b[00m\n",
      "\u001b[91m Client19 Train => Local Epoch: 0 \tAcc: 51.886 \tLoss: 2.0556\u001b[00m\n",
      "\u001b[92m Client19 Test =>                   \tAcc: 13.504 \tLoss: 5.7905\u001b[00m\n",
      "\u001b[91m Client18 Train => Local Epoch: 0 \tAcc: 80.147 \tLoss: 0.5380\u001b[00m\n",
      "\u001b[92m Client18 Test =>                   \tAcc: 64.635 \tLoss: 1.2033\u001b[00m\n",
      "\u001b[91m Client11 Train => Local Epoch: 0 \tAcc: 80.460 \tLoss: 0.5583\u001b[00m\n",
      "\u001b[92m Client11 Test =>                   \tAcc: 70.185 \tLoss: 0.9542\u001b[00m\n",
      "\u001b[91m Client10 Train => Local Epoch: 0 \tAcc: 80.053 \tLoss: 0.5516\u001b[00m\n",
      "\u001b[92m Client10 Test =>                   \tAcc: 61.301 \tLoss: 1.2674\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 81.689 \tLoss: 0.5437\u001b[00m\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 65.638 \tLoss: 1.0063\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 81.778 \tLoss: 0.5346\u001b[00m\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 67.746 \tLoss: 1.0160\u001b[00m\n",
      "\u001b[91m Client14 Train => Local Epoch: 0 \tAcc: 80.377 \tLoss: 0.5655\u001b[00m\n",
      "\u001b[92m Client14 Test =>                   \tAcc: 64.561 \tLoss: 1.1489\u001b[00m\n",
      "\u001b[91m Client5 Train => Local Epoch: 0 \tAcc: 78.961 \tLoss: 0.5720\u001b[00m\n",
      "\u001b[92m Client5 Test =>                   \tAcc: 60.277 \tLoss: 1.3316\u001b[00m\n",
      "\u001b[91m Client15 Train => Local Epoch: 0 \tAcc: 81.124 \tLoss: 0.5217\u001b[00m\n",
      "\u001b[92m Client15 Test =>                   \tAcc: 64.520 \tLoss: 1.1092\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 80.480 \tLoss: 0.5520\u001b[00m\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 65.167 \tLoss: 1.0591\u001b[00m\n",
      "\u001b[91m Client16 Train => Local Epoch: 0 \tAcc: 81.188 \tLoss: 0.5337\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Client16 Test =>                   \tAcc: 77.108 \tLoss: 0.6446\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "选择的客户端index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "====================== SERVER V1==========================\n",
      " Train: Round  99, Avg Accuracy 77.966 | Avg Loss 0.694\n",
      " Test: Round  99, Avg Accuracy 62.575 | Avg Loss 1.374\n",
      "==========================================================\n",
      "idxs_users [ 8  7 17  0  9  3 12 13  6 19 18 11 10  4  1 14  5 15  2 16]\n",
      "------------------------------------------------------------\n",
      "------ Fed Server: Federation process at Client-Side -------\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 7, 17, 9, 3, 12, 13, 6, 18, 11, 10, 4, 1, 14, 5, 15, 2, 16]\n",
      "fedserver选择的客户端index: [0, 1, 2, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "acc: 66.68911647796631\n",
      "acc: 63.09940719604492\n",
      "acc: 59.341325759887695\n",
      "acc: 68.60856628417969\n",
      "acc: 64.33189582824707\n",
      "acc: 71.1274242401123\n",
      "acc: 62.29121780395508\n",
      "acc: 66.81707954406738\n",
      "acc: 64.63496780395508\n",
      "acc: 70.18453693389893\n",
      "acc: 61.301185607910156\n",
      "acc: 65.63846969604492\n",
      "acc: 67.74649810791016\n",
      "acc: 64.56088352203369\n",
      "acc: 60.27747821807861\n",
      "acc: 64.52047443389893\n",
      "acc: 65.16702556610107\n",
      "acc: 77.10802841186523\n",
      "====================== Fed Server==========================\n",
      " Train: Round  99, Avg Accuracy 77.966 | Avg Loss 0.694\n",
      " Test: Round  99, Avg Accuracy 65.747 | Avg Loss 1.108\n",
      "==========================================================\n",
      "Epoch 99 finished in 00:02:00\n",
      "Epoch 99 finished. Total time: 12091.26 seconds\n"
     ]
    }
   ],
   "source": [
    "for iter in range(epochs):\n",
    "    start_time = time.time()  # 记录开始时间\n",
    "    m = max(int(frac * num_users), 1)\n",
    "    idxs_users = np.random.choice(range(num_users), m, replace=False)  # ，replace=False表示不允许重复选择。\n",
    "    w_locals_client = []  # 用于存储每个客户端训练后的本地模型参数。\n",
    "    loss_avg_test_all_dict = {}\n",
    "    acc_avg_test_all_dict = {}\n",
    "    idx_local_client_dict = {}\n",
    "\n",
    "    for idx in idxs_users:\n",
    "        local = Client(net_glob_client, idx, lr, device, dataset_train=dataset_train, dataset_test=dataset_test,\n",
    "                       idxs=dict_users[idx], idxs_test=dict_users_test[idx], is_attacker=None)\n",
    "        # Training ------------------\n",
    "        w_client = local.train(net=copy.deepcopy(net_glob_client).to(device))\n",
    "        idx_local_client_dict[len(w_locals_client)] = idx\n",
    "        w_locals_client.append(copy.deepcopy(w_client))\n",
    "\n",
    "        # Testing -------------------\n",
    "        local.evaluate(net=copy.deepcopy(net_glob_client).to(device), ell=iter, selected_clients=best_clients_indices)\n",
    "\n",
    "        # Update the dictionaries with the client's self.loss_avg_test_all and self.acc_avg_test_all\n",
    "        loss_avg_test_all_dict[idx] = local.loss_avg_test_all\n",
    "        acc_avg_test_all_dict[idx] = local.acc_avg_test_all\n",
    "\n",
    "    print(\"idxs_users\",idxs_users)\n",
    "    # Ater serving all clients for its local epochs------------\n",
    "    # Federation process at Client-Side------------------------\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    print(\"------ Fed Server: Federation process at Client-Side -------\")\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    # w_locals_client是所有客户端训练后的本地模型参数列表，FedAvg函数是加权平均函数，返回全局模型参数w_glob_client。\n",
    "    # w_glob_client = FedAvg(w_locals_client)\n",
    "    # # 或使用基于聚类的方法\n",
    "    w_locals_client, smallest_cluster_indices = remove_anomalies_kmeans(w_locals_client, w_glob_client, n_clusters=4,\n",
    "                                                                        remove_ratio=poisoned_frac)\n",
    "    w_glob_client = FedAvg(w_locals_client)\n",
    "    best_clients_indices = [client for client in list(range(len(idxs_users))) if client not in smallest_cluster_indices]\n",
    "    # 调用 Krum 算法\n",
    "    # num_to_select = int(num_users * (1 - poisoned_frac - 0.1))  # 选择的客户端数量\n",
    "    # w_glob_client, best_clients_indices = krum_aggregation(w_locals_client, num_to_select)\n",
    "    print([idxs_users[i] for i in best_clients_indices])\n",
    "    # Update client-side global model\n",
    "    net_glob_client.load_state_dict(w_glob_client)\n",
    "\n",
    "    print(\"fedserver选择的客户端index:\", best_clients_indices)\n",
    "    best_clients_idxs = [idx_local_client_dict[i] for i in best_clients_indices]\n",
    "    krum_acc_test_collect_user = [acc_avg_test_all_dict[i] for i in best_clients_idxs]\n",
    "    for acc in krum_acc_test_collect_user:\n",
    "        print(\"acc:\",acc)\n",
    "    krum_loss_test_collect_user = [loss_avg_test_all_dict[i] for i in best_clients_idxs]\n",
    "    \n",
    "    krum_acc_avg_all_user = sum(krum_acc_test_collect_user) / len(krum_acc_test_collect_user)\n",
    "    krum_loss_avg_all_user = sum(krum_loss_test_collect_user) / len(krum_loss_test_collect_user)\n",
    "    krum_acc_test_collect.append(krum_acc_avg_all_user)\n",
    "    krum_loss_test_collect.append(krum_loss_avg_all_user)\n",
    "\n",
    "    print(\"====================== Fed Server==========================\")\n",
    "    print(' Train: Round {:3d}, Avg Accuracy {:.3f} | Avg Loss {:.3f}'.format(iter, acc_avg_all_user_train,\n",
    "                                                                              loss_avg_all_user_train))\n",
    "    print(' Test: Round {:3d}, Avg Accuracy {:.3f} | Avg Loss {:.3f}'.format(iter, krum_acc_avg_all_user,\n",
    "                                                                             krum_loss_avg_all_user))\n",
    "    print(\"==========================================================\")\n",
    "\n",
    "    end_time = time.time()  # 记录结束时间\n",
    "    epoch_time = end_time - start_time  # 计算epoch所耗费的时间\n",
    "    total_time += epoch_time  # 将时间差加到总时间中\n",
    "    # 将时间差值转换为小时、分钟和秒数\n",
    "    hours, rem = divmod(epoch_time, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "    print(f\"Epoch {iter} finished in {int(hours):02d}:{int(minutes):02d}:{int(seconds):02d}\")\n",
    "    print(f\"Epoch {iter} finished. Total time: {total_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and Evaluation completed!\n"
     ]
    }
   ],
   "source": [
    "print(\"Training and Evaluation completed!\")\n",
    "\n",
    "# ===============================================================================\n",
    "# Save output data to .excel file (we use for comparision plots)\n",
    "program = \"SFLV1_label_flipping_random_detect_\"\n",
    "round_process = [i for i in range(1, len(acc_train_collect) + 1)]\n",
    "df = DataFrame({'round': round_process, 'acc_train': acc_train_collect, 'acc_test': acc_test_collect,\n",
    "                'loss_train': loss_train_collect, 'loss_test': loss_test_collect})\n",
    "file_name = program  + str(poisoned_frac) + \"_\" + dataset_choice + \".xlsx\"\n",
    "krum_df = DataFrame({'round': round_process, 'acc_train': acc_train_collect, 'acc_test': krum_acc_test_collect,\n",
    "                'loss_train': loss_train_collect, 'loss_test': krum_loss_test_collect})\n",
    "krum_df.to_excel(file_name, sheet_name=\"v1_test\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[25.383042278289793,\n",
       " 32.9638097333908,\n",
       " 36.612591905593874,\n",
       " 39.237591896057125,\n",
       " 41.648092870712276,\n",
       " 43.11948529720306,\n",
       " 44.65705423355103,\n",
       " 46.14234834194183,\n",
       " 47.254825372695926,\n",
       " 48.14947151184082,\n",
       " 49.41693474769592,\n",
       " 49.91865808486937,\n",
       " 51.21886489868164,\n",
       " 52.355238952636704,\n",
       " 53.22277112960815,\n",
       " 53.431066198349,\n",
       " 54.289292297363275,\n",
       " 55.331916389465334,\n",
       " 55.71254594802856,\n",
       " 56.220703134536734,\n",
       " 57.164177370071414,\n",
       " 57.50275732994081,\n",
       " 58.3909696292877,\n",
       " 58.87695308685303,\n",
       " 59.302159910202036,\n",
       " 60.144071674346925,\n",
       " 60.548713178634635,\n",
       " 60.604894285202036,\n",
       " 61.38465068817139,\n",
       " 61.70634188652038,\n",
       " 62.092715959548954,\n",
       " 62.32812494277955,\n",
       " 63.16475177764894,\n",
       " 63.280445728302006,\n",
       " 63.87557439804078,\n",
       " 63.916704883575434,\n",
       " 64.28538599967956,\n",
       " 64.58007809638977,\n",
       " 64.78550084114075,\n",
       " 65.41704958915709,\n",
       " 65.83030785560608,\n",
       " 66.20668651580809,\n",
       " 66.26769295692442,\n",
       " 66.386488904953,\n",
       " 67.03527107238769,\n",
       " 67.16440711021421,\n",
       " 67.5899585533142,\n",
       " 67.487476978302,\n",
       " 68.1533776950836,\n",
       " 68.41360289573667,\n",
       " 68.51229314804075,\n",
       " 68.7190946006775,\n",
       " 69.13775269508362,\n",
       " 69.38568467140198,\n",
       " 69.6125918674469,\n",
       " 69.89005051612854,\n",
       " 69.86397054672241,\n",
       " 70.35328581809998,\n",
       " 70.4733454990387,\n",
       " 71.05514701843262,\n",
       " 71.05457257270811,\n",
       " 71.48368563652036,\n",
       " 71.7465532875061,\n",
       " 71.94669116020202,\n",
       " 71.8652343559265,\n",
       " 72.15636487007141,\n",
       " 72.26068470954895,\n",
       " 72.41670497894289,\n",
       " 72.77699906349181,\n",
       " 73.08754596710205,\n",
       " 73.00068933486936,\n",
       " 73.4062499809265,\n",
       " 73.25264243125915,\n",
       " 73.64556526184082,\n",
       " 73.79595588684083,\n",
       " 74.3521369457245,\n",
       " 74.04561119079591,\n",
       " 74.48357075691223,\n",
       " 74.36638327598573,\n",
       " 74.66233916282656,\n",
       " 74.97311580657959,\n",
       " 74.91739431381225,\n",
       " 75.13017002105713,\n",
       " 75.48081347465514,\n",
       " 75.52964155197144,\n",
       " 75.82387410163878,\n",
       " 75.75425092697142,\n",
       " 76.33203125953673,\n",
       " 76.18462779045103,\n",
       " 76.48471971511842,\n",
       " 76.50459564208982,\n",
       " 76.61557906150819,\n",
       " 77.05330888748169,\n",
       " 76.92451749801636,\n",
       " 76.93956804275513,\n",
       " 77.25287227630614,\n",
       " 77.643382396698,\n",
       " 77.70909932136534,\n",
       " 77.46461400032044,\n",
       " 77.96553313255309]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_train_collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 创建一个名为df的DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'age': [25, 30, 35],\n",
    "    'country': ['USA', 'Canada', 'Australia']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
