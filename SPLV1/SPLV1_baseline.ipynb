{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c3d19d7",
   "metadata": {},
   "source": [
    "# 一、 背景设置\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8193ea19",
   "metadata": {},
   "source": [
    "## 初始设置\n",
    "模型架构:SplitFedV1   \n",
    "DNN架构:ResNet18<br>\n",
    "数据集:HAM10000,  \n",
    "多分类问题  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cce89ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#============================================================================\n",
    "# SplitfedV1 (SFLV1) learning: ResNet18 on HAM10000\n",
    "# HAM10000 dataset: Tschandl, P.: The HAM10000 dataset, a large collection of multi-source dermatoscopic images of common pigmented skin lesions (2018), doi:10.7910/DVN/DBW86T\n",
    "\n",
    "# We have three versions of our implementations\n",
    "# Version1: without using socket and no DP+PixelDP\n",
    "# Version2: with using socket but no DP+PixelDP\n",
    "# Version3: without using socket but with DP+PixelDP\n",
    "\n",
    "# This program is Version1: Single program simulation \n",
    "# ============================================================================\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms   # 导入PyTorch中的图像变换模块。\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F  # 导入PyTorch中的常用函数模块，例如ReLU、softmax等。\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "from pandas import DataFrame\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e74a90",
   "metadata": {},
   "source": [
    "## 创建随机数种子，保证程序结果可以重复"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60183050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce GTX 1660 Ti\n"
     ]
    }
   ],
   "source": [
    "# 将随机数种子设置为1234，这可以确保在每次运行代码时生成的随机数序列都是相同的。\n",
    "SEED = 1234\n",
    "random.seed(SEED)  # 确保Python标准库中的随机数生成器生成的随机数序列相同。\n",
    "np.random.seed(SEED)  # 确保NumPy中的随机数生成器生成的随机数序列相同。\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)  #  设置PyTorch中的CUDA随机数生成器的种子，确保在使用CUDA时生成的随机数序列相同。\n",
    "if torch.cuda.is_available():\n",
    "    # 如果CUDA可用，则打印第一个可用的CUDA设备的名称。\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    print(torch.cuda.get_device_name(0)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533c4a8f",
   "metadata": {},
   "source": [
    "## 定义程序和变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23aa219f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------SFLV1 ResNet18 on HAM10000----------\n"
     ]
    }
   ],
   "source": [
    "#===================================================================\n",
    "program = \"SFLV1 ResNet18 on HAM10000\"    # 定义了程序名称。\n",
    "print(f\"---------{program}----------\")              # this is to identify the program in the slurm outputs files\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# To print in color -------test/train of the client side\n",
    "# 定义一个函数 prRed，用于在控制台中以红色打印文本。\n",
    "def prRed(skk): print(\"\\033[91m {}\\033[00m\" .format(skk)) \n",
    "# 用于在控制台中以绿色打印文本。\n",
    "def prGreen(skk): print(\"\\033[92m {}\\033[00m\" .format(skk))     \n",
    "\n",
    "#===================================================================\n",
    "# No. of users\n",
    "num_users = 5  # 参与训练的客户端\n",
    "epochs = 200\n",
    "frac = 1        # participation of clients; if 1 then 100% clients participate in SFLV1\n",
    "lr = 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b879b235",
   "metadata": {},
   "source": [
    "# 模型定义"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813288b3",
   "metadata": {},
   "source": [
    "## Client-side Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea58333a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=====================================================================================================\n",
    "#                           Client-side Model definition\n",
    "#=====================================================================================================\n",
    "# Model at client side\n",
    "class ResNet18_client_side(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet18_client_side,                                                          self).__init__()\n",
    "        self.layer1 = nn.Sequential (\n",
    "                # (n+1)/2\n",
    "                nn.Conv2d(3, 64, kernel_size = 7, stride = 2, padding = 3, bias = False),\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.ReLU (inplace = True),\n",
    "                # (n+3)/2\n",
    "                nn.MaxPool2d(kernel_size = 3, stride = 2, padding =1),\n",
    "            )\n",
    "        self.layer2 = nn.Sequential  (\n",
    "            # 不变\n",
    "                nn.Conv2d(64, 64, kernel_size = 3, stride = 1, padding = 1, bias = False),\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.ReLU (inplace = True),\n",
    "                nn.Conv2d(64, 64, kernel_size = 3, stride = 1, padding = 1),\n",
    "                nn.BatchNorm2d(64),              \n",
    "            )\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                # 其中，m.weight 表示子模块 m 的权重张量，.data 表示获取该张量的底层数据，并且.normal_() 表示在该数据上进行 Inplace 操作，即直接在原数据上修改而不返回新的数据。\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                # 如果该子模块是 nn.BatchNorm2d 类型，就将权重设置为1，偏差设置为0。\n",
    "                # 这是 Batch Normalization 的初始化方式。\n",
    "                m.weight.data.fill_(1)\n",
    "                \n",
    "                m.bias.data.zero_()\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        resudial1 = F.relu(self.layer1(x))\n",
    "        out1 = self.layer2(resudial1)\n",
    "        out1 = out1 + resudial1 # adding the resudial inputs -- downsampling not required in this layer\n",
    "        resudial2 = F.relu(out1)\n",
    "        return resudial2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98982f45",
   "metadata": {},
   "source": [
    "创建实例，打印"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa40bb43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet18_client_side(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net_glob_client = ResNet18_client_side()\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"We use\",torch.cuda.device_count(), \"GPUs\")\n",
    "    net_glob_client = nn.DataParallel(net_glob_client)    \n",
    "\n",
    "net_glob_client.to(device)\n",
    "print(net_glob_client)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d8fed9",
   "metadata": {},
   "source": [
    "## Server-side Model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83008733",
   "metadata": {},
   "source": [
    "### BaseBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecdef2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Baseblock(nn.Module):\n",
    "    # residule block\n",
    "    expansion = 1 # 类变量，用于定义基本块的输出通道数与输入通道数的比例，默认为1。\n",
    "    def __init__(self, input_planes, planes, stride = 1, dim_change = None):\n",
    "        super(Baseblock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_planes, planes, stride =  stride, kernel_size = 3, padding = 1)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, stride = 1, kernel_size = 3, padding = 1)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.dim_change = dim_change\n",
    "        \n",
    "    def forward(self, x):\n",
    "        res = x\n",
    "        output = F.relu(self.bn1(self.conv1(x)))\n",
    "        output = self.bn2(self.conv2(output))\n",
    "        \n",
    "        if self.dim_change is not None:\n",
    "            res =self.dim_change(res)\n",
    "            \n",
    "        output += res\n",
    "        output = F.relu(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df739a6",
   "metadata": {},
   "source": [
    "### Server-side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b34eb94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18_server_side(nn.Module):\n",
    "    def __init__(self, block, num_layers, classes):\n",
    "        super(ResNet18_server_side, self).__init__()\n",
    "        self.input_planes = 64\n",
    "        self.layer3 = nn.Sequential (\n",
    "                nn.Conv2d(64, 64, kernel_size = 3, stride = 1, padding = 1),\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.ReLU (inplace = True),\n",
    "                nn.Conv2d(64, 64, kernel_size = 3, stride = 1, padding = 1),\n",
    "                nn.BatchNorm2d(64),       \n",
    "                )   \n",
    "        \n",
    "        self.layer4 = self._layer(block, 128, num_layers[0], stride = 2)\n",
    "        self.layer5 = self._layer(block, 256, num_layers[1], stride = 2)\n",
    "        self.layer6 = self._layer(block, 512, num_layers[2], stride = 2)\n",
    "        self.averagePool = nn.AvgPool2d(kernel_size = 2, stride = 1)\n",
    "        self.fc = nn.Linear(512 * block.expansion, classes)\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "        \n",
    "        \n",
    "    def _layer(self, block, planes, num_layers, stride = 2):\n",
    "        dim_change = None\n",
    "        if stride != 1 or planes != self.input_planes * block.expansion:\n",
    "            dim_change = nn.Sequential(nn.Conv2d(self.input_planes, planes*block.expansion, kernel_size = 1, stride = stride),\n",
    "                                       nn.BatchNorm2d(planes*block.expansion))\n",
    "        netLayers = []\n",
    "        # # 将一个基本块block加入到列表中，并且输入参数为当前输入通道数self.inplanes、输出通道数planes、步长stride和下采样操作downsample。\n",
    "        netLayers.append(block(self.input_planes, planes, stride = stride, dim_change = dim_change))\n",
    "        self.input_planes = planes * block.expansion\n",
    "        for i in range(1, num_layers):\n",
    "            netLayers.append(block(self.input_planes, planes))\n",
    "            self.input_planes = planes * block.expansion\n",
    "        # 最后，将netLayers序列封装为nn.Sequential类型的对象，并将其返回\n",
    "        return nn.Sequential(*netLayers)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out2 = self.layer3(x)\n",
    "        out2 = out2 + x          # adding the resudial inputs -- downsampling not required in this layer\n",
    "        x3 = F.relu(out2)\n",
    "        \n",
    "        x4 = self. layer4(x3)\n",
    "        x5 = self.layer5(x4)\n",
    "        x6 = self.layer6(x5)\n",
    "        \n",
    "        x7 = F.avg_pool2d(x6, 2)\n",
    "        x8 = x7.view(x7.size(0), -1) \n",
    "        y_hat =self.fc(x8)\n",
    "        \n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b896d1c7",
   "metadata": {},
   "source": [
    "### 创建实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e759d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet18_server_side(\n",
      "  (layer3): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Baseblock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dim_change): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Baseblock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer5): Sequential(\n",
      "    (0): Baseblock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dim_change): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Baseblock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer6): Sequential(\n",
      "    (0): Baseblock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dim_change): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Baseblock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (averagePool): AvgPool2d(kernel_size=2, stride=1, padding=0)\n",
      "  (fc): Linear(in_features=512, out_features=7, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net_glob_server = ResNet18_server_side(Baseblock, [2,2,2], 7) #7 is my numbr of classes\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"We use\",torch.cuda.device_count(), \"GPUs\")\n",
    "    net_glob_server = nn.DataParallel(net_glob_server)   # to use the multiple GPUs \n",
    "\n",
    "net_glob_server.to(device)\n",
    "print(net_glob_server) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef78269f",
   "metadata": {},
   "source": [
    "## Server端参数和聚合函数定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf76305a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===================================================================================\n",
    "# For Server Side Loss and Accuracy \n",
    "loss_train_collect = []  # 创建一个空列表，用于记录每个客户端训练的损失。\n",
    "acc_train_collect = []\n",
    "loss_test_collect = []  # # 创建一个空列表，用于记录全局模型在测试集上的损失。\n",
    "acc_test_collect = []\n",
    "batch_acc_train = []\n",
    "batch_loss_train = []\n",
    "batch_acc_test = []\n",
    "batch_loss_test = []\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "count1 = 0\n",
    "count2 = 0\n",
    "\n",
    "def calculate_accuracy(fx, y):\n",
    "    preds = fx.max(1, keepdim=True)[1]\n",
    "    correct = preds.eq(y.view_as(preds)).sum()\n",
    "    acc = 100.00 *correct.float()/preds.shape[0]\n",
    "    return acc\n",
    "\n",
    "# to print train - test together in each round-- these are made global\n",
    "acc_avg_all_user_train = 0\n",
    "loss_avg_all_user_train = 0\n",
    "loss_train_collect_user = []\n",
    "acc_train_collect_user = []\n",
    "loss_test_collect_user = []\n",
    "acc_test_collect_user = []\n",
    "\n",
    "# （即权重和偏置）保存到w_glob_server中。\n",
    "w_glob_server = net_glob_server.state_dict()\n",
    "w_locals_server = []\n",
    "\n",
    "#client idx collector\n",
    "idx_collect = []    # 初始化一个空列表，用于收集选择的客户端的索引。\n",
    "l_epoch_check = False   # 初始化一个布尔变量，用于指示是否进行了本地训练轮次的检查。\n",
    "fed_check = False   # 初始化一个布尔变量，用于指示是否完成了联邦学习。\n",
    "# Initialization of net_model_server and net_server (server-side model)\n",
    "net_model_server = [net_glob_server for i in range(num_users)]  # 该列表包含了每个客户端的初始模型。\n",
    "net_server = copy.deepcopy(net_model_server[0]).to(device)  # 初始化为net_model_server的第一个元素的深拷贝，并将其移到GPU上。\n",
    "#optimizer_server = torch.optim.Adam(net_server.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96da673",
   "metadata": {},
   "source": [
    "### 定义聚合规则"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40e26c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FedAvg(w):\n",
    "    w_avg = copy.deepcopy(w[0])\n",
    "    for k in w_avg.keys():\n",
    "        for i in range(1, len(w)):\n",
    "            w_avg[k] += w[i][k]\n",
    "        w_avg[k] = torch.div(w_avg[k], len(w))\n",
    "    return w_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b05bf1",
   "metadata": {},
   "source": [
    "# 训练&评估函数定义"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0815d6",
   "metadata": {},
   "source": [
    "## Server 训练和评估函数定义\n",
    "### train_server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4d3f267",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_server(fx_client, y, l_epoch_count, l_epoch, idx, len_batch):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        fx_client: 一个函数，用于在客户端更新模型参数，它接受以下参数：net_model_client（客户端模型），optimizer_client（客户端优化器），train_loader（客户端训练数据），l_epoch（客户端训练轮数）。\n",
    "        y:目标变量的标签值。\n",
    "        l_epoch_count:训练的总轮数\n",
    "        l_epoch:当前训练的轮数\n",
    "        idx:用于选择在全局模型中使用哪些本地模型进行更新的客户端的索引。\n",
    "        len_batch:训练数据的批次大小。\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    # 这些是全局变量，因为它们在函数内被更新，并且在函数之外被调用。\n",
    "    \"\"\"\n",
    "    net_model_server: 全局模型。\n",
    "    criterion: 损失函数，用于计算模型的误差。\n",
    "    optimizer_server: 优化器，用于更新全局模型的参数。\n",
    "    device: 设备（CPU或GPU）用于计算。\n",
    "    batch_acc_train: 当前批次的准确度。\n",
    "    batch_loss_train: 当前批次的损失。\n",
    "    l_epoch_check: 在训练期间用于检查损失和准确度的训练周期数。\n",
    "    fed_check: 用于检查训练周期是否已完成的标志。\n",
    "    loss_train_collect: 用于收集所有客户端训练损失的列表。\n",
    "    acc_train_collect: 用于收集所有客户端训练准确度的列表。\n",
    "    count1: 计数器，用于跟踪当前已经训练的客户端数量。\n",
    "    acc_avg_all_user_train: 所有客户端训练准确度的平均值。\n",
    "    loss_avg_all_user_train: 所有客户端训练损失的平均值。\n",
    "    idx_collect: 用于跟踪已经训练的客户端的索引列表。\n",
    "    w_locals_server: 所有客户端本地模型参数的列表。\n",
    "    w_glob_server: 全局模型参数的列表。\n",
    "    net_server: 全局模型。\n",
    "    \"\"\"\n",
    "    global net_model_server, criterion, optimizer_server, device, batch_acc_train, batch_loss_train, l_epoch_check, fed_check\n",
    "    global loss_train_collect, acc_train_collect, count1, acc_avg_all_user_train, loss_avg_all_user_train, idx_collect, w_locals_server, w_glob_server, net_server\n",
    "    global loss_train_collect_user, acc_train_collect_user, lr\n",
    "\n",
    "    # net_server是全局模型，返回制定索引的本地模型\n",
    "    net_server = copy.deepcopy(net_model_server[idx]).to(device)    # copy.deepcopy() 函数用于创建一个当前本地模型的副本，以便我们可以在全局模型的更新过程中使用它，而不会对原始本地模型进行更改。\n",
    "    # 方法将模型设置为训练模式，这意味着在计算时会使用训练期间的正则化技术，如dropout或batch normalization。\n",
    "    net_server.train()\n",
    "    # 是一个PyTorch中的Adam优化器的实现，它接受模型参数和学习率作为参数，用于更新模型参数以最小化损失函数。在这里，我们使用全局模型的参数和一个预定义的学习率 lr 创建了一个Adam优化器对象\n",
    "    optimizer_server = torch.optim.Adam(net_server.parameters(), lr = lr)\n",
    "\n",
    "    \n",
    "    # 1.train and update\n",
    "    # 用于清空之前的梯度信息，这样我们可以在每个训练迭代中计算新的梯度并更新模型参数。\n",
    "    optimizer_server.zero_grad()\n",
    "    \n",
    "    fx_client = fx_client.to(device)\n",
    "    y = y.to(device)\n",
    "    \n",
    "    #---------forward prop-------------\n",
    "    fx_server = net_server(fx_client)   # 作为输入传递到全局模型 net_server 中，然后返回模型的预测输出 fx_server\n",
    "    \n",
    "    # calculate loss\n",
    "    loss = criterion(fx_server, y)\n",
    "    # calculate accuracy\n",
    "    acc = calculate_accuracy(fx_server, y)\n",
    "    \n",
    "    #--------backward prop--------------\n",
    "    loss.backward()\n",
    "    # 由于我们需要在全局模型更新之前将 fx_client 更新到最新的版本，因此我们使用 clone().detach() 函数来创建一个新的 dfx_client 张量，它具有相同的值但不会被计算图所记录。\n",
    "    dfx_client = fx_client.grad.clone().detach()\n",
    "    optimizer_server.step()\n",
    "    \n",
    "    batch_loss_train.append(loss.item())\n",
    "    batch_acc_train.append(acc.item())\n",
    "    \n",
    "    # Update the server-side model for the current batch\n",
    "    net_model_server[idx] = copy.deepcopy(net_server)\n",
    "    \n",
    "    # count1: to track the completion of the local batch associated with one client\n",
    "    count1 += 1\n",
    "    if count1 == len_batch:\n",
    "        acc_avg_train = sum(batch_acc_train)/len(batch_acc_train)           # 计算当前batch的准确率\n",
    "        loss_avg_train = sum(batch_loss_train)/len(batch_loss_train)    # 计算当前batch的损失\n",
    "        \n",
    "        batch_acc_train = []    # 将当前batch准确率清零\n",
    "        batch_loss_train = []\n",
    "        count1 = 0\n",
    "        \n",
    "        prRed('Client{} Train => Local Epoch: {} \\tAcc: {:.3f} \\tLoss: {:.4f}'.format(idx, l_epoch_count, acc_avg_train, loss_avg_train))\n",
    "        \n",
    "        # copy the last trained model in the batch\n",
    "        # 的状态字典复制到一个新的字典中，以便我们可以将其发送到参与者，从而启动下一轮的联邦学习。注意，w_server 中包含的参数是最新一轮训练的参数，因此每个参与者将从这些参数开始训练它们的本地模型。\n",
    "        w_server = net_server.state_dict()      \n",
    "        \n",
    "        # If one local epoch is completed, after this a new client will come\n",
    "        if l_epoch_count == l_epoch-1:\n",
    "            # l_epoch_count 是本地epoch的计数器，l_epoch 是本地epoch的总数。当计数器 l_epoch_count 等于总数 l_epoch 减 1 时，说明本地epoch已经完成。\n",
    "            # # 标记已经完成本地epoch\n",
    "            l_epoch_check = True                # to evaluate_server function - to check local epoch has completed or not \n",
    "            # We store the state of the net_glob_server()\n",
    "            # w_server 是全局模型中最新的训练参数，w_locals_server 是用于存储每个参与者的最后一轮训练参数的列表。因此，当本地epoch完成时，将 w_server 添加到 w_locals_server 中，以便之后将其发送到联邦平均服务器。\n",
    "            w_locals_server.append(copy.deepcopy(w_server))\n",
    "            \n",
    "            # we store the last accuracy in the last batch of the epoch and it is not the average of all local epochs\n",
    "            # this is because we work on the last trained model and its accuracy (not earlier cases)\n",
    "            \n",
    "            #print(\"accuracy = \", acc_avg_train)\n",
    "            acc_avg_train_all = acc_avg_train   # 记录最后一个batch的准确率和损失，作为本地epoch的结果\n",
    "            loss_avg_train_all = loss_avg_train #\n",
    "                        \n",
    "            # accumulate accuracy and loss for each new user\n",
    "            loss_train_collect_user.append(loss_avg_train_all)   # 将本地epoch的损失添加到损失列表中\n",
    "            acc_train_collect_user.append(acc_avg_train_all)    # # 将本地epoch的准确率添加到准确率列表中\n",
    "            \n",
    "            # collect the id of each new user                        \n",
    "            if idx not in idx_collect:\n",
    "                idx_collect.append(idx) \n",
    "                #print(idx_collect)\n",
    "                print(idx_collect)\n",
    "        \n",
    "        # This is for federation process--------------------\n",
    "        if len(idx_collect) == num_users:\n",
    "            # 如果客户端编号列表的长度等于客户端总数，说明所有客户端的训练结果都已经到达服务器了。\n",
    "            fed_check = True                                                  # to evaluate_server function  - to check fed check has hitted\n",
    "            # Federation process at Server-Side------------------------- output print and update is done in evaluate_server()\n",
    "            # for nicer display \n",
    "                                   \n",
    "            w_glob_server = FedAvg(w_locals_server)  # 使用联邦平均算法更新全局模型，将所有客户端的本地模型参数传入该函数中。\n",
    "            \n",
    "            # server-side global model update and distribute that model to all clients ------------------------------\n",
    "            net_glob_server.load_state_dict(w_glob_server)      # 将更新后的全局模型参数加载到服务器端的模型中。\n",
    "            net_model_server = [net_glob_server for i in range(num_users)]  # 创建一个长度为客户端数量的列表，每个元素都是更新后的全局模型。这个列表用于向每个客户端分发全局模型参数。\n",
    "            \n",
    "            w_locals_server = []    #  # 清空本地模型参数列表\n",
    "            idx_collect = []    # 清空客户端编号列表\n",
    "            \n",
    "            acc_avg_all_user_train = sum(acc_train_collect_user)/len(acc_train_collect_user)    # 计算所有客户端训练结果的平均准确率和损失\n",
    "            loss_avg_all_user_train = sum(loss_train_collect_user)/len(loss_train_collect_user)\n",
    "            \n",
    "            loss_train_collect.append(loss_avg_all_user_train)\n",
    "            acc_train_collect.append(acc_avg_all_user_train)\n",
    "            \n",
    "            acc_train_collect_user = []\n",
    "            loss_train_collect_user = []\n",
    "            \n",
    "    # send gradients to the client               \n",
    "    return dfx_client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcebf93",
   "metadata": {},
   "source": [
    "### eval_server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d0f80b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_server(fx_client, y, idx, len_batch, ell):\n",
    "    global net_model_server, criterion, batch_acc_test, batch_loss_test, check_fed, net_server, net_glob_server \n",
    "    global loss_test_collect, acc_test_collect, count2, num_users, acc_avg_train_all, loss_avg_train_all, w_glob_server, l_epoch_check, fed_check\n",
    "    global loss_test_collect_user, acc_test_collect_user, acc_avg_all_user_train, loss_avg_all_user_train\n",
    "    \n",
    "    net = copy.deepcopy(net_model_server[idx]).to(device)\n",
    "    net.eval()\n",
    "  \n",
    "    with torch.no_grad():\n",
    "        # with torch.no_grad()是一个上下文管理器，它可以暂时关闭所有的requires_grad标志，从而不计算梯度1。这样可以节省内存，提高推理速度，也可以避免不必要的梯度累积2。通常在验证或部署模型时使用这个方法3。\n",
    "        fx_client = fx_client.to(device)\n",
    "        y = y.to(device) \n",
    "        #---------forward prop-------------\n",
    "        fx_server = net(fx_client)\n",
    "        \n",
    "        # calculate loss\n",
    "        loss = criterion(fx_server, y)\n",
    "        # calculate accuracy\n",
    "        acc = calculate_accuracy(fx_server, y)\n",
    "        \n",
    "        \n",
    "        batch_loss_test.append(loss.item())\n",
    "        batch_acc_test.append(acc.item())\n",
    "        \n",
    "               \n",
    "        count2 += 1\n",
    "        if count2 == len_batch:\n",
    "            acc_avg_test = sum(batch_acc_test)/len(batch_acc_test)\n",
    "            loss_avg_test = sum(batch_loss_test)/len(batch_loss_test)\n",
    "            \n",
    "            batch_acc_test = []\n",
    "            batch_loss_test = []\n",
    "            count2 = 0\n",
    "            \n",
    "            prGreen('Client{} Test =>                   \\tAcc: {:.3f} \\tLoss: {:.4f}'.format(idx, acc_avg_test, loss_avg_test))\n",
    "            \n",
    "            # if a local epoch is completed   \n",
    "            if l_epoch_check:\n",
    "                l_epoch_check = False\n",
    "                \n",
    "                # Store the last accuracy and loss\n",
    "                acc_avg_test_all = acc_avg_test\n",
    "                loss_avg_test_all = loss_avg_test\n",
    "                        \n",
    "                loss_test_collect_user.append(loss_avg_test_all)\n",
    "                acc_test_collect_user.append(acc_avg_test_all)\n",
    "                \n",
    "            # if federation is happened----------                    \n",
    "            if fed_check:\n",
    "                fed_check = False\n",
    "                print(\"------------------------------------------------\")\n",
    "                print(\"------ Federation process at Server-Side ------- \")\n",
    "                print(\"------------------------------------------------\")\n",
    "                \n",
    "                acc_avg_all_user = sum(acc_test_collect_user)/len(acc_test_collect_user)\n",
    "                loss_avg_all_user = sum(loss_test_collect_user)/len(loss_test_collect_user)\n",
    "            \n",
    "                loss_test_collect.append(loss_avg_all_user)\n",
    "                acc_test_collect.append(acc_avg_all_user)\n",
    "                acc_test_collect_user = []\n",
    "                loss_test_collect_user= []\n",
    "                              \n",
    "                print(\"====================== SERVER V1==========================\")\n",
    "                print(' Train: Round {:3d}, Avg Accuracy {:.3f} | Avg Loss {:.3f}'.format(ell, acc_avg_all_user_train, loss_avg_all_user_train))\n",
    "                print(' Test: Round {:3d}, Avg Accuracy {:.3f} | Avg Loss {:.3f}'.format(ell, acc_avg_all_user, loss_avg_all_user))\n",
    "                print(\"==========================================================\")\n",
    "         \n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031c8dc0",
   "metadata": {},
   "source": [
    "## DataSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b0e3edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetSplit(Dataset):\n",
    "    def __init__(self, dataset, idxs):\n",
    "        self.dataset = dataset\n",
    "        self.idxs = list(idxs)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idxs)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        image, label = self.dataset[self.idxs[item]]\n",
    "        return image, label\n",
    "\n",
    "def dataset_iid(dataset, num_users):\n",
    "    # 该函数接受一个数据集dataset和一个整数num_users作为输入。它的作用是将数据集分割成num_users份，以便每个客户端都有一份相同分布的数据集。\n",
    "    num_items = int(len(dataset)/num_users)\n",
    "    dict_users, all_idxs = {}, [i for i in range(len(dataset))]\n",
    "    for i in range(num_users):\n",
    "        dict_users[i] = set(np.random.choice(all_idxs, num_items, replace = False))\n",
    "        all_idxs = list(set(all_idxs) - dict_users[i])\n",
    "    return dict_users   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1728639d",
   "metadata": {},
   "source": [
    "## Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8484455e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Client(object):\n",
    "    def __init__(self, net_client_model, idx, lr, device, dataset_train = None, dataset_test = None, idxs = None, idxs_test = None):\n",
    "        # net_client_model:一个与客户端实例相关的神经网络模型。\n",
    "        self.idx = idx  # 一个整数，表示客户端的索引\n",
    "        self.device = device    # 一个字符串，表示执行客户端计算的设备。\n",
    "        self.lr = lr\n",
    "        self.local_ep = 1\n",
    "        #self.selected_clients = []\n",
    "        self.ldr_train = DataLoader(DatasetSplit(dataset_train, idxs), batch_size = 256, shuffle = True)    # 一个PyTorch数据集，表示客户端可用于训练的数据\n",
    "        self.ldr_test = DataLoader(DatasetSplit(dataset_test, idxs_test), batch_size = 256, shuffle = True)\n",
    "        \n",
    "\n",
    "    def train(self, net):\n",
    "        net.train()\n",
    "        optimizer_client = torch.optim.Adam(net.parameters(), lr = self.lr) \n",
    "        \n",
    "        for iter in range(self.local_ep):\n",
    "            # 外层循环是客户端的本地训练轮数self.local_ep\n",
    "            len_batch = len(self.ldr_train)\n",
    "            for batch_idx, (images, labels) in enumerate(self.ldr_train):\n",
    "                # 内层循环是数据加载器self.ldr_train中每个批次的训练。在每个批次中，将图像和标签加载到设备上，然后将优化器的梯度清零。\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                optimizer_client.zero_grad()\n",
    "                #---------forward prop-------------\n",
    "                fx = net(images)\n",
    "                # 生成一个可求导的副本client_fx\n",
    "                client_fx = fx.clone().detach().requires_grad_(True)\n",
    "                \n",
    "                # Sending activations to server and receiving gradients from server\n",
    "                dfx = train_server(client_fx, labels, iter, self.local_ep, self.idx, len_batch)\n",
    "                \n",
    "                #--------backward prop -------------\n",
    "                fx.backward(dfx)\n",
    "                optimizer_client.step()\n",
    "                            \n",
    "            \n",
    "            #prRed('Client{} Train => Epoch: {}'.format(self.idx, ell))\n",
    "           \n",
    "        return net.state_dict() \n",
    "    \n",
    "    def evaluate(self, net, ell):\n",
    "        net.eval()\n",
    "           \n",
    "        with torch.no_grad():\n",
    "            len_batch = len(self.ldr_test)\n",
    "            for batch_idx, (images, labels) in enumerate(self.ldr_test):\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                #---------forward prop-------------\n",
    "                fx = net(images)\n",
    "                \n",
    "                # Sending activations to server \n",
    "                evaluate_server(fx, labels, self.idx, len_batch, ell)\n",
    "            \n",
    "            #prRed('Client{} Test => Epoch: {}'.format(self.idx, ell))\n",
    "            \n",
    "        return   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb71b6e",
   "metadata": {},
   "source": [
    "# 程序运行"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e7d1e9",
   "metadata": {},
   "source": [
    "## 导入数据并预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37ea76ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     lesion_id      image_id   dx dx_type   age   sex localization\n",
      "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp\n",
      "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp\n",
      "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp\n",
      "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp\n",
      "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear\n",
      "Melanocytic nevi                  6705\n",
      "Melanoma                          1113\n",
      "Benign keratosis-like lesions     1099\n",
      "Basal cell carcinoma               514\n",
      "Actinic keratoses                  327\n",
      "Vascular lesions                   142\n",
      "Dermatofibroma                     115\n",
      "Name: cell_type, dtype: int64\n",
      "4    6705\n",
      "5    1113\n",
      "2    1099\n",
      "1     514\n",
      "0     327\n",
      "6     142\n",
      "3     115\n",
      "Name: target, dtype: int64\n",
      "     lesion_id      image_id   dx dx_type   age   sex localization  \\\n",
      "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp   \n",
      "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp   \n",
      "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp   \n",
      "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp   \n",
      "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear   \n",
      "\n",
      "                                                path  \\\n",
      "0  D:\\codes\\DeepLearning\\SplitFed-When-Federated-...   \n",
      "1  D:\\codes\\DeepLearning\\SplitFed-When-Federated-...   \n",
      "2  D:\\codes\\DeepLearning\\SplitFed-When-Federated-...   \n",
      "3  D:\\codes\\DeepLearning\\SplitFed-When-Federated-...   \n",
      "4  D:\\codes\\DeepLearning\\SplitFed-When-Federated-...   \n",
      "\n",
      "                        cell_type  target  \n",
      "0  Benign keratosis-like lesions        2  \n",
      "1  Benign keratosis-like lesions        2  \n",
      "2  Benign keratosis-like lesions        2  \n",
      "3  Benign keratosis-like lesions        2  \n",
      "4  Benign keratosis-like lesions        2  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('D:\\codes\\DeepLearning\\SplitFed-When-Federated-Learning-Meets-Split-Learning\\data\\HAM10000_metadata.csv')\n",
    "\"\"\"\n",
    "lesion_id：病变ID，标识一组图像（有些病变ID具有多个图像）.一个患者可能有多个损伤，该ID对应一个患者的所有损伤都相同。\n",
    "image_id：图像ID，唯一标识每个图像\n",
    "dx：病变诊断，一个分类标签，代表着皮肤病的类型，如良性病变（如色素性痣或良性肿瘤）或恶性病变（如黑色素瘤或基底细胞癌）。\n",
    "dx_type：病变诊断类型，指诊断方法，包括临床（通过肉眼观察）、镜下（组织活检）、或是历史（过去的诊断）。\n",
    "age：患者年龄，以年为单位，有一些缺失值。\n",
    "sex：患者性别，分为男性或女性，有一些缺失值。\n",
    "localization：病变位置，即皮肤上的具体位置，如头皮、脸部、手臂等。\n",
    "\"\"\"\n",
    "print(df.head())\n",
    "\n",
    "# python字典\n",
    "# 在皮肤病分类任务中，通常需要将原始的标签进行映射，从而将缩写转换为完整的病种名称。\n",
    "lesion_type = {\n",
    "    'nv': 'Melanocytic nevi',  # 黑素瘤痣\n",
    "    'mel': 'Melanoma',  # 黑色素瘤\n",
    "    'bkl': 'Benign keratosis-like lesions ',  # 良性鳞状细胞痣\n",
    "    'bcc': 'Basal cell carcinoma',  # 基底细胞癌\n",
    "    'akiec': 'Actinic keratoses',  # 日光性角化病\n",
    "    'vasc': 'Vascular lesions',  # 血管病变\n",
    "    'df': 'Dermatofibroma'  # 皮脂纤维瘤\n",
    "}\n",
    "\n",
    "# merging both folders of HAM1000 dataset -- part1 and part2 -- into a single directory\n",
    "# os.path.join是路径拼接，glob是自带的文件操作，获得制定的文件\n",
    "\"\"\"\n",
    "glob(os.path.join(\"data\", '*', '*.jpg'))获取了data目录下的所有.jpg图片的路径，其中*是通配符，可以匹配任何文件夹名。\n",
    "os.path.basename(x)获取了路径x的文件名，如ISIC_0024433.jpg。\n",
    "\n",
    "os.path.splitext(os.path.basename(x))[0]去掉了文件名的后缀.jpg，如ISIC_0024433。\n",
    "\n",
    "最终的结果是一个字典，其中key为图片id，value为图片路径，如{'ISIC_0024433': 'data\\HAM10000_images_part_1\\ISIC_0024433.jpg', ...}。\n",
    "\"\"\"\n",
    "imageid_path = {os.path.splitext(os.path.basename(x))[0]: x\n",
    "                for x in glob(os.path.join(\"D:\\codes\\DeepLearning\\SplitFed-When-Federated-Learning-Meets-Split-Learning\\data\", '*', '*.jpg'))}\n",
    "\n",
    "# print(\"path---------------------------------------\", imageid_path.get)\n",
    "# 将图像id映射为图像文件的路径，并将其存储在数据集中的path列中。\n",
    "df['path'] = df['image_id'].map(imageid_path.get)\n",
    "# 将诊断编码映射为对应的分类名称，并将其存储在数据集中的cell_type列中。\n",
    "df['cell_type'] = df['dx'].map(lesion_type.get)\n",
    "# 将分类名称转换为数字编码，并将其存储在数据集中的target列中。这里使用了.\n",
    "# 可以将字符串类型的分类变量转换为数字编码，其中不同的分类名称对应不同的数字编码。\n",
    "df['target'] = pd.Categorical(df['cell_type']).codes\n",
    "print(df['cell_type'].value_counts())\n",
    "print(df['target'].value_counts())\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb3ad1b",
   "metadata": {},
   "source": [
    "### Custom dataset prepration in Pytorch format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec84f755",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkinData(Dataset):\n",
    "    # 其作用是将数据集转化为可以在PyTorch中使用的形式\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        __getitem__通过给定索引index返回一个样本数据。该方法首先打开一个图片，\n",
    "        然后读取该图片的路径并将其转换为PyTorch中的Tensor对象。同时还会返回该样本的标签（即病变类型所对应的数字编码）。\n",
    "        \"\"\"\n",
    "        X = Image.open(self.df['path'][index]).resize((64, 64))\n",
    "        y = torch.tensor(int(self.df['target'][index]))\n",
    "\n",
    "        if self.transform:\n",
    "            \"\"\"\n",
    "            在构造SkinData对象时，可以选择是否使用变换（transform）来对样本数据进行预处理。\n",
    "            如果使用变换，将对图像进行缩放，同时可以应用一些常用的数据增强操作，如随机旋转、随机翻转、随机裁剪等。\n",
    "            \"\"\"\n",
    "            X = self.transform(X)\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "acd407eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Train-test split  \n",
    "train, test = train_test_split(df, test_size=0.2)\n",
    "# reset_index()函数用于重置索引，以便在后续处理中更容易使用。\n",
    "train = train.reset_index()\n",
    "test = test.reset_index()\n",
    "\n",
    "# =============================================================================\n",
    "#                         Data preprocessing\n",
    "# =============================================================================\n",
    "# Data preprocessing: Transformation \n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\"\"\"\n",
    "函数将它们组合成一个数据预处理的 pipeline。在 train_transforms 中，首先进行了一个 50% 的概率的水平翻转，之后是一个 50% 的概率的竖直翻转，然后进行了一个 3 像素的 padding，紧接着进行了一个 10 度的随机旋转，最后对图像中心区域进行 64 像素的裁剪，最终将图像转换为 Tensor 格式，并进行归一化处理。而在 \"\"\"\n",
    "# torchvision.transforms是pytorch中的图像预处理包。一般用Compose把多个步骤整合到一起\n",
    "train_transforms = transforms.Compose([transforms.RandomHorizontalFlip(),  # 以0。5概率水平翻转给定PIL图像\n",
    "                                       transforms.RandomVerticalFlip(),  # 竖直\n",
    "                                       transforms.Pad(3),  #\n",
    "                                       transforms.RandomRotation(10),\n",
    "                                       transforms.CenterCrop(64),  # 图片中间区域进行裁剪\n",
    "                                       transforms.ToTensor(),  # 转化为torch tensor\n",
    "                                       transforms.Normalize(mean=mean, std=std)\n",
    "                                       ])\n",
    "\"\"\"\n",
    "只进行了一个 3 像素的 padding，之后进行了一个图像中心区域 64 像素的裁剪，最终将图像转换为 Tensor 格式，并进行归一化处理。这样做的目的是对训练和测试数据集进行相同的处理方式，以便在模型训练和测试时有相同的数据输入。\"\"\"\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Pad(3),\n",
    "    transforms.CenterCrop(64),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "# With augmentation\n",
    "dataset_train = SkinData(train, transform=train_transforms)\n",
    "dataset_test = SkinData(test, transform=test_transforms)\n",
    "\n",
    "# -----------------------------------------------\n",
    "dict_users = dataset_iid(dataset_train, num_users)\n",
    "dict_users_test = dataset_iid(dataset_test, num_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c193a3",
   "metadata": {},
   "source": [
    "## Train and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91e9051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 41.946 \tLoss: 1.6383\u001b[00m\n",
      "[4]\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 67.339 \tLoss: 1.6486\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 40.299 \tLoss: 1.6437\u001b[00m\n",
      "[4, 3]\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 64.453 \tLoss: 1.7233\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 42.734 \tLoss: 1.6302\u001b[00m\n",
      "[4, 3, 2]\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 65.234 \tLoss: 1.6943\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 40.885 \tLoss: 1.6761\u001b[00m\n",
      "[4, 3, 2, 1]\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 66.254 \tLoss: 1.7079\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 43.048 \tLoss: 1.6146\u001b[00m\n",
      "[4, 3, 2, 1, 0]\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 66.059 \tLoss: 1.6946\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "====================== SERVER V1==========================\n",
      " Train: Round   0, Avg Accuracy 41.782 | Avg Loss 1.641\n",
      " Test: Round   0, Avg Accuracy 65.868 | Avg Loss 1.694\n",
      "==========================================================\n",
      "-----------------------------------------------------------\n",
      "------ FedServer: Federation process at Client-Side ------- \n",
      "-----------------------------------------------------------\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 67.930 \tLoss: 1.0129\u001b[00m\n",
      "[1]\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 65.495 \tLoss: 1.2969\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 70.169 \tLoss: 0.9734\u001b[00m\n",
      "[1, 0]\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 67.274 \tLoss: 1.2852\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 65.752 \tLoss: 1.0514\u001b[00m\n",
      "[1, 0, 3]\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 69.640 \tLoss: 1.3114\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 66.751 \tLoss: 1.0004\u001b[00m\n",
      "[1, 0, 3, 4]\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 69.314 \tLoss: 1.2978\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 68.613 \tLoss: 0.9791\u001b[00m\n",
      "[1, 0, 3, 4, 2]\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 65.994 \tLoss: 1.3066\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "====================== SERVER V1==========================\n",
      " Train: Round   1, Avg Accuracy 67.843 | Avg Loss 1.003\n",
      " Test: Round   1, Avg Accuracy 67.543 | Avg Loss 1.300\n",
      "==========================================================\n",
      "-----------------------------------------------------------\n",
      "------ FedServer: Federation process at Client-Side ------- \n",
      "-----------------------------------------------------------\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 71.724 \tLoss: 0.8407\u001b[00m\n",
      "[0]\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 67.817 \tLoss: 1.0870\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 68.026 \tLoss: 0.9308\u001b[00m\n",
      "[0, 3]\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 68.511 \tLoss: 1.1494\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 70.588 \tLoss: 0.8621\u001b[00m\n",
      "[0, 3, 2]\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 65.690 \tLoss: 1.0912\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 67.796 \tLoss: 0.9186\u001b[00m\n",
      "[0, 3, 2, 4]\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 68.403 \tLoss: 1.0638\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 69.680 \tLoss: 0.8948\u001b[00m\n",
      "[0, 3, 2, 4, 1]\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 66.385 \tLoss: 1.0969\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "====================== SERVER V1==========================\n",
      " Train: Round   2, Avg Accuracy 69.563 | Avg Loss 0.889\n",
      " Test: Round   2, Avg Accuracy 67.361 | Avg Loss 1.098\n",
      "==========================================================\n",
      "-----------------------------------------------------------\n",
      "------ FedServer: Federation process at Client-Side ------- \n",
      "-----------------------------------------------------------\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 69.470 \tLoss: 0.8730\u001b[00m\n",
      "[1]\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 68.750 \tLoss: 0.9657\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 70.656 \tLoss: 0.8570\u001b[00m\n",
      "[1, 2]\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 65.951 \tLoss: 0.9881\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 69.995 \tLoss: 0.8557\u001b[00m\n",
      "[1, 2, 4]\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 72.504 \tLoss: 0.8929\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 70.950 \tLoss: 0.8291\u001b[00m\n",
      "[1, 2, 4, 0]\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 66.927 \tLoss: 0.9751\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 69.568 \tLoss: 0.8584\u001b[00m\n",
      "[1, 2, 4, 0, 3]\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 69.596 \tLoss: 0.9480\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "====================== SERVER V1==========================\n",
      " Train: Round   3, Avg Accuracy 70.128 | Avg Loss 0.855\n",
      " Test: Round   3, Avg Accuracy 68.746 | Avg Loss 0.954\n",
      "==========================================================\n",
      "-----------------------------------------------------------\n",
      "------ FedServer: Federation process at Client-Side ------- \n",
      "-----------------------------------------------------------\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 72.912 \tLoss: 0.7688\u001b[00m\n",
      "[2]\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 69.206 \tLoss: 0.9176\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 69.506 \tLoss: 0.8444\u001b[00m\n",
      "[2, 1]\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 68.056 \tLoss: 0.9055\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 73.637 \tLoss: 0.7592\u001b[00m\n",
      "[2, 1, 0]\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 69.466 \tLoss: 0.8737\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 70.198 \tLoss: 0.8180\u001b[00m\n",
      "[2, 1, 0, 4]\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 71.593 \tLoss: 0.8304\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 70.238 \tLoss: 0.8429\u001b[00m\n",
      "[2, 1, 0, 4, 3]\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 66.970 \tLoss: 0.9067\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "====================== SERVER V1==========================\n",
      " Train: Round   4, Avg Accuracy 71.298 | Avg Loss 0.807\n",
      " Test: Round   4, Avg Accuracy 69.058 | Avg Loss 0.887\n",
      "==========================================================\n",
      "-----------------------------------------------------------\n",
      "------ FedServer: Federation process at Client-Side ------- \n",
      "-----------------------------------------------------------\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 73.079 \tLoss: 0.7520\u001b[00m\n",
      "[0]\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 69.575 \tLoss: 0.8421\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 72.066 \tLoss: 0.7738\u001b[00m\n",
      "[0, 2]\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 69.141 \tLoss: 0.8705\u001b[00m\n",
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 72.039 \tLoss: 0.7942\u001b[00m\n",
      "[0, 2, 3]\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 67.839 \tLoss: 0.9383\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 71.522 \tLoss: 0.7883\u001b[00m\n",
      "[0, 2, 3, 1]\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 67.383 \tLoss: 0.9335\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 70.057 \tLoss: 0.8138\u001b[00m\n",
      "[0, 2, 3, 1, 4]\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 72.635 \tLoss: 0.8099\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "====================== SERVER V1==========================\n",
      " Train: Round   5, Avg Accuracy 71.753 | Avg Loss 0.784\n",
      " Test: Round   5, Avg Accuracy 69.314 | Avg Loss 0.879\n",
      "==========================================================\n",
      "-----------------------------------------------------------\n",
      "------ FedServer: Federation process at Client-Side ------- \n",
      "-----------------------------------------------------------\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 73.343 \tLoss: 0.7481\u001b[00m\n",
      "[2]\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 69.379 \tLoss: 0.8751\u001b[00m\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 72.135 \tLoss: 0.7553\u001b[00m\n",
      "[2, 0]\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 72.569 \tLoss: 0.7893\u001b[00m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 70.832 \tLoss: 0.7975\u001b[00m\n",
      "[2, 0, 3]\n",
      "\u001b[92m Client3 Test =>                   \tAcc: 71.680 \tLoss: 0.7916\u001b[00m\n",
      "\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 71.151 \tLoss: 0.7772\u001b[00m\n",
      "[2, 0, 3, 1]\n",
      "\u001b[92m Client1 Test =>                   \tAcc: 68.772 \tLoss: 0.8564\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 71.809 \tLoss: 0.7933\u001b[00m\n",
      "[2, 0, 3, 1, 4]\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 72.656 \tLoss: 0.7759\u001b[00m\n",
      "------------------------------------------------\n",
      "------ Federation process at Server-Side ------- \n",
      "------------------------------------------------\n",
      "====================== SERVER V1==========================\n",
      " Train: Round   6, Avg Accuracy 71.854 | Avg Loss 0.774\n",
      " Test: Round   6, Avg Accuracy 71.011 | Avg Loss 0.818\n",
      "==========================================================\n",
      "-----------------------------------------------------------\n",
      "------ FedServer: Federation process at Client-Side ------- \n",
      "-----------------------------------------------------------\n",
      "\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 74.530 \tLoss: 0.7229\u001b[00m\n",
      "[0]\n",
      "\u001b[92m Client0 Test =>                   \tAcc: 70.421 \tLoss: 0.8234\u001b[00m\n",
      "\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 70.678 \tLoss: 0.7760\u001b[00m\n",
      "[0, 4]\n",
      "\u001b[92m Client4 Test =>                   \tAcc: 71.332 \tLoss: 0.7879\u001b[00m\n",
      "\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 73.972 \tLoss: 0.7145\u001b[00m\n",
      "[0, 4, 2]\n",
      "\u001b[92m Client2 Test =>                   \tAcc: 69.423 \tLoss: 0.8614\u001b[00m\n"
     ]
    }
   ],
   "source": [
    "#------------ Training And Testing  -----------------\n",
    "net_glob_client.train()\n",
    "#copy weights\n",
    "w_glob_client = net_glob_client.state_dict()\n",
    "# Federation takes place after certain local epochs in train() client-side\n",
    "# this epoch is global epoch, also known as rounds\n",
    "for iter in range(epochs):\n",
    "    m = max(int(frac * num_users), 1)\n",
    "    idxs_users = np.random.choice(range(num_users), m, replace = False)\n",
    "    w_locals_client = []\n",
    "      \n",
    "    for idx in idxs_users:\n",
    "        local = Client(net_glob_client, idx, lr, device, dataset_train = dataset_train, dataset_test = dataset_test, idxs = dict_users[idx], idxs_test = dict_users_test[idx])\n",
    "        # Training ------------------\n",
    "        w_client = local.train(net = copy.deepcopy(net_glob_client).to(device))\n",
    "        w_locals_client.append(copy.deepcopy(w_client))\n",
    "        \n",
    "        # Testing -------------------\n",
    "        local.evaluate(net = copy.deepcopy(net_glob_client).to(device), ell= iter)\n",
    "        \n",
    "            \n",
    "    # Ater serving all clients for its local epochs------------\n",
    "    # Fed  Server: Federation process at Client-Side-----------\n",
    "    print(\"-----------------------------------------------------------\")\n",
    "    print(\"------ FedServer: Federation process at Client-Side ------- \")\n",
    "    print(\"-----------------------------------------------------------\")\n",
    "    w_glob_client = FedAvg(w_locals_client)   \n",
    "    \n",
    "    # Update client-side global model \n",
    "    net_glob_client.load_state_dict(w_glob_client)    \n",
    "    \n",
    "#===================================================================================      \n",
    "\n",
    "print(\"Training and Evaluation completed!\")    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35401605",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===============================================================================\n",
    "# Save output data to .excel file (we use for comparision plots)\n",
    "round_process = [i for i in range(1, len(acc_train_collect)+1)]\n",
    "df = DataFrame({'round': round_process,'acc_train':acc_train_collect, 'acc_test':acc_test_collect})     \n",
    "file_name = program+\".xlsx\"    \n",
    "df.to_excel(file_name, sheet_name= \"v1_test\", index = False)     \n",
    "\n",
    "#=============================================================================\n",
    "#                         Program Completed\n",
    "#============================================================================="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
